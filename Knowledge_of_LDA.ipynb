{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NollyKeyz/NLP/blob/main/Knowledge_of_LDA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ld1LTkNMz7Ff"
      },
      "source": [
        "## Introduction\n",
        "** **\n",
        "Topic Models, in a nutshell, are a type of statistical language models used for uncovering hidden structure in a collection of texts. In a practical and more intuitively, you can think of it as a task of:\n",
        "\n",
        "- **Dimensionality Reduction**, where rather than representing a text T in its feature space as {Word_i: count(Word_i, T) for Word_i in Vocabulary}, you can represent it in a topic space as {Topic_i: Weight(Topic_i, T) for Topic_i in Topics}\n",
        "- **Unsupervised Learning**, where it can be compared to clustering, as in the case of clustering, the number of topics, like the number of clusters, is an output parameter. By doing topic modeling, we build clusters of words rather than clusters of texts. A text is thus a mixture of all the topics, each having a specific weight\n",
        "- **Tagging**, abstract “topics” that occur in a collection of documents that best represents the information in them.\n",
        "\n",
        "There are several existing algorithms you can use to perform the topic modeling. The most common of it are, Latent Semantic Analysis (LSA/LSI), Probabilistic Latent Semantic Analysis (pLSA), and Latent Dirichlet Allocation (LDA)\n",
        "\n",
        "In this workshop, we’ll take a closer look at LDA, and implement our first topic model using the sklearn implementation\n",
        "\n",
        "### Theoretical Overview\n",
        "LDA is a generative probabilistic model that assumes each topic is a mixture over an underlying set of words, and each document is a mixture of over a set of topic probabilities.\n",
        "\n",
        "![LDA_Model](https://github.com/chdoig/pytexas2015-topic-modeling/blob/master/images/lda-4.png?raw=true)\n",
        "\n",
        "We can describe the generative process of LDA as, given the M number of documents, N number of words, and prior K number of topics, the model trains to output:\n",
        "\n",
        "- `psi`, the distribution of words for each topic K\n",
        "- `phi`, the distribution of topics for each document i\n",
        "\n",
        "#### Parameters of LDA\n",
        "\n",
        "- `Alpha parameter` is Dirichlet prior concentration parameter that represents document-topic density — with a higher alpha, documents are assumed to be made up of more topics and result in more specific topic distribution per document.\n",
        "- `Beta parameter` is the same prior concentration parameter that represents topic-word density — with high beta, topics are assumed to made of up most of the words and result in a more specific word distribution per topic."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "czqxM14Uz7Fh"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/Ali-Alameer/NLP/blob/main/week9_topic_modelling_LDA.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t6rbEErmz7Fh"
      },
      "source": [
        "** **\n",
        "### LDA Implementation\n",
        "\n",
        "1. [Loading data](#load_data)\n",
        "2. [Data cleaning](#clean_data)\n",
        "3. [Exploratory analysis](#eda)\n",
        "4. [Prepare data for LDA analysis](#data_preparation)\n",
        "5. [LDA model training](#train_model)\n",
        "6. [Analyzing LDA model results](#results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B-DZci9Oz7Fh"
      },
      "source": [
        "** **\n",
        "For this workshop, we’ll use the dataset of papers published in NeurIPS (NIPS) conference which is one of the most prestigious yearly events in the machine learning community. The CSV data file contains information on the different NeurIPS papers that were published from 1987 until 2016 (29 years!). These papers discuss a wide variety of topics in machine learning, from neural networks to optimization methods, and many more.\n",
        "\n",
        "Let’s start by looking at the content of the file"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VpoCQstkz7Fi"
      },
      "source": [
        "** **\n",
        "#### Step 1: Loading Data <a class=\"anchor\\\" id=\"load_data\"></a>\n",
        "** **"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "vscode": {
          "languageId": "python"
        },
        "id": "PXmFYsaYz7Fi",
        "outputId": "5a14524b-305a-4a43-8073-c16e5fcbb894",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyLDAvis\n",
            "  Downloading pyLDAvis-3.4.1-py3-none-any.whl (2.6 MB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/2.6 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.5/2.6 MB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m49.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m33.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.24.2 in /usr/local/lib/python3.10/dist-packages (from pyLDAvis) (1.25.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from pyLDAvis) (1.11.4)\n",
            "Collecting pandas>=2.0.0 (from pyLDAvis)\n",
            "  Downloading pandas-2.2.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.0/13.0 MB\u001b[0m \u001b[31m48.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from pyLDAvis) (1.3.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from pyLDAvis) (3.1.3)\n",
            "Requirement already satisfied: numexpr in /usr/local/lib/python3.10/dist-packages (from pyLDAvis) (2.9.0)\n",
            "Collecting funcy (from pyLDAvis)\n",
            "  Downloading funcy-2.0-py2.py3-none-any.whl (30 kB)\n",
            "Requirement already satisfied: scikit-learn>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from pyLDAvis) (1.2.2)\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.10/dist-packages (from pyLDAvis) (4.3.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from pyLDAvis) (67.7.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=2.0.0->pyLDAvis) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=2.0.0->pyLDAvis) (2023.4)\n",
            "Collecting tzdata>=2022.7 (from pandas>=2.0.0->pyLDAvis)\n",
            "  Downloading tzdata-2024.1-py2.py3-none-any.whl (345 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m345.4/345.4 kB\u001b[0m \u001b[31m27.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0.0->pyLDAvis) (3.3.0)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim->pyLDAvis) (6.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->pyLDAvis) (2.1.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=2.0.0->pyLDAvis) (1.16.0)\n",
            "Installing collected packages: funcy, tzdata, pandas, pyLDAvis\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 1.5.3\n",
            "    Uninstalling pandas-1.5.3:\n",
            "      Successfully uninstalled pandas-1.5.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "bigframes 0.23.0 requires pandas<2.1.4,>=1.5.0, but you have pandas 2.2.1 which is incompatible.\n",
            "google-colab 1.0.0 requires pandas==1.5.3, but you have pandas 2.2.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed funcy-2.0 pandas-2.2.1 pyLDAvis-3.4.1 tzdata-2024.1\n"
          ]
        }
      ],
      "source": [
        "!pip install pyLDAvis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "vscode": {
          "languageId": "python"
        },
        "id": "9_twK0hpz7Fi"
      },
      "outputs": [],
      "source": [
        "# Importing modules\n",
        "import pandas as pd\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "24Ys6fUJz7Fj"
      },
      "source": [
        "Read the dataset automatically from the github repository"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "vscode": {
          "languageId": "python"
        },
        "id": "ALkv43hUz7Fj",
        "outputId": "ece0bbb5-1f8d-4bdd-9cff-a36412a2dea8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     id  year                                              title event_type  \\\n",
              "0     1  1987  Self-Organization of Associative Database and ...        NaN   \n",
              "1    10  1987  A Mean Field Theory of Layer IV of Visual Cort...        NaN   \n",
              "2   100  1988  Storing Covariance by the Associative Long-Ter...        NaN   \n",
              "3  1000  1994  Bayesian Query Construction for Neural Network...        NaN   \n",
              "4  1001  1994  Neural Network Ensembles, Cross Validation, an...        NaN   \n",
              "\n",
              "                                            pdf_name          abstract  \\\n",
              "0  1-self-organization-of-associative-database-an...  Abstract Missing   \n",
              "1  10-a-mean-field-theory-of-layer-iv-of-visual-c...  Abstract Missing   \n",
              "2  100-storing-covariance-by-the-associative-long...  Abstract Missing   \n",
              "3  1000-bayesian-query-construction-for-neural-ne...  Abstract Missing   \n",
              "4  1001-neural-network-ensembles-cross-validation...  Abstract Missing   \n",
              "\n",
              "                                          paper_text  \n",
              "0  767\\n\\nSELF-ORGANIZATION OF ASSOCIATIVE DATABA...  \n",
              "1  683\\n\\nA MEAN FIELD THEORY OF LAYER IV OF VISU...  \n",
              "2  394\\n\\nSTORING COVARIANCE BY THE ASSOCIATIVE\\n...  \n",
              "3  Bayesian Query Construction for Neural\\nNetwor...  \n",
              "4  Neural Network Ensembles, Cross\\nValidation, a...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c1545930-5876-4b24-93cd-85bd4f750768\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>year</th>\n",
              "      <th>title</th>\n",
              "      <th>event_type</th>\n",
              "      <th>pdf_name</th>\n",
              "      <th>abstract</th>\n",
              "      <th>paper_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1987</td>\n",
              "      <td>Self-Organization of Associative Database and ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1-self-organization-of-associative-database-an...</td>\n",
              "      <td>Abstract Missing</td>\n",
              "      <td>767\\n\\nSELF-ORGANIZATION OF ASSOCIATIVE DATABA...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>10</td>\n",
              "      <td>1987</td>\n",
              "      <td>A Mean Field Theory of Layer IV of Visual Cort...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>10-a-mean-field-theory-of-layer-iv-of-visual-c...</td>\n",
              "      <td>Abstract Missing</td>\n",
              "      <td>683\\n\\nA MEAN FIELD THEORY OF LAYER IV OF VISU...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>100</td>\n",
              "      <td>1988</td>\n",
              "      <td>Storing Covariance by the Associative Long-Ter...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>100-storing-covariance-by-the-associative-long...</td>\n",
              "      <td>Abstract Missing</td>\n",
              "      <td>394\\n\\nSTORING COVARIANCE BY THE ASSOCIATIVE\\n...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1000</td>\n",
              "      <td>1994</td>\n",
              "      <td>Bayesian Query Construction for Neural Network...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1000-bayesian-query-construction-for-neural-ne...</td>\n",
              "      <td>Abstract Missing</td>\n",
              "      <td>Bayesian Query Construction for Neural\\nNetwor...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1001</td>\n",
              "      <td>1994</td>\n",
              "      <td>Neural Network Ensembles, Cross Validation, an...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1001-neural-network-ensembles-cross-validation...</td>\n",
              "      <td>Abstract Missing</td>\n",
              "      <td>Neural Network Ensembles, Cross\\nValidation, a...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c1545930-5876-4b24-93cd-85bd4f750768')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c1545930-5876-4b24-93cd-85bd4f750768 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c1545930-5876-4b24-93cd-85bd4f750768');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-0717c08b-e039-49b3-911c-5ad2bfb3e49c\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-0717c08b-e039-49b3-911c-5ad2bfb3e49c')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-0717c08b-e039-49b3-911c-5ad2bfb3e49c button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "papers",
              "summary": "{\n  \"name\": \"papers\",\n  \"rows\": 6560,\n  \"fields\": [\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1901,\n        \"min\": 1,\n        \"max\": 6603,\n        \"num_unique_values\": 6560,\n        \"samples\": [\n          3087,\n          78,\n          5412\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"year\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 8,\n        \"min\": 1987,\n        \"max\": 2016,\n        \"num_unique_values\": 30,\n        \"samples\": [\n          1992,\n          1990,\n          2012\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"title\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 6560,\n        \"samples\": [\n          \"Natural Actor-Critic for Road Traffic Optimisation\",\n          \"Learning Representations by Recirculation\",\n          \"Quantized Kernel Learning for Feature Matching\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"event_type\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"Oral\",\n          \"Spotlight\",\n          \"Poster\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pdf_name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 6560,\n        \"samples\": [\n          \"3087-natural-actor-critic-for-road-traffic-optimisation.pdf\",\n          \"78-learning-representations-by-recirculation.pdf\",\n          \"5412-quantized-kernel-learning-for-feature-matching.pdf\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"abstract\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3244,\n        \"samples\": [\n          \"Tensor CANDECOMP/PARAFAC (CP) decomposition has wide applications in statistical learning of latent variable models and in data mining. In this paper, we propose fast and randomized tensor CP decomposition algorithms based on sketching. We build on the idea of count sketches, but introduce many novel ideas which are unique to tensors. We develop novel methods for randomized com- putation of tensor contractions via FFTs, without explicitly forming the tensors. Such tensor contractions are encountered in decomposition methods such as ten- sor power iterations and alternating least squares. We also design novel colliding hashes for symmetric tensors to further save time in computing the sketches. We then combine these sketching ideas with existing whitening and tensor power iter- ative techniques to obtain the fastest algorithm on both sparse and dense tensors. The quality of approximation under our method does not depend on properties such as sparsity, uniformity of elements, etc. We apply the method for topic mod- eling and obtain competitive results.\",\n          \"Many spectral unmixing methods rely on the non-negative decomposition of spectral data onto a dictionary of spectral templates. In particular, state-of-the-art music transcription systems decompose the spectrogram of the input signal onto a dictionary of representative note spectra. The typical measures of fit used to quantify the adequacy of the decomposition compare the data and template entries frequency-wise. As such, small displacements of energy from a frequency bin to another as well as variations of timber can disproportionally harm the fit. We address these issues by means of optimal transportation and propose a new measure of fit that treats the frequency distributions of energy holistically as opposed to frequency-wise. Building on the harmonic nature of sound, the new measure is invariant to shifts of energy to harmonically-related frequencies, as well as to small and local displacements of energy. Equipped with this new measure of fit, the dictionary of note templates can be considerably simplified to a set of Dirac vectors located at the target fundamental frequencies (musical pitch values). This in turns gives ground to a very fast and simple decomposition algorithm that achieves state-of-the-art performance on real musical data.\",\n          \"The problem of  multiclass boosting is considered. A new framework,based on multi-dimensional codewords and predictors is introduced. The optimal set of codewords is derived, and a margin enforcing loss proposed. The resulting risk is minimized by gradient descent on a multidimensional functional space. Two algorithms are proposed: 1) CD-MCBoost, based on coordinate descent, updates one predictor component at a time, 2) GD-MCBoost, based on gradient descent, updates all components jointly. The algorithms differ in the weak learners that they support but are both shown to be 1) Bayes consistent, 2) margin enforcing, and 3) convergent to the global minimum of the risk. They also reduce to AdaBoost when there are only two classes. Experiments show that both methods outperform previous multiclass boosting approaches on a number of datasets.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"paper_text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 6553,\n        \"samples\": [\n          \"550\\n\\nAckley and Littman\\n\\nGeneralization and scaling in reinforcement\\nlearning\\nDavid H. Ackley\\nMichael L. Littman\\nCognitive Science Research Group\\nBellcore\\nMorristown, NJ 07960\\n\\nABSTRACT\\nIn associative reinforcement learning, an environment generates input\\nvectors, a learning system generates possible output vectors, and a reinforcement function computes feedback signals from the input-output\\npairs. The task is to discover and remember input-output pairs that\\ngenerate rewards. Especially difficult cases occur when rewards are\\nrare, since the expected time for any algorithm can grow exponentially\\nwith the size of the problem. Nonetheless, if a reinforcement function\\npossesses regularities, and a learning algorithm exploits them, learning\\ntime can be reduced below that of non-generalizing algorithms. This\\npaper describes a neural network algorithm called complementary reinforcement back-propagation (CRBP), and reports simulation results\\non problems designed to offer differing opportunities for generalization.\\n\\n1\\n\\nREINFORCEMENT LEARNING REQUIRES SEARCH\\n\\nReinforcement learning (Sutton, 1984; Barto & Anandan, 1985; Ackley, 1988; Allen,\\n1989) requires more from a learner than does the more familiar supervised learning\\nparadigm. Supervised learning supplies the correct answers to the learner, whereas\\nreinforcement learning requires the learner to discover the correct outputs before\\nthey can be stored. The reinforcement paradigm divides neatly into search and\\nlearning aspects: When rewarded the system makes internal adjustments to learn\\nthe discovered input-output pair; when punished the system makes internal adjustments to search elsewhere.\\n\\n\\fGeneralization and Scaling in Reinforcement Learning\\n1.1\\n\\nMAKING REINFORCEMENT INTO ERROR\\n\\nFollowing work by Anderson (1986) and Williams (1988), we extend the backpropagation algorithm to associative reinforcement learning. Start with a \\\"garden variety\\\" backpropagation network: A vector i of n binary input units propagates\\nthrough zero or more layers of hidden units, ultimately reaching a vector 8 of m\\nsigmoid units, each taking continuous values in the range (0,1). Interpret each 8j\\nas the probability that an associated random bit OJ takes on value 1. Let us call\\nthe continuous, deterministic vector 8 the search vector to distinguish it from the\\nstochastic binary output vector o.\\nGiven an input vector, we forward propagate to produce a search vector 8, and\\nthen perform m independent Bernoulli trials to produce an output vector o. The\\ni - 0 pair is evaluated by the reinforcement function and reward or punishment\\nensues. Suppose reward occurs. We therefore want to make 0 more likely given i.\\nBackpropagation will do just that if we take 0 as the desired target to produce an\\nerror vector (0 - 8) and adjust weights normally.\\nNow suppose punishment occurs, indicating 0 does not correspond with i. By choice\\nof error vector, backpropagation allows us to push the search vector in any direction;\\nwhich way should we go? In absence of problem-specific information, we cannot pick\\nan appropriate direction with certainty. Any decision will involve assumptions. A\\nvery minimal \\\"don't be like 0\\\" assumption-employed in Anderson (1986), Williams\\n(1988), and Ackley (1989)-pushes s directly away from 0 by taking (8 - 0) as the\\nerror vector. A slightly stronger \\\"be like not-o\\\" assumption-employed in Barto &\\nAnandan (1985) and Ackley (1987)-pushes s directly toward the complement of 0\\nby taking ((1 - 0) - 8) as the error vector. Although the two approaches always\\nagree on the signs of the error terms, they differ in magnitudes. In this work,\\nwe explore the second possibility, embodied in an algorithm called complementary\\nreinforcement back-propagation ( CRBP).\\nFigure 1 summarizes the CRBP algorithm. The algorithm in the figure reflects three\\nmodifications to the basic approach just sketched. First, in step 2, instead of using\\nthe 8j'S directly as probabilities, we found it advantageous to \\\"stretch\\\" the values\\nusing a parameter v. When v < 1, it is not necessary for the 8i'S to reach zero or\\none to produce a deterministic output. Second, in step 6, we found it important\\nto use a smaller learning rate for punishment compared to reward. Third, consider\\nstep 7: Another forward propagation is performed, another stochastic binary output vector 0* is generated (using the procedure from step 2), and 0* is compared\\nto o. If they are identical and punishment occurred, or if they are different and\\nreward occurred, then another error vector is generated and another weight update\\nis performed. This loop continues until a different output is generated (in the case\\nof failure) or until the original output is regenerated (in the case of success). This\\nmodification improved performance significantly, and added only a small percentage\\nto the total number of weight updates performed.\\n\\n551\\n\\n\\f552\\n\\nAckley and Littman\\n\\nO. Build a back propagation network with input dimensionality n and output\\ndimensionality m. Let t = 0 and te = O.\\n1. Pick random i E 2n and forward propagate to produce a/s.\\n2. Generate a binary output vector o. Given a uniform random variable ~ E [0,1]\\nand parameter 0 < v < 1,\\nOJ\\n\\n=\\n\\n{1,\\n\\n0,\\n\\nif(sj - !)/v+! ~ ~j\\notherwise.\\n\\n3. Compute reinforcement r = f(i,o). Increment t. If r < 0, let te = t.\\n4. Generate output errors ej. If r > 0, let tj = OJ, otherwise let tj = 1- OJ. Let\\nej = (tj - sj)sj(l- Sj).\\n5. Backpropagate errors.\\n6. Update weights. 1:::..Wjk = 1]ekSj, using 1] = 1]+ if r ~ 0, and 1] = 1]- otherwise,\\nwith parameters 1]+,1]- > o.\\n7. Forward propagate again to produce new Sj's. Generate temporary output\\nvector 0*. If (r > 0 and 0* #- 0) or (r < 0 and 0* = 0), go to 4.\\n8. If te ~ t, exit returning te, else go to 1.\\n\\nFigure 1: Complementary Reinforcement Back Propagation-CRBP\\n\\n2\\n\\nON-LINE GENERALIZATION\\n\\nWhen there are many possible outputs and correct pairings are rare, the computational cost associated with the search for the correct answers can be profound.\\nThe search for correct pairings will be accelerated if the search strategy can effectively generalize the reinforcement received on one input to others. The speed of\\nan algorithm on a given problem relative to non-generalizing algorithms provides a\\nmeasure of generalization that we call on-line generalization.\\nO. Let z be an array of length 2n. Set the z[i] to random numbers from 0 to\\n2m - 1. Let t = te = O.\\n1. Pick a random input i E 2n.\\n2. Compute reinforcement r = f(i, z[i]). Increment t.\\n3. If r < 0 let z[i] = (z[i] + 1) mod 2m , and let te = t.\\n4. If te <t:: t exit returning t e, else go to 1.\\n\\nFigure 2: The Table Lookup Reference Algorithm Tref(f, n, m)\\nConsider the table-lookup algorithm Tref(f, n, m) summarized in Figure 2. In this\\nalgorithm, a separate storage location is used for each possible input. This prevents\\nthe memorization of one i - 0 pair from interfering with any other. Similarly,\\nthe selection of a candidate output vector depends only on the slot of the table\\ncorresponding to the given input. The learning speed of T ref depends only on the\\ninput and output dimensionalities and the number of correct outputs associated\\n\\n\\fGeneralization and Scaling in Reinforcement Learning\\n\\nwith each input. When a problem possesses n input bits and n output bits, and\\nthere is only one correct output vector for each input vector, Tre{ runs in about 4n\\ntime (counting each input-output judgment as one.) In such cases one expects to\\ntake at least 2n - 1 just to find one correct i - 0 pair, so exponential time cannot be\\navoided without a priori information. How does a generalizing algorithm such as\\nCRBP compare to Trer?\\n\\n3\\n\\nSIMULATIONS ON SCALABLE PROBLEMS\\n\\nWe have tested CRBP on several simple problems designed to offer varying degrees\\nand types of generalization. In all of the simulations in this section, the following\\ndetails apply: Input and output bit counts are equal (n). Parameters are dependent\\non n but independent of the reinforcement function f. '7+ is hand-picked for each\\nn,l 11- = 11+/10 and II = 0.5. All data points are medians of five runs. The stopping\\ncriterion te ~ t is interpreted as te +max(2000, 2n+l) < t. The fit lines in the figures\\nare least squares solutions to a x bn , to two significant digits.\\nAs a notational convenience, let c = ~\\n\\n3.1\\n\\nn\\n\\nE ij\\n\\n;=1\\n\\n-\\n\\nthe fraction of ones in the input.\\n\\nn-MAJORlTY\\n\\nConsider this \\\"majority rules\\\" problem: [if c > ~ then 0 = In else 0 = on]. The i-o\\nmapping is many-to-l. This problem provides an opportunity for what Anderson\\n(1986) called \\\"output generalization\\\": since there are only two correct output states,\\nevery pair of output bits are completely correlated in the cases when reward occurs.\\n\\nG)\\n\\n'iii\\nu\\nrn\\n\\nC)\\n\\n0\\n\\n::::.\\nG)\\n\\nE\\n\\n;\\n\\n10 7\\n10 6\\n10 5\\n10 4\\n\\nx\\n\\nTable\\n\\nD\\n\\nCRBP n-n-n\\n\\n+ CRBP n-n\\n\\n10 3\\n10 2\\n10 1\\n10 0\\n0\\n\\n1\\n\\n2\\n\\n3\\n\\n456\\n\\n78\\n\\n91011121314\\n\\nn\\nFigure 3: The n-majority problem\\n\\nFigure 3 displays the simulation results. Note that although Trer is faster than\\nCRBP at small values of n, CRBP's slower growth rate (1.6n vs 4.2n ) allows it to\\ncross over and begin outperforming Trer at about 6 bits. Note also--in violation of\\n1 For n = 1 to 12. we used '1+\\n0.219. 0.170. 0.121}.\\n\\n= {2.000. 1.550. 1.130.0.979.0.783.0.709.0.623.0.525.0.280.\\n\\n553\\n\\n\\f554\\n\\nAckley and Littman\\n\\nsome conventional wisdom-that although n-majority is a linearly separable problem, the performance of CRBP with hidden units is better than without. Hidden\\nunits can be helpful--even on linearly separable problems-when there are opportunities for output generalization.\\n\\n3.2\\n\\nn-COPY AND THE 2k -ATTRACTORS FAMILY\\n\\nAs a second example, consider the n-copy problem: [0 = i]. The i-o mapping is now\\n1-1, and the values of output bits in rewarding states are completely uncorrelated,\\nbut the value of each output bit is completely correlated with the value of the\\ncorresponding input bit. Figure 4 displays the simulation results. Once again, at\\n\\nG)\\n\\n'ii\\n\\ntA\\nQ\\n0\\n\\n::::.\\nG)\\n\\n-\\n\\n.5\\n\\n10 7\\n10 6\\n10 5\\n10 4\\n\\nx\\n150*2.0I\\\\n\\n\\nD\\n\\n10 3\\n10 2\\n\\n12*2.2I\\\\n\\n\\n+\\n\\nTable\\nCRBP n-n-n\\nCRBP n-n\\n\\n10 1\\n10 0\\n0\\n\\n1\\n\\n2\\n\\n3\\n\\n4\\n\\n5\\n\\n6\\n\\n7\\n\\n8\\n\\n9\\n\\n10 1112\\n\\nn\\nFigure 4: The n-copy problem\\nlow values of n, Trer is faster, but CRBP rapidly overtakes Trer as n increases. In\\nn-copy, unlike n-majority, CRBP performs better without hidden units.\\nThe n-majority and n-copy problems are extreme cases of a spectrum. n-majority\\ncan be viewed as a \\\"2-attractors\\\" problem in that there are only two correct\\noutputs-all zeros and all ones-and the correct output is the one that i is closer\\nto in hamming distance. By dividing the input and output bits into two groups\\nand performing the majority function independently on each group, one generates\\na \\\"4-aUractors\\\" problem. In general, by dividing the input and output bits into\\n1 ~ Ie ~ n groups, one generates a \\\"2i:-attractors\\\" problem. When Ie = 1, nmajority results, and when Ie n, n-copy results.\\n\\n=\\n\\nFigure 5 displays simulation results on the n = 8-bit problems generated when Ie is\\nvaried from 1 to n. The advantage of hidden units for low values of Ie is evident,\\nas is the advantage of \\\"shortcut connections\\\" (direct input-to-output weights) for\\nlarger values of Ie. Note also that combination of both hidden units and shortcut\\nconnections performs better than either alone.\\n\\n\\fGeneralization and Scaling in Reinforcement Learning\\n\\n105~--------------------------------~\\n\\nCASP 8-10-8\\n-+- CASP 8-8\\n.... CASP 8-10-Sls\\n-0-\\n\\n... Table\\n\\n3\\n\\n2\\n\\n1\\n\\n5\\n\\n4\\n\\n7\\n\\n6\\n\\n8\\n\\nk\\n\\nFigure 5: The 21:- attractors family at n = 8\\n\\n3.3\\n\\nn-EXCLUDED MIDDLE\\n\\nAll of the functions considered so far have been linearly separable. Consider this\\n\\\"folded majority\\\" function: [if\\n< c < then 0 on else 0 In]. Now, like\\nn-majority, there are only two rewarding output states, but the determination of\\nwhich output state is correct is not linearly separable in the input space. When\\nn = 2, the n-excluded middle problem yields the EQV (i.e., the complement of\\nXOR) function, but whereas functions such as n-parity [if nc is even then 0\\non\\nelse 0 = In] get more non-linear with increasing n, n-excluded middle does not.\\n\\ni\\n\\ni\\n\\n=\\n\\n=\\n\\n=\\n\\n107~------------------------------~~\\n\\n-\\n\\n10 6\\n10 5\\n\\nD)\\n\\n10 4\\n10 3\\n\\nI)\\n\\n'ii\\nu\\nf)\\n\\n.2\\n\\nI)\\n\\nE\\n\\n:::\\n\\nx\\nc\\n\\n17oo*1.6\\\"n\\n\\nTable\\n\\nCRSP n-n-n/s\\n\\n10 2\\n10 1\\n10 0\\n0\\n\\n1\\n\\n2\\n\\n3\\n\\n4\\n\\n5\\n\\n6\\n\\n7\\n\\n8\\n\\n9\\n\\n10 1112\\n\\nn\\nFigure 6: The n-excluded middle problem\\nFigure 6 displays the simulation results. CRBP is slowed somewhat compared to\\nthe linearly separable problems, yielding a higher \\\"cross over point\\\" of about 8 bits.\\n\\n555\\n\\n\\f556\\n\\nAckley and Littman\\n\\n4\\n\\nSTRUCTURING DEGENERATE OUTPUT SPACES\\n\\nAll of the scaling problems in the previous section are designed so that there is\\na single correct output for each possible input. This allows for difficult problems\\neven at small sizes, but it rules out an important aspect of generalizing algorithms\\nfor associative reinforcement learning: If there are multiple satisfactory outputs\\nfor given inputs, a generalizing algorithm may impose structure on the mapping it\\nproduces.\\nWe have two demonstrations of this effect, \\\"Bit Count\\\" and \\\"Inverse Arithmetic.\\\"\\nThe Bit Count problem simply states that the number of I-bits in the output should\\nequal the number of I-bits in the input. When n = 9, Tref rapidly finds solutions\\ninvolving hundreds of different output patterns. CRBP is slower--especially with\\nrelatively few hidden units-but it regularly finds solutions involving just 10 output\\npatterns that form a sequence from 09 to 19 with one bit changing per step.\\n0+Ox4=0\\n1+0x4=1\\n2+0x4=2\\n3+0x4=3\\n\\n0+2x4=8\\n1+2x4=9\\n2 + 2 x 4 = 10\\n3+2x4=11\\n\\n4+0x4=4 4+ 2 x 4 =\\n5+0x4=5 5 + 2 x 4 =\\n6+0x4=6 6 + 2 x 4 =\\n7+0x4=7 7 + 2 x 4 =\\n\\n12\\n13\\n14\\n15\\n\\n2+2-4=0 2+2+4=8\\n3+2-4=1 3+2+4=9\\n2+2+4=2 2 + 2 x 4 = 10\\n3+2+4=3 3+2x4=1l\\n6+2-4=4\\n7+2-4=5\\n6+2+4=6\\n7+2-.;-4=7\\n\\n6+\\n7+\\n6+\\n7+\\n\\n2+ 4 =\\n2+ 4 =\\n2x4=\\n2x4=\\n\\n0+4 x 4 = 16 0+6 x 4 =\\n1+4x4=17 1 + 6 x 4 =\\n2 + 4 x 4 = 18 2 + 6 x 4 =\\n3 +4 x 4 = 19 3 + 6 x 4 =\\n\\n24\\n25\\n26\\n27\\n\\n4+4\\n5+ 4\\n6+ 4\\n7+ 4\\n\\n=\\n=\\n=\\n=\\n\\n28\\n29\\n30\\n31\\n24\\n25\\n26\\n27\\n\\nx\\nx\\nx\\nx\\n\\n4=\\n4=\\n4=\\n4=\\n\\n6+ 6 + 4 =\\n7+6+4=\\n2+ 4 x 4 =\\n3+ 4 x 4=\\n\\n12 4 x 4 +\\n13 5 + 4 x\\n14 6 + 4 x\\n15 7 +4 x\\n\\n4=\\n4=\\n4\\n4=\\n\\n=\\n\\n20 4 + 6 x\\n21 5 + 6 x\\n22 6 + 6 x\\n23 7 + 6 x\\n\\n4\\n4\\n4\\n4\\n\\n16\\n17\\n18\\n19\\n\\n0+6 x\\n1+ 6 x\\n2+ 6x\\n3+ 6x\\n\\n4=\\n4=\\n4=\\n4=\\n\\n20\\n21\\n22\\n23\\n\\n4+\\n5+\\n6+\\n7+\\n\\n4 = 28\\n4 = 29\\n4 30\\n4 = 31\\n\\n6\\n6\\n6\\n6\\n\\nx\\nx\\nx\\nx\\n\\n=\\n\\nFigure 7: Sample CRBP solutions to Inverse Arithmetic\\n\\nThe Inverse Arithmetic problem can be summarized as follows: Given i E 25 , find\\n:1:, y, z E 23 and 0, <> E {+(OO)' -(01)' X (10)' +(11)} such that :I: oy<>z = i. In all there are\\n13 bits of output, interpreted as three 3-bit binary numbers and two 2-bit operators,\\nand the task is to pick an output that evaluates to the given 5-bit binary input\\nunder the usual rules: operator precedence, left-right evaluation, integer division,\\nand division by zero fails.\\nAs shown in Figure 7, CRBP sometimes solves this problem essentially by discovering positional notation, and sometimes produces less-globally structured solutions,\\nparticularly as outputs for lower-valued i's, which have a wider range of solutions.\\n\\n\\fGeneralization and Scaling in Reinforcement Learning\\n\\n5\\n\\nCONCLUSIONS\\n\\nSome basic concepts of supervised learning appear in different guises when the\\nparadigm of reinforcement learning is applied to large output spaces. Rather than\\na \\\"learning phase\\\" followed by a \\\"generalization test,\\\" in reinforcement learning\\nthe search problem is a generalization test, performed simultaneously with learning.\\nInformation is put to work as soon as it is acquired.\\nThe problem of of \\\"overfitting\\\" or \\\"learning the noise\\\" seems to be less of an issue,\\nsince learning stops automatically when consistent success is reached. In experiments not reported here we gradually increased the number of hidden units on\\nthe 8-bit copy problem from 8 to 25 without observing the performance decline\\nassociated with \\\"too many free parameters.\\\"\\nThe 2 k -attractors (and 2 k -folds-generalizing Excluded Middle) families provide\\na starter set of sample problems with easily understood and distinctly different\\nextreme cases.\\nIn degenerate output spaces, generalization decisions can be seen directly in the\\ndiscovered mapping. Network analysis is not required to \\\"see how the net does it.\\\"\\nThe possibility of ultimately generating useful new knowledge via reinforcement\\nlearning algorithms cannot be ruled out.\\nReferences\\nAckley, D.H. (1987) A connectionist machine for genetic hillclimbing. Boston, MA: Kluwer\\nAcademic Press.\\nAckley, D.H. (1989) Associative learning via inhibitory search. In D.S. Touretzky (ed.),\\nAdvances in Neural Information Processing Systems 1, 20-28. San Mateo, CA: Morgan\\nKaufmann.\\nAllen, R.B. (1989) Developing agent models with a neural reinforcement technique. IEEE\\nSystems, Man, and Cybernetics Conference. Cambridge, MA.\\nAnderson, C.W. (1986) Learning and problem solving with multilayer connectionist systems. University of Mass. Ph.D. dissertation. COINS TR 86-50. Amherst, MA.\\nBarto, A.G. (1985) Learning by statistical cooperation of self-interested neuron-like computing elements. Human Neurobiology, 4:229-256.\\nBarto, A.G., & Anandan, P. (1985) Pattern recognizing stochastic learning automata.\\nIEEE Transactions on Systems, Man, and Cybernetics, 15, 360-374.\\nRumelhart, D.E., Hinton, G.E., & Williams, R.J. (1986) Learning representations by backpropagating errors. Nature, 323, 533-536.\\nSutton, R.S. (1984) Temporal credit assignment in reinforcement learning. University of\\nMass. Ph.D. dissertation. COINS TR 84-2. Amherst, MA.\\nWilliams, R.J. (1988) Toward a theory of reinforcement-learning connectionist systems.\\nCollege of Computer Science of Northeastern University Technical Report NU-CCS-88-3.\\nBoston, MA.\\n\\n557\\n\\n\\f\",\n          \"Dynamics of Supervised Learning with\\nRestricted Training Sets and Noisy Teachers\\n\\nA.C.C. Coolen\\nDept of Mathematics\\nKing's College London\\nThe Strand, London WC2R 2LS, UK\\ntcoolen@mth.kc1.ac.uk\\n\\nC.W.H.Mace\\nDept of Mathematics\\nKing's College London\\nThe Strand, London WC2R 2LS, UK\\ncmace@mth.kc1.ac.uk\\n\\nAbstract\\nWe generalize a recent formalism to describe the dynamics of supervised\\nlearning in layered neural networks, in the regime where data recycling\\nis inevitable, to the case of noisy teachers. Our theory generates reliable\\npredictions for the evolution in time of training- and generalization errors, and extends the class of mathematically solvable learning processes\\nin large neural networks to those situations where overfitting can occur.\\n\\n1 Introduction\\nTools from statistical mechanics have been used successfully over the last decade to study\\nthe dynamics of learning in layered neural networks (for reviews see e.g. [1] or [2]). The\\nsimplest theories result upon assuming the data set to be much larger than the number\\nof weight updates made, which rules out recycling and ensures that any distribution of\\nrelevance will be Gaussian. Unfortunately, both in terms of applications and in terms of\\nmathematical interest, this regime is not the most relevant one. Most complications and\\npeculiarities in the dynamics of learning arise precisely due to data recycling, which creates\\nfor the system the possibility to improve performance by memorizing answers rather than\\nby learning an underlying rule. The dynamics of learning with restricted training sets was\\nfirst studied analytically in [3] (linear learning rules) and [4] (systems with binary weights).\\nThe latter studies were ahead of their time, and did not get the attention they deserved just\\nbecause at that stage even the simpler learning dynamics without data recycling had not\\nyet been studied. More recently attention has moved back to the dynamics of learning\\nin the recycling regime. Some studies aimed at developing a general theory [5, 6, 7],\\nsome at finding exact solutions for special cases [8]. All general theories published so far\\nhave in common that they as yet considered realizable scenario's: the rule to be learned\\nwas implementable by the student, and overfitting could not yet occur. The next hurdle is\\nthat where restricted training sets are combined with unrealizable rules. Again some have\\nturned to non-typical but solvable cases, involving Hebbian rules and noisy [9] or 'reverse\\nwedge' teachers [10]. More recently the cavity method has been used to build a general\\ntheory [11] (as yet for batch learning only). In this paper we generalize the general theory\\nlaunched in [6,5,7], which applies to arbitrary learning rules, to the case of noisy teachers.\\nWe will mirror closely the presentation in [6] (dealing with the simpler case of noise-free\\nteachers), and we refer to [5, 7] for background reading on the ideas behind the formalism.\\n\\n\\fA. C. C. Coolen and C. W. H. Mace\\n\\n238\\n\\n2 Definitions\\nAs in [6, 5] we restrict ourselves for simplicity to perceptrons. A student perceptron operates a linear separation, parametrised by a weight vector J E iRN :\\nS:{-I,I}N -t{-I,I}\\n\\nS(e) = sgn[J?e]\\n\\nIt aims to emulate a teacher o~erating a similar rule, which, however, is characterized by a\\nvariable weight vector BE iR ,drawn at random from a distribution P(B) such as\\nP(B) = >'6[B+B*]\\n\\noutput noise:\\n\\n+ (1->')6[B-B*]\\n\\n(1)\\n\\nP(B) = [~~/NrN e- tN (B-B')2/E2\\n(2)\\nThe parameters>. and ~ control the amount of teacher noise, with the noise-free teacher\\nB = B* recovered in the limits>. -t 0 and ~ -t O. The student modifies J iteratively, using\\nexamples of input vectors which are drawn at random from a fixed (randomly composed)\\nE {-I, I}N with a> 0, and the corresponding\\ntraining set containing p = aN vectors\\nvalues of the teacher outputs. We choose the teacher noise to be consistent, i.e. the answer\\nwill remain the same when that particular question\\ngiven by the teacher to a question\\nre-appears during the learning process. Thus T(e?) = sgn[BJL . e], with p teacher weight\\nvectors BJL, drawn randomly and independently from P(B), and we generalize the training\\nl , B l ), . .. , (e, BP)}. Consistency of teacher noise is natural\\nset accordingly to jj =\\nin terms of applications, and a prerequisite for overfitting phenomena. Averages over the\\ntraining set will be denoted as ( ... ) b; averages over all possible input vectors E {-I, I}N\\nas ( ... )e. We analyze two classes of learning rules, of the form J (? + 1) = J (?) + f).J (?):\\n\\nGaussian weight noise:\\n\\ne\\n\\ne\\n\\ne\\n\\nHe\\n\\ne\\n\\n= 11 {e(?) 9 [J(?)?e(?), B(?)?e(?)] - ,J(?) }\\nf).J(?) = 11 {(e 9 [J(?)?e, B?eDl> - ,J(m) }\\n\\non-line:\\n\\nf).J(?)\\n\\nbatch :\\n\\n(3)\\n\\nIn on-line learning one draws at each step ? a question/answer pair (e (?), B (?)) at random from the training set. In batch learning one iterates a deterministic map which is an\\naverage over all data in the training set. Our performance measures are the training- and\\ngeneralization errors, defined as follows (with the step function O[x > 0] = 1, O[x < 0] = 0):\\nEt(J)\\n\\n= (O[-(J ?e)(B ?em b\\n\\nEg(J)\\n\\n= (O[-(J ?e)(B* ?e)])e\\n\\n(4)\\n\\nWe introduce macroscopic observables, taylored to the present problem, generalizing [5, 6]:\\nQ[J]=J 2,\\nR[J]=J?B*,\\nP[x,y,z;J]=(6[x-J?e]6[y-B*?e]6[z-B?eDl> (5)\\nAs in [5, 6] we eliminate technical subtleties by assuming the number of arguments (x, y, z)\\nfor which P[x, y, z; J] is evaluated to go to infinity after the limit N -t 00 has been taken.\\n\\n3 Derivation of Macroscopic Laws\\nUpon generalizing the calculations in [6, 5], one finds for on-line learning:\\n\\n!\\n!\\n\\nQ = 2'f} !dXdydZ P[x, y, z] xg[x, z] - 2'f},Q + 'f}2!dXdYdZ P[x, y, z] g2[x, z]\\n\\n(6)\\n\\nR = 'f} !dXdydZ P[x, y, z] y9[x, z]- 'f},R\\n\\n(7)\\n\\n:t\\n\\nP[x, y, z] =\\n\\n~\\n\\n!\\n\\ndx' P[x', y, z] {6[x-x' -'f}G[x', z]] -6[x-x']}\\n\\n-'f}! / dx'dy'dz' / dx'dy'dz'9[x', z]A[x, y, z; x',y', z']\\n\\n1\\n+'i'f}2\\n\\n!\\n\\n+ 'f}, :x\\n\\nEP2P[x, y, z]\\ndx'dy'dz' P[x', y', z']92[x', z'] 8x\\n\\n{xP[x , y, z]}\\n\\n(8)\\n\\n\\fSupervised Learning with Restricted Training Sets\\n\\n239\\n\\nThe complexity of the problem is concentrated in a Green's function:\\nA[x, y, Zj x', y', z'] = lim\\nN-+oo\\n\\n(( ([1-6ee , ]6[x-J?e]6[y-B*?e]6[z-B?e] (e?e')6[x' -J?e']6[y' - B*?e']6[y' - B?e'])i?i> )QW;t\\n\\nJ\\n\\nIt involves a conditional average of the form (K[J])QW;t = dJ Pt(JIQ,R,P)K[J], with\\nPt(J) 6[Q-Q[J]]6[R- R[J]] nXYZ 6[P[x, y, z] -P[x, y, Zj J]]\\nPt(JIQ,R,P)\\nJdJ Pt(J) 6[Q - Q[J]]6[R- R[J]] nXYZ 6[P[x, y, z] - P[x, y, z; J]]\\n\\n=\\n\\nin which Pt (J) is the weight probability density at time t. The solution of (6,7,8) can be\\nused to generate the N -+ 00 performance measures (4) at any time:\\nEt\\n\\n=/\\n\\ndxdydz P[x, y, z]O[-xz]\\n\\nEg\\n\\n= 11\\\"-1 arccos[RIVQ]\\n\\n(9)\\n\\nExpansion of these equations in powers of\\\"\\\" and retaining only the terms linear in \\\"\\\" gives\\nthe corresponding equations describing batch learning. So far this analysis is exact.\\n\\n4\\n\\nClosure of Macroscopic Laws\\n\\nAs in [6, 5] we close our macroscopic laws (6,7,8) by making the two key assumptions\\nunderlying dynamical replica theory:\\n(i) For N -+ 00 our macroscopic observables obey closed dynamic equations.\\n(ii) These equations are self-averaging with respect to the specific realization of D.\\n\\n(i) implies that probability variations within {Q, R, P} subshells are either absent or irrelevant to the macroscopic laws. We may thus make the simplest choice for Pt (J IQ, R, P):\\nPt(JIQ,R,P) -+ 6[Q-Q[J]] 6[R-R[J]]\\n\\nII 6[P[x,y,z]-P[x,y,ZjJ]]\\n\\n(10)\\n\\nxyz\\n\\nThe procedure (10) leads to exact laws if our observables {Q, R, P} indeed obey closed\\nequations for N -+ 00. It is a maximum entropy approximation if not. (ii) allows us\\nto average the macroscopic laws over all training sets; it is observed in simulations, and\\nproven using the formalism of [4]. Our assumptions (10) result in the closure of (6,7,8),\\nsince now the Green's function can be written in terms of {Q, R, Pl. The final ingredient\\nof dynamical replica theory is doing the average of fractions with the replica identity\\n\\n/ JdJ W[JID]GIJID])\\n\\n\\\\\\n\\nJdJ W[JID]\\n\\n= lim\\nsets\\n\\n/dJ I\\n\\n???\\n\\ndJn (G[J 1 ID]\\n\\nn-+O\\n\\nIT\\n\\nW[JO<ID])sets\\n\\na=1\\n\\nOur problem has been reduced to calculating (non-trivial) integrals and averages. One\\nfinds that P[x, y, z] P[x, zly]P[y] with Ply] (211\\\")-!exp[-!y 21With the short-hands\\nDy = P[y]dy and (f(x, y, z)) = Dydxdz P[x, zly]f(x, y, z) we can write the resulting\\nmacroscopic laws, for the case of output noise (1), in the following compact way:\\n\\n=\\n\\nd\\n\\ndt Q = 2\\\",(V - ,Q)\\n\\n[)\\n\\n[)tP[x,zly] =\\n\\n=\\n\\nJ\\n\\n+ rJ2 Z\\n\\nd\\n\\ndtR = \\\",(W - ,R)\\n\\n(11)\\n\\n1 [)x[)22P[x,zIY]\\na1/dx'P[x',zly] {6[x-x'-\\\",G[x',z]]-6[x-x'] }+2\\\",2Z\\n\\n-\\\",:x {P[x,zly]\\n\\n[U(x-RY)+Wy-,x+[V-RW-(Q-R2)U]~[x,y,z])}\\n\\n(12)\\n\\nwith\\n\\nU = (~[x, y, z]9[x, z]),\\n\\nv = (x9[x, z]),\\n\\nW = (y9[x, z]),\\n\\nZ = (9 2[x, z])\\n\\nThe solution of (12) is at any time of the following form:\\n\\nP[x,zly]\\n\\n= (1-,x)6[y-z]P+[xly] + ,x6[y+z]P-[xly]\\n\\n(13)\\n\\n\\fA. C. C. Coolen and C. W. H. Mace\\n\\n240\\n\\nFinding the function <I> [x, y, z] (in replica symmetric ansatz) requires solving a saddle-point\\nproblem for a scalar observable q and two functions M?[xly]. Upon introducing\\n\\nB = . . :. V. .,. .q.,-Q___R,-2\\nQ(I-q)\\n(with Jdx M?[xly]\\n\\nJdx M?[xly]eBxs J[x, y]\\nJdx M?[xly]eBxs\\n\\n(f[x, y])? =\\n*\\n\\n= 1 for all y) the saddle-point equations acquire the fonn\\np?[Xly] =\\n\\nfor all X, y :\\n\\n((x-Ry)2) + (qQ-R 2)[I-!:.]\\na\\n\\n!\\n\\nDs (O[X -xl);\\n\\n2 !DYDS S[(I-A)(X); + A(X);]\\n= qQ+Q-2R\\n..jqQ_R2\\n\\n(14)\\n(15)\\n\\nThe equations (14) which detennine M?[xly] have the same structure as the corresponding\\n(single) equation in [5, 6], so the proofs in [5, 6] again apply, and the solutions M?[xly],\\ngiven a q in the physical range q E [R2/Q, 1], are unique. The function <I> [x, y, z] is then\\ngiven by\\n<I> [X,\\n\\ny, z]\\n\\n=!\\n\\nDs s\\n{(I-A)O[Z-y](o[X -x)); + AO[Z+Y](o[X -xl);}\\n..jqQ_R2 P[X, zly]\\n(16)\\n\\nWorking out predictions from these equations is generally CPU-intensive, mainly due to\\nthe functional saddle-point equation (14) to be solved at each time step. However, as in [7]\\none can construct useful approximations of the theory, with increasing complexity:\\n\\n(i) Large a approximation (giving the simplest theory, without saddle-point equations)\\n(ii) Conditionally Gaussian approximation for M[xly] (with y-dependent moments)\\n(iii) Annealed approximation of the functional saddle-point equation\\n\\n5 Benchmark Tests: The Limits a --+ 00 and ,\\\\ --+ 0\\nWe first show that in the limit a --+ 00 our theory reduces to the simple (Q, R) formalism\\nof infinite training sets, as worked out for noisy teachers in [12]. Upon making the ansatz\\n\\np?[xly] = P[xly] = [27r(Q-R 2)]-t e- t [x- Rv]2/(Q-R 2)\\n\\n(17)\\n\\none finds\\n\\n<I>[x,y,Z] = (x-Ry)/(Q-R 2)\\n\\nM?[xly] = P[xly],\\n\\nInsertion of our ansatz into (12), followed by rearranging of terms and usage of the above\\nexpression for <I> [x, y, z], shows that (12) is satisfied. The remaining equations (11) involve\\nonly averages over the Gaussian distribution (17), and indeed reduce to those of [12]:\\n\\n~! Q =\\n\\n(I-A) { 2(x9[x, y))\\n1 d\\n--d R\\n1} t\\n\\n+ 1}{92[x, y)) } + A {2(x9[x,-y)) + 1}(92[x,-y)) } - 2,Q\\n\\n= (I-A)(y9[x,y)) + A(y9[x,-yl) -,R\\n\\nNext we turn to the limit A --+ 0 (restricted training sets & noise-free teachers) and show that\\nhere our theory reproduces the fonnalism of [6,5]. Now we make the following ansatz:\\n\\nP+[xly] = P[xly],\\n\\nP[x, zly]\\n\\n= o[z-y]P[xIY]\\n\\n(18)\\n\\nInsertion shows that for A = 0 solutions of this fonn indeed solve our equations, giving\\n<p[x, y, z]--+ <I> [x, y] and M+[xly]\\nM[xly), and leaving us exactly with the fonnalism\\nof [6, 5] describing the case of noise-free teachers and restricted training sets (apart from\\nsome new tenns due to the presence of weight decay, which was absent in [6, 5]).\\n\\n=\\n\\n\\f241\\n\\nSupervised Learning with Restricted Training Sets\\n0. , r------~--__,\\n\\n0..4\\n\\n~-------_____I\\n\\n0..4\\n\\n11>=0.'\\n\\n0..3\\n\\na=4\\n\\n0. ,\\n\\n0..0.\\n\\n--\\n\\n, 0.\\n\\n0.2\\n\\n_ __ ___ _____ _\\n\\na= 1\\n\\n0;=1\\n\\n------- ---- -- --- -\\n\\n0.\\n\\n0;=2\\n\\n=-=\\n-\\n\\n0;=2\\n\\n- - ----- -\\n\\na=4\\na=4\\n\\n= =-=\\n--=-=--=-=--=-=-=-- -=-=-_oed\\n\\na=4\\n\\n,\\n\\n0;=2\\n\\n':::::========:::j\\n\\n0..3\\n\\n-- - ----\\n\\n0;=1\\n\\n:::---- - -----1\\n\\n0;=2\\n\\n0..2\\n\\n11>=0.'\\n\\n~-------~\\n\\n0;=1\\n\\n0.,\\n\\n11>=0,\\n\\n\\\"\\n\\n,\\n\\nno. I\\n\\n0.\\n\\n, 0.\\n\\n\\\"\\n\\nFigure 1: On-line Hebbian learning: conditionally Gaussian approximation versus exact\\nsolution in [9] (.,., = 1, ,X = 0.2). Left: \\\"I = 0.1, right: \\\"I = 0.5. Solid lines: approximated\\ntheory, dashed lines: exact result. Upper curves: Eg as functions of time (here the two\\ntheories agree), lower curves: E t as functions of time.\\n\\n6\\n\\nBenchmark Tests: Hebbian Learning\\n\\nThe special case of Hebbian learning, i.e. Q[x, z] = sgn(z), can be solved exactly at any\\ntime, for arbitrary {a, ,x, \\\"I} [9], providing yet another excellent benchmark for our theory.\\nFor batch execution of Hebbian learning the macroscopic laws are obtained upon expanding\\n(11,12) and retaining only those terms which are linear in.,.,. All integrations can now be\\ndone and all equations solved explicitly, resulting in U =0, Z = 1, W = (I-2,X)J2/7r, and\\n\\nQ\\n\\n= Qo e-2rryt +\\n\\n2Ro(I-2'x) e-17\\\"Yt[I_e-rrrt]\\n\\\"I\\n\\nf{ + [~(I-2,X)2+.!.]\\n\\nV:;\\n\\n7r\\n\\na\\n\\n[I-e- 17 \\\"Y tF\\n\\\"12\\n\\nR = Ro e- 17\\\"Y t +(I-2'x)J2/7r[I-e- 17\\\"Y t ]/\\\"I\\nq = [aR2+(I_e- 17\\\"Yt)2 i'l]/aQ\\np?[xIY] = [27r(Q-R2)] -t e-tlz-RH sgn(y)[1-e-\\\"..,t]/a\\\"Y]2/(Q-R2)\\n(19)\\nFrom these results, in tum, follow the performance measures Eg = 7r- 1 arccos[ R/ JQ) and\\n\\nE = ! - !(1-,X)!D\\n2\\n\\nt\\n\\n2\\n\\nerf[IYIR+[I-e- 77\\\"Y t ]/a\\\"l] + !,X!D erf[IYIR-[I-e- 17\\\"Y t ]/a\\\"l]\\nY\\nJ2(Q-R2)\\n2\\ny\\nJ2(Q-R2)\\n\\nComparison with the exact solution, calculated along the lines of [9] or, equivalently, obtained upon putting t ?\\nin [9], shows that the above expressions are all exact.\\n\\n.,.,-2\\n\\nFor on-line execution we cannot (yet) solve the functional saddle-point equation in general.\\nHowever, some analytical predictions can still be extracted from (11,12,13):\\n\\nQ = Qo e-217\\\"Yt + 2Ro(I-2,X) e-77\\\"Yt[I_e-17\\\"Yt]\\n\\\"I\\n\\nR = Ro e- 17\\\"Y t + (I-2,X)J2/7r[I-e- 17\\\"Y t ]/\\\"I\\n\\nJ\\n\\nf{ + [~(I-2,X)2+.!.]\\n\\nV:;\\n\\n7r\\n\\na\\n\\n[I_e- 17\\\"Y t ]2\\n\\\"12\\n\\n+ !L[I_e- 217\\\"Y t ]\\n2\\\"1\\n\\ndx xP?[xIY] = Ry ? sgn(y)[I-e- 17\\\"Y t ]/a\\\"l\\n\\nwith U =0, W = (I-2,X)J2/7r, V = W R+[I-e- 17\\\"Y t ]/a\\\"l, and Z = 1. Comparison with the\\nresults in [9] shows that the above expressions, and thus also that of E g , are all fully exact,\\nat any time. Observables involving P[x, y, z] (including the training error) are not as easily\\nsolved from our equations. Instead we used the conditionally Gaussian approximation\\n(found to be adequate for the noiseless Hebbian case [5, 6, 7]). The result is shown in\\nfigure 1. The agreement is reasonable, but significantly less than that in [6]; apparently\\nteacher noise adds to the deformation of the field distribution away from a Gaussian shape.\\n\\n\\f242\\n\\nA. C. C. Coolen and C. W H. Mac\\n\\n~\\n\\n0.6\\n\\n000000\\n\\n0.4\\n\\n0.4\\n\\nE\\n\\n~\\n\\n0.2\\n\\nI\\ni\\n0.0\\n\\n0\\n\\n4\\n\\n2\\n\\n6\\n\\n10\\n\\n0.0\\n\\n-3\\n\\n-2\\n\\n-I\\n\\n0\\nX\\n\\n0.6\\n\\nf\\n\\n0.4\\n\\n0.4 [\\n\\nE\\n0.2\\n\\n0.2\\n\\n0.0\\n\\nL-o!i6iIII.\\\"\\\"\\\"\\\"\\\"',-\\\"--~_~~_ _--'\\n\\n-3\\n\\n-2\\n\\n-I\\n\\n0\\n\\n2\\n\\n3\\n\\nX\\n\\n,=\\n\\nFigure 2: Large a approximation versus numerical simulations (with N = 10,000), for\\n0 and A = 0.2. Top row: Perceptron rule, with.,., = ~. Bottom row: Adatron rule,\\nwith.,., = ~. Left: training errors E t and generalisation errors Eg as functions of time, for\\naE {~, 1, 2}. Lines: approximated theory, markers: simulations (circles: E t , squares: Eg) .\\nRight: joint distributions for student field and teacher noise p?[x] = dy P[x, y, z = ?y]\\n(upper: P+[x], lower: P-[x]). Histograms: simulations, lines: approximated theory.\\n\\nJ\\n\\n7\\n\\nNon-Linear Learning Rules: Theory versus Simulations\\n\\nIn the case of non-linear learning rules no exact solution is known against which to test our\\nformalism, leaving numerical simulations as the yardstick. We have evaluated numerically\\nthe large a approximation of our theory for Perceptron learning, 9[x, z] = sgn(z)O[-xz],\\nand for Adatron learning, 9[x, z] = sgn(z)lzIO[-xz]. This approximation leads to the\\nfollowing fully explicit equation for the field distributions:\\n\\n1/\\n\\nd\\n-p?[xly]\\n= dt\\na\\n.\\n\\nWith\\n\\nU=\\n\\n' +1\\n\\ndx' p?[x'ly]{o[x-x'-.,.,.1'[x', ?y]] -o[x-x]}\\n\\n_ ~ {P[ I ] [W _\\n.,., 8\\nx y\\ny\\n\\nJ\\n\\nX\\n\\n~ p?[xly]\\n\\n_.,.,2 Z!:I 2\\n2\\nuX\\n\\n,X + U[X?(y)-RY]+(V-RW)[X-X?(y)]]}\\nQ _ R2\\n\\nDydx {(I-A)P+[xly][x-P(y)]9[x,Y]+AP-[xly][x-x-(y)]9[x,-y])\\nV =\\nW=\\nZ=\\n\\n!\\n1\\n1\\n\\nDydx x {(I-A)P+[xly]9[x, Y]+AP-[xly]9[x,-y])\\nDydx y {(1-A)P+[xly]9[x, Y]+AP-[xly]9[x,-y])\\n\\nDydx {(I-A)P+[xly]92[x, Y]+AP-[xly]9 2[x,-yJ)\\n\\n\\fSupervised Learning with Restricted Training Sets\\n\\n243\\n\\nJ\\n\\nand with the short-hands X?(y) = dx xP?[xly). The result of our comparison is shown\\nin figure 2. Note: E t increases monotonically with a, and Eg decreases monotonically\\nwith a, at any t. As in the noise-free formalism [7], the large a approximation appears to\\ncapture the dominant terms both for a -7 00 and for a -7 O. The predicting power of our\\ntheory is mainly limited by numerical constraints. For instance, the Adatron learning rule\\ngenerates singularities at x = 0 in the distributions P?[xly) (especially for small \\\"I) which,\\nalthough predicted by our theory, are almost impossible to capture in numerical solutions.\\n\\n8 Discussion\\nWe have shown how a recent theory to describe the dynamics of supervised learning with\\nrestricted training sets (designed to apply in the data recycling regime, and for arbitrary online and batch learning rules) [5, 6, 7] in large layered neural networks can be generalized\\nsuccessfully in order to deal also with noisy teachers. In our generalized approach the joint\\ndistribution P[x, y, z) for the fields of student, 'clean' teacher, and noisy teacher is taken to\\nbe a dynamical order parameter, in addition to the conventional observables Q and R. From\\nthe order parameter set {Q, R, P} we derive the generalization error Eg and the training\\nerror E t . Following the prescriptions of dynamical replica theory one finds a diffusion\\nequation for P[x, y, z], which we have evaluated by making the replica-symmetric ansatz.\\nWe have carried out several orthogonal benchmark tests of our theory: (i) for a -7 00 (no\\ndata recycling) our theory is exact, (ii) for A -7 0 (no teacher noise) our theory reduces\\nto that of [5, 6, 7], and (iii) for batch Hebbian learning our theory is exact. For on-line\\nHebbian learning our theory is exact with regard to the predictions for Q, R, Eg and the\\ny-dependent conditional averages Jdx xP?[xly), at any time, and a crude approximation\\nof our equations already gives reasonable agreement with the exact results [9] for E t . For\\nnon-linear learning rules (Perceptron and Adatron) we have compared numerical solution\\nof a simple large a aproximation of our equations to numerical simulations, and found\\nsatisfactory agreement. This paper is a preliminary presentation of results obtained in the\\nsecond stage of a research programme aimed at extending our theoretical tools in the arena\\nof learning dynamics, building on [5, 6, 7]. Ongoing work is aimed at systematic application of our theory and its approximations to various types of non-linear learning rules, and\\nat generalization of the theory to multi-layer networks.\\n\\nReferences\\n[1]\\n[2]\\n[3]\\n[4]\\n[5]\\n[6]\\n[7]\\n[8]\\n[9]\\n[10]\\n[11]\\n[12]\\n\\nMace C.W.H. and Coolen AC.C (1998), Statistics and Computing 8, 55\\nSaad D. (ed.) (1998), On-Line Learning in Neural Networks (Cambridge: CUP)\\nHertz J.A., Krogh A and Thorgersson G.I. (1989), J. Phys. A 22, 2133\\nHomerH. (1992a), Z. Phys. B 86, 291 and Homer H. (1992b), Z. Phys. B 87,371\\nCoolen A.C.C. and Saad D. (1998), in On-Line Learning in Neural Networks, Saad\\nD. (ed.), (Cambridge: CUP)\\nCoolen AC.C. and Saad D. (1999), in Advances in Neural Information Processing\\nSystems 11, Kearns D., Solla S.A., Cohn D.A (eds.), (MIT press)\\nCoolen A.C.C. and Saad D. (1999), preprints KCL-MTH-99-32 & KCL-MTH-99-33\\nRae H.C., Sollich P. and Coolen AC.C. (1999), in Advances in Neural Information\\nProcessing Systems 11, Kearns D., Solla S.A., Cohn D.A. (eds.), (MIT press)\\nRae H.C., Sollich P. and Coolen AC.C. (1999),J. Phys. A 32, 3321\\nInoue J.I. (1999) private communication\\nWong K.YM., Li S. and Tong YW. (1999),preprint cond-mat19909004\\nBiehl M., Riegler P. and Stechert M. (1995), Phys. Rev. E 52, 4624\\n\\n\\f\",\n          \"Predicting Action Content On-Line and in\\nReal Time before Action Onset ? an\\nIntracranial Human Study\\n\\nShengxuan Ye\\nCalifornia Institute of Technology\\nPasadena, CA\\nsye@caltech.edu\\n\\nUri Maoz\\nCalifornia Institute of Technology\\nPasadena, CA\\nurim@caltech.edu\\nIan Ross\\nHuntington Hospital\\nPasadena, CA\\nianrossmd@aol.com\\n\\nAdam Mamelak\\nCedars-Sinai Medical Center\\nLos Angeles, CA\\nadam.mamelak@cshs.org\\n\\nChristof Koch\\nCalifornia Institute of Technology\\nPasadena, CA\\nAllen Institute for Brain Science\\nSeattle, WA\\nkoch@klab.caltech.edu\\n\\nAbstract\\nThe ability to predict action content from neural signals in real time before the action occurs has been long sought in the neuroscientific study of decision-making,\\nagency and volition. On-line real-time (ORT) prediction is important for understanding the relation between neural correlates of decision-making and conscious,\\nvoluntary action as well as for brain-machine interfaces. Here, epilepsy patients,\\nimplanted with intracranial depth microelectrodes or subdural grid electrodes for\\nclinical purposes, participated in a ?matching-pennies? game against an opponent.\\nIn each trial, subjects were given a 5 s countdown, after which they had to raise\\ntheir left or right hand immediately as the ?go? signal appeared on a computer\\nscreen. They won a fixed amount of money if they raised a different hand than\\ntheir opponent and lost that amount otherwise. The question we here studied was\\nthe extent to which neural precursors of the subjects? decisions can be detected in\\nintracranial local field potentials (LFP) prior to the onset of the action.\\nWe found that combined low-frequency (0.1?5 Hz) LFP signals from 10 electrodes\\nwere predictive of the intended left-/right-hand movements before the onset of the\\ngo signal. Our ORT system predicted which hand the patient would raise 0.5 s\\nbefore the go signal with 68?3% accuracy in two patients. Based on these results,\\nwe constructed an ORT system that tracked up to 30 electrodes simultaneously,\\nand tested it on retrospective data from 7 patients. On average, we could predict\\nthe correct hand choice in 83% of the trials, which rose to 92% if we let the system\\ndrop 3/10 of the trials on which it was less confident. Our system demonstrates?\\nfor the first time?the feasibility of accurately predicting a binary action on single\\ntrials in real time for patients with intracranial recordings, well before the action\\noccurs.\\n\\n1\\n\\n\\f1\\n\\nIntroduction\\n\\nThe work of Benjamin Libet [1, 2] and others [3, 4] has challenged our intuitive notions of the relation between decision making and conscious voluntary action. Using electrocorticography (EEG),\\nthese experiments measured brain potentials from subjects that were instructed to flex their wrist at a\\ntime of their choice and note the position of a rotating dot on a clock when they felt the urge to move.\\nThe results suggested that a slow cortical wave measured over motor areas?termed ?readiness potential? [5], and known to precede voluntary movement [6]?begins a few hundred milliseconds before the average reported time of the subjective ?urge? to move. This suggested that action onset and\\ncontents could be decoded from preparatory motor signals in the brain before the subject becomes\\naware of an intention to move and of the contents of the action. However, the readiness potential\\nwas computed by averaging over 40 or more trials aligned to movement onset after the fact. More\\nrecently, it was shown that action contents can be decoded using functional magnetic-resonance\\nimaging (fMRI) several seconds before movement onset [7]. But, while done on a single-trial basis,\\ndecoding the neural signals took place off-line, after the experiment was concluded, as the sluggish\\nnature of fMRI hemodynamic signals precluded real-time analysis. Moreover, the above studies\\nfocused on arbitrary and meaningless action?purposelessly raising the left or right hand?while\\nwe wanted to investigate prediction of reasoned action in more realistic, everyday situations with\\nconsequences for the subject.\\nIntracranial recordings are good candidates for single-trial, ORT analysis of action onset and contents [8, 9], because of the tight temporal pairing of LFP to the underlying neuronal signals. Moreover, such recordings are known to be cleaner and more robust, with signal-to-noise ratios up to\\n100 times larger than surface recordings like EEG [10, 11]. We therefore took advantage of a rare\\nopportunity to work with epilepsy patients implanted with intracranial electrodes for clinical purposes. Our ORT system (Fig. 1) predicts, with far above chance accuracy, which one of two future\\nactions is about to occur on this one trial and feeds the prediction back to the experimenter, all\\nbefore the onset of the go signal that triggers the patient?s movement (see Experimental Methods).\\nWe achieve relatively high prediction performance using only part of the data?learning from brain\\nactivity in past trials only (Fig. 2) to predict future ones (Fig. 3)?while still running the analysis\\nquickly enough to act upon the prediction before the subject moved.\\n\\n2\\n2.1\\n\\nExperimental Methods\\nSubjects\\n\\nSubjects in this experiment were 8 consenting intractable epilepsy patients that were implanted with\\nintracranial electrodes as part of their presurgical clinical evaluation (ages 18?60, 3 males). They\\nwere inpatients in the neuro-telemetry ward at the Cedars Sinai Medical Center or the Huntington\\nMemorial Hospital, and are designated with CS or HMH after their patient numbers, respectively. Six\\nof them?P12CS, P15CS, P22CS and P29?31HMH were implanted with intracortical depth electrodes targeting their bilateral anterior-cingulate cortex, amygdala, hippocampus and orbitofrontal\\ncortex. These electrodes had eight 40 ?m microwires at their tips, 7 for recording and 1 serving as\\na local ground. Two patients, P15CS and P22CS, had additional microwires in the supplementary\\nmotor area. We utilized the LFP recorded from the microwires in this study. Two other patients,\\nP16CS and P19CS, were implanted with an 8?8 subdural grid (64 electrodes) over parts of their\\ntemporal and prefrontal dorsolateral cortices. The data of one patient?P31HMH?was excluded\\nbecause microwire signals were too noisy for meaningful analysis. The institutional review boards\\nof Cedars Sinai Medical Center, the Huntington Memorial Hospital and the California Institute of\\nTechnology approved the experiments.\\nDuring the experiment, the subject sat in a hospital bed in a semi-inclined ?lounge chair? position.\\nThe stimulus/analysis computer (bottom left of Fig. 4) displaying the game screen (bottom right\\ninset of Fig. 4) was positioned to be easily viewable for the subject. When playing against the\\nexperimenter, the latter sat beside the bed. The response box was placed within easy reach of the\\nsubject (Fig. 4).\\n2\\n\\n\\f2.2\\n\\nExperiment Design\\n\\nAs part of our focus on purposeful, reasoned action, we had the subjects play a matching-pennies\\ngame?a 2-choice version of ?rock paper scissors??either against the experimenter or against a\\ncomputer. The subjects pressed down a button with their left hand and another with their right on a\\nresponse box. Then, in each trial, there was a 5 s countdown followed by a go signal, after which\\nthey had to immediately lift one of their hands. It was agreed beforehand that the patient would win\\nthe trial if she lifted a different hand than her opponent, and lose if she raised the same hand as her\\nopponent. Both players started off with a fixed amount of money, $5, and in each trial $0.10 was\\ndeducted from the loser and awarded to the winner. If a player lifted her hand before the go signal,\\ndid not lift her hand within 500 ms of the go signal, or lifted no hand or both hands at the go signal?\\nan error trial?she lost $0.10 without her opponent gaining any money. The subjects were shown the\\ncountdown, the go signal, the overall score, and various instructions on a stimulus computer placed\\nbefore them (Fig. 4). Each game consisted of 50 trials. If, at the end of the game, the subject had\\nmore money than her opponent, she received that money in cash from the experimenter.\\nBefore the experimental session began, the experimenter explained the rules of the game to the subject, and she could practice playing the game until she was familiar with it. Consequently, patients\\nusually made only few errors during the games (<6% of the trials). Following the tutorial, the subject played 1?3 games against the computer and then once against the experimenter, depending on\\ntheir availability and clinical circumstances. The first 2 games of P12CS were removed because\\nthe subject tended to constantly raise the right hand regardless of winning or losing. Two patients,\\nP15CS and P19CS, were tested in actual ORT conditions. In such sessions?3 games each?the\\nsubjects always played against the experimenter. These ORT games were different from the other\\ngames in two respects. First, a computer screen was placed behind the patient, in a location where\\nshe could not see it. Second, the experimenter was wearing earphones (Fig. 1,4). Half a second before go-signal onset, an arrow pointing towards the hand that the system predicted the experimenter\\nhad to raise to win the trial was displayed on that screen. Simultaneously, a monophonic tone was\\nplayed in the experimenter?s earphone ipsilateral to that hand. The experimenter then lifted that hand\\nat the go signal (see Supplemental Movie).\\n\\nCheetah Machine\\nCollect\\nand save\\ndata\\n\\nPatient\\nwith intracranial electrodes\\n\\nDown\\nsampling\\n\\nBuffer\\n\\n1Gbps\\nRouter\\n\\nTTL Signal\\n\\nThe winner is\\nPlayer 1\\nPLAYER 1 PLAYER 2\\nSCORE 1\\n\\nAnalysis/stimulus machine\\n\\nSCORE 2\\n\\nResponse Box Game Screen\\n\\n/\\nExperimenter\\n\\nResult\\nInterpreta\\ntion\\n\\nAnalysis\\n\\nFiltering\\n\\nDisplay/Sound\\n\\nFigure 1: A schematic diagram of the on-line real-time (ORT) system. Neural signals flow from\\nthe patient through the Cheetah machine to the analysis/stimulus computer, which controls the input\\nand output of the game and computes the prediction of the hand the patient would raise at the go\\nsignal. It displays it on a screen behind the patient and informs the experimenter which hand to raise\\nby playing a tone in his ipsilateral ear using earphones.\\n\\n3\\n\\n\\f3\\n3.1\\n\\nThe real-time system\\nHardware and software overview\\n\\n?V\\n\\n?V\\n\\n?V\\n\\nNeural data from the intracranial electrodes were transferred to a recording system (Neuralynx,\\nDigital Lynx), where it was collected and saved to the local Cheetah machine, down sampled\\nfrom 32 kHz to 2 kHz and buffered. The data were then transferred, through a dedicated 1 Gbps\\nlocal-area network, to the analysis/stimulus machine. This computer first band-pass-filtered the\\ndata to the 0.1?5 Hz range (delta and lower theta bands) using a second-order zero-lag elliptic\\nfilter with an attenuation of 40 dB (cf. Figs. 2a and 2b). We found that this frequency range?\\ngenerally comparable to that of the readiness potential?resulted in optimal prediction performance.\\nIt then ran the analysis algorithm (see below) on the filtered data. This computer also controlled\\nthe game screen, displaying the names of the players, their current scores and various instructions.\\nThe analysis/stimulus computer further\\ncontrolled the response box, which con- (a)\\n800\\nsisted of 4 LED-lit buttons. The buttons of the subject and her opponent\\n600\\nflashed red or blue whenever she or her\\n?5\\n?4\\n?3\\n?2\\n?1\\n0\\nopponent won, respectively. Addition(b)100\\nally, the analysis/stimulus computer sent\\n0\\na unique transistor-transistor logic (TTL)\\n?100\\n?200\\npulse whenever the game screen changed\\n?5\\n?4\\n?3\\n?2\\n?1\\n0\\nor a button was pressed on the response\\nbox, which synchronized the timing of (c) 100\\n0\\nthese events with the LFP recordings.\\n?100\\nIn real-time game sessions, the analy?200\\n?5\\n?4\\n?3\\n?2\\n?1\\n0\\nsis/stimulus computer also displayed the\\nappropriate arrow on the computer screen (d) 1\\nbehind the subject and played the tone\\n0\\nto the appropriate ear of the experimenter\\n?1\\n0.5 s before go-signal onset (Figs. 1,4).\\n?5\\n?4\\n?3\\n?2\\n?1\\n0\\nThe analysis software was based on a\\nmachine-learning algorithm that trained\\non past-trials data to predict the current\\ntrial and is detailed below. The training phase included the first 70% of the\\ntrials, with the prediction carried out on\\nthe remaining 30% using the trained parameters, together with an online weighting system (see below). The system examined only neural activity, and had no\\naccess to the subject?s left/right-choice\\nhistory. After filtering all the training\\ntrials (Fig. 2b), the system found the\\nmean and standard error over all leftward\\nand rightward training trials, separately\\n(Fig. 2c, left designated in red). It then\\nfound the electrodes and time windows\\nwhere the left/right separation was high\\n(Fig. 2d,e; see below), and trained the classifiers on these time windows (Fig. 2f?g).\\nThe best electrode/time-window/classifier\\n(ETC) combinations were then used to\\npredict the current trial in the prediction\\nphase (Fig. 3). The number of ETCs that\\ncan be actively monitored is currently limited to 10 due to the computational power\\nof the real-time system.\\n\\nEl 49?T1\\n\\n(e)\\n\\nEl 49?T2\\n\\nEl 49?T3\\n\\n1\\n0\\n?1\\n?5\\n\\n?4\\n\\n?3\\n?2\\n?1\\nCountdown to go signal at t=0 (seconds)\\n\\n0\\n\\n(f)\\nClassifier\\nCf1\\n\\nClassifier\\nCf2\\n\\n...\\n\\nClassifier\\nCf6\\n\\nEl 49?T1?Cf1\\nEl 49?T1?Cf2\\nEl 49?T1?Cf6\\n...\\nEl 49?T2?Cf1\\nEl 49?T2?Cf2\\nEl 49?T2?Cf6\\nEl 49?T3?Cf1\\nEl 49?T3?Cf2\\nEl 49?T3?Cf6\\n\\n(g)\\nCombination\\nEl49-T1-Cf2\\n\\nCombination\\nEl49-T2-Cf2\\n\\n...\\n\\nCombination\\nEl49-T2-Cf6\\n\\nFigure 2: The ORT-system?s training phase. Left (in\\nred) and right (in blue) raw signals (a) are low-pass filtered (b). Mean?standard errors of signals preceeding left- and right-hand movments (c) are used to compute a left/right separability index (d), from which time\\nwindows with good separation are found (e). Seven\\nclassifiers are then applied to all the time windows (f)\\nand the best electrode/time-window/classifier combinations are selected (g) and used in the prediction phase\\n(Fig. 3).\\n\\n4\\n\\n\\f?V\\n\\n100\\n0\\n?100\\n?200\\n?5\\n\\n?4\\n\\n?3\\n\\n?2\\n\\n?1\\n\\n0\\n\\nTrained classifiers\\n\\nCombination\\nE l 49?T1?Cf2\\n\\nCombination\\nE l 49?T2?Cf2\\n\\nWeight = 1\\n\\nWeight = 1\\n\\nCombination\\nE l 49?T2?Cf6\\n\\n&\\n\\nWeight = 1\\n\\nPredicted result\\nL\\n\\nL\\n\\nL\\n\\nL\\n\\nL\\n\\nR\\n\\nL\\n\\n&\\n\\nR\\n\\nL\\nReal result\\n\\nAdjust the weights\\n\\nL\\n\\n==\\n\\nFigure 3: The ORT-system?s prediction phase. A new signal?from 5 to 0.5 seconds before the\\ngo signal?is received in real time, and each electrode/time-window/classifier combination (ETC)\\nclassifies it as resulting in left- or right-hand movement. These predictions are then compared to the\\nactual hand movement, with the weights associated with ETCs that correctly (incorrectly) predicted\\nincreasing (decreasing).\\n\\n3.2\\n\\nComputing optimal left/right-separating time windows\\n\\nThe algorithm focused on finding the time windows with the best left/right separation for the different recording electrodes over the training set (Fig. 2c?e). That is, we wanted to predict whether\\nthe signal aN (t) on trial N will result in a leftward or rightward movement?i.e., whether the label of the N th trial will be Lt or Rt, respectively. For each electrode, we looked at the N ? 1\\nprevious trials a1 (t), a2 (t), . . . , aN ?1 (t), and their associated labels as l1 , l2 , . . . , lN ?1 . Now, let\\nN ?1\\n?1\\nL(t) = {ai (t) | li = Lt}N\\ni=1 and R(t) = {ai (t) | li = Rt}i=1 be the set of previous leftward and\\nrightward trials in the training set, respectively. Furthermore, let Lm (t) (Rm (t)) and Ls (t) (Rs (t))\\nbe the mean and standard error of L(t) (R(t)), respectively. We can now define the normalized\\nrelative left/right separation for each electrode at time t (see Fig. 2d):\\n?\\n[Lm (t) ? Ls (t)] ? [Rm (t) + Rs (t)]\\n?\\n?\\nif [Lm (t) ? Ls (t)] ? [Rm (t) + Rs (t)] > 0\\n?\\n?\\nLm (t) ? Rm (t)\\n?\\n?\\n?\\n?\\n?\\n[Rm (t) ? Rs (t)] ? [Lm (t) + Ls (t)]\\n?(t) =\\n?\\nif [Rm (t) ? Rs (t)] ? [Lm (t) + Ls (t)] > 0\\n?\\n?\\n?\\nRm (t) ? Lm (t)\\n?\\n?\\n?\\n?\\n?\\n?\\n0\\notherwise\\nThus, ?(t) > 0 (?(t) < 0) means that the leftward trials tend to be considerably higher (lower)\\nthan rightward trials for that electrode at time t, while ?(t) = 0 suggests no left/right separation at\\ntime t. We define a consecutive time period of |?(t)| > 0 for t < prediction time (the time before\\nthe go signal when we want the system to output a prediction; -0.5 s for the ORT trials) as a time\\nwindow (Fig. 2e). After all time windows are found for all electrodes, time windows lessRthan M ms\\nt\\napart are combined into one. Then, for each time window from t1 to t2 we define a = t12 |?(t)|dt.\\nWe then eliminate all time windows satisfying a < A. We found the values M = 200 ms and\\nA = 4, 500 ?V ? ms to be optimal for real-time analysis. This resulted in 20?30 time windows over\\nall 64 electrodes that we monitored.\\n5\\n\\n\\f1\\n$4.80\\n\\n$5.20\\n\\nP15CS\\n\\nUri\\n\\nFigure 4: The experimental setup in the clinic. At 400 ms before the go signal, the patient and\\nexperimenter are watching the game screen (inset on bottom right) on the analysis/stimulus computer\\n(bottom left) and still pressing down the buttons of the response box. The realtime system already\\ncomputed a prediction, and thus displays an arrow on the screen behind the patient and plays a tone\\nin the experimenter?s ear ipsilateral to the hand it predicts he should raise to beat the patient (see\\nSupplemental Movie).\\n3.3\\n\\nClassifiers selection and ETC determination\\n\\nWe used ensemble learning with 7 types of relatively simple binary classifiers (due to real-time\\nprocessing considerations) on every electrode?s time windows (Fig. 2f). Classifiers A to G would\\nclassify aN (t) as Lt if:\\nP\\nP\\nP\\n(A) Defining aN,M , Lm,M and Rm,M as aN (t), Lm (t) and Rm (t) over time window M ,\\n\\u0001\\n\\u0001\\n\\u0001\\n(i) sign Rm,M 6= sign aN,M = sign Lm,M , or\\n\\f\\n\\f\\n\\f \\f\\n\\u0001\\n\\u0001\\n\\u0001\\n(ii) sign Rm,M = sign aN,M = sign Lm,M and \\fLm,M \\f > \\fRm,M \\f, or\\n\\f\\n\\f\\n\\f \\f\\n\\u0001\\n\\u0001\\n\\u0001\\n(iii) sign Rm (t) 6= sign SN,M 6= sign Lm (t) and \\fLm,M \\f < \\fRm,M \\f;\\n\\f\\n\\u0001\\n\\u0001\\f \\f\\n\\u0001\\n\\u0001\\f\\n(B) \\fmean aN (t) ? mean Lm (t) \\f < \\fmean aN (t) ? mean Rm (t) \\f;\\n\\f\\n\\f\\n\\u0001\\n\\u0001\\f\\n\\u0001\\n\\u0001\\f\\n(C) \\fmedian aN (t) ? median Lm (t) \\f < \\fmedian aN (t) ? median Rm (t) \\f over the time\\nwindow;\\n\\f\\n\\f\\n\\f\\n\\f\\n\\f\\n(D) aN (t) ? Lm (t)\\fL2 < \\faN (t) ? Rm (t)\\fL2 over the time window;\\n(E) aN (t) is convex/concave like Lm (t) while Rm (t) is concave/convex, respectively;\\n(F) Linear support-vector machine (SVM) designates it as so; and\\n(G) k-nearest neighbors (KNN) with Euclidean distance designates it as so.\\nEach classifier is optimized for certain types of features. To estimate how well its classification\\nwould generalize from the training to the test set, we trained and tested it using a 70/30 crossvalidation procedure within the training set. We tested each classifier on every time window of every\\nelectrode, discarding those with accuracy <0.68, which left 12.0 ? 1.6% of the original 232 ? 18\\nETCs, on average (?standard error). The training phase therefore ultimately output a set of S binary\\nETC combinations (Fig. 2g) that were used in the prediction phase (Fig. 3).\\n3.4\\n\\nThe prediction-phase weighting system\\n\\nIn the prediction phase, each of the overall S binary ETCs calculates a prediction, ci ? {?1, 1} (for\\nright and left, respectively), independently at the desired prediction time. All classifiers are initially\\n6\\n\\n\\fPS\\ngiven the same weight, w1 = w2 = ? ? ? = wS = 1. We then calculate ? = i=1 wi ? ci and predict\\nleft (right) if ? > d (? < ?d), or declare it an undetermined trial if ?d < ? < d. Here d is the\\ndrop-off threshold for the prediction. Thus the larger d is, the more confident the system needs to be\\nto make a prediction, and the larger the proportion of trials on which the system abstains?the dropoff rate. Weight wi associated with ETCi is increased (decreased) by 0.1 whenever ETCi predicts\\nthe hand movement correctly (incorrectly). A constantly erring ETC would therefore be associated\\nwith an increasingly small and then increasingly negative weight.\\n3.5\\n\\nImplementation\\n\\nThe algorithm was implemented in MATLAB 2011a (MathWorks, Natick, MA) as well as in C++\\non Visual Studio 2008 (Microsoft, Redmond, WA) for enhanced performance. The neural signals\\nwere collected by the Digital Lynx S system using Cheetah 5.4.0 (Neuralynx, Redmond, WA). The\\nsimulated-ORT system was also implemented in MATLAB 2011a. The simulated-ORT analyses\\ncarried out in this paper used real patient data saved on the Digital Lynx system.\\n1\\n\\n0.9\\n\\nDrop rate:\\nNone\\n0.18\\n0\\u0011\\u0016\\u0013\\n\\nPrediction accuracy\\n\\n0.8\\n\\n0.7\\nSignificant accuracy\\n(p=0.05)\\n0.6\\n\\n0.5\\n\\n?5\\n\\n?4.5\\n\\n?4\\n\\n?3.5\\n\\n?3\\n\\n?2.5\\nTime (s)\\n\\n?2\\n\\n?1.5\\n\\n?1\\n\\n?0.5\\n\\n0\\nGo-signal\\nonset\\n\\nFigure 5: Across-subjects average of the prediction accuracy of simulated-ORT versus time before\\nthe go signal. The mean accuracies over time when the system predicts on every trial, is allowed\\nto drop 19% or 30% of the trials, are depicted in blue, green and red, respectively (?standard error\\nshaded). Values above the dashed horizontal line are significant at p = 0.05.\\n\\n4\\n\\nResults\\n\\nWe tested our prediction system in actual real time on 2 patients?P15CS and P19CS (a depth\\nand grid patient, respectively), with a prediction time of 0.5 s before the go signal (see Supplementary Movie). Because of computational limitations, the ORT system could only track 10\\nelectrodes with just 1 ETC per electrode in real time. For P15CS, we achieved an accuracy of\\n72?2% (?standard error; accuracy = number of accurately predicted trials / [total number of trials - number of dropped trials]; p = 10?8 , binomial test) without modifying the weights online during the prediction (see Section 3.4). For P19CS we did not run patient-specific training of the ORT system, and used parameter values that were good on average over previous patients instead. The prediction accuracy was significantly above chance 63?2% (?standard error; p = 7 ? 10?4 , binomial test). To understand how much we could improve our accuracy\\nwith optimized hardware/software, we ran the simulated-ORT at various prediction times along\\n7\\n\\n\\fAccuracy\\n\\nthe 5 s countdown leading to the go signal. We further tested 3 drop-off rates?0, 0.19 and\\n0.30 (Fig. 5; drop-off rate = number of dropped trials / total number of trials; these resulted\\nfrom 3 drop-off thresholds?0, 0.1 and 0.2?respectively, see Section 3.4:). Running offline,\\nwe were able to track 20?30 ETCs, which resulted in considerably higher accuracies (Figs. 5,6).\\nAveraged over all subjects, the accuracy rose from about 65% more than\\n1\\n4 s before the go signal to 83?92%\\nclose to go-signal onset, depending\\n0.9\\non the allowed drop-off rate. In particular, we found that for a predic0.8\\ntion time of 0.5 s before go-signal\\nonset, we could achieve accuracies\\n0.7\\nof 81?5% and 90?3% (?standard\\nerror) for P15CS and P19CS, re0.6\\nspectively, with no drop off (Fig. 6).\\nPatients:\\nP12CS\\nWe also analyzed the weights that\\nP15CS\\nour weighting system assigned to the\\n0.5\\nP16CS\\nP19CS\\ndifferent ETCs. We found that the\\nP22CS\\nempirical distribution of weights to\\nP29HMH\\n0.4\\nP30HMH\\nETCs associated with classifiers A to\\nG was, on average: 0.15, 0.12, 0.16,\\n?5 ?4.5 ?4 ?3.5 ?3 ?2.5 ?2 ?1.5 ?1 ?0.5 0\\n0.22, 0.01, 0.26 and 0.07, respecTime before go signal (at t=0) (seconds)\\ntively. This suggests that the linear\\nSVM and L2-norm comparisons (of\\naN to Lm and Rm ) together make up Figure 6: Simulated-ORT accuracy over time for individual\\nnearly half of the overall weights at- patients with no drop off.\\ntributed to the classifiers, while the\\ncurrent concave/convex measure is of\\nlittle use as a classifier.\\n\\n5\\n\\nDiscussion\\n\\nWe constructed an ORT system that, based on intracranial recordings, predicted which hand a person would raise well before movement onset at accuracies much greater than chance in a competitive environment. We further tested this system off-line, which suggested that with optimized\\nhardware/software, such action contents would be predictable in real time at relatively high accuracies already several seconds before movement onset. Both our prediction accuracy and drop-off\\nrates close to movement onset are superior to those achieved before movement onset with noninvasive methods like EEG and fMRI [7, 12?14]. Importantly, our subjects played a matching pennies game?a 2-choice version of rock-paper-scissors [15]?to keep their task realistic, with minor\\nthough real consequences, unlike the Libet-type paradigms whose outcome bears no consequences\\nfor the subjects. It was suggested that accurate online, real-time prediction before movement onset\\nis key to investigating the relation between the neural correlates of decisions, their awareness, and\\nvoluntary action [16, 17]. Such prediction capabilities would facilitate many types of experiments\\nthat are currently infeasible. For example, it would make it possible to study decision reversals on\\na single-trial basis, or to test whether subjects can guess above chance which of their action contents are predictable from their current brain activity, potentially before having consciously made up\\ntheir mind [16, 18]. Accurately decoding these preparatory motor signals may also result in earlier\\nand improved classification for brain-computer interfaces [13, 19, 20]. The work we present here\\nsuggests that such ORT analysis might well be possible.\\nAcknowledgements\\nWe thank Ueli Rutishauser, Regan Blythe Towel, Liad Mudrik and Ralph Adolphs for meaningful\\ndiscussions. This research was supported by the Ralph Schlaeger Charitable Foundation, Florida\\nState University?s ?Big Questions in Free Will? initiative and the G. Harold & Leila Y. Mathers\\nCharitable Foundation.\\n8\\n\\n\\fReferences\\n[1] B. Libet, C. Gleason, E. Wright, and D. Pearl. Time of conscious intention to act in relation to\\nonset of cerebral activity (readiness-potential): The unconscious initiation of a freely voluntary\\nact. Brain, 106:623, 1983.\\n[2] B. Libet. Unconscious cerebral initiative and the role of conscious will in voluntary action.\\nBehavioral and brain sciences, 8:529?539, 1985.\\n[3] P. Haggard and M. Eimer. On the relation between brain potentials and the awareness of\\nvoluntary movements. Experimental Brain Research, 126:128?133, 1999.\\n[4] A. Sirigu, E. Daprati, S. Ciancia, P. Giraux, N. Nighoghossian, A. Posada, and P. Haggard.\\nAltered awareness of voluntary action after damage to the parietal cortex. Nature Neuroscience,\\n7:80?84, 2003.\\n[5] H. Kornhuber and L. Deecke. Hirnpotenti?alanderungen bei Willk?urbewegungen und passiven\\nBewegungen des Menschen: Bereitschaftspotential und reafferente Potentiale. Pfl?ugers Archiv\\nEuropean Journal of Physiology, 284:1?17, 1965.\\n[6] H. Shibasaki and M. Hallett. What is the Bereitschaftspotential? Clinical Neurophysiology,\\n117:2341?2356, 2006.\\n[7] C. Soon, M. Brass, H. Heinze, and J. Haynes. Unconscious determinants of free decisions in\\nthe human brain. Nature Neuroscience, 11:543?545, 2008.\\n[8] I. Fried, R. Mukamel, and G. Kreiman. Internally generated preactivation of single neurons in\\nhuman medial frontal cortex predicts volition. Neuron, 69:548?562, 2011.\\n[9] M. Cerf, N. Thiruvengadam, F. Mormann, A. Kraskov, R. Quian Quiorga, C. Koch, and\\nI. Fried. On-line, voluntary control of human temporal lobe neurons. Nature, 467:1104?1108,\\n2010.\\n[10] T. Ball, M. Kern, I. Mutschler, A. Aertsen, and A. Schulze-Bonhage. Signal quality of simultaneously recorded invasive and non-invasive EEG. Neuroimage, 46:708?716, 2009.\\n[11] G. Schalk, J. Kubanek, K. Miller, N. Anderson, E. Leuthardt, J. Ojemann, D. Limbrick,\\nD. Moran, L. Gerhardt, and J. Wolpaw. Decoding two-dimensional movement trajectories\\nusing electrocorticographic signals in humans. Journal of Neural engineering, 4:264, 2007.\\n[12] O. Bai, V. Rathi, P. Lin, D. Huang, H. Battapady, D. Y. Fei, L. Schneider, E. Houdayer, X. Chen,\\nand M. Hallett. Prediction of human voluntary movement before it occurs. Clinical Neurophysiology, 122:364?372, 2011.\\n[13] O. Bai, P. Lin, S. Vorbach, J. Li, S. Furlani, and M. Hallett. Exploration of computational\\nmethods for classification of movement intention during human voluntary movement from\\nsingle trial EEG. Clinical Neurophysiology, 118:2637?2655, 2007.\\n[14] U. Maoz, A. Arieli, S. Ullman, and C. Koch. Using single-trial EEG data to predict laterality\\nof voluntary motor decisions. Society for Neuroscience, 38:289.6, 2008.\\n[15] C. Camerer. Behavioral game theory: Experiments in strategic interaction. Princeton University Press, 2003.\\n[16] J. D. Haynes. Decoding and predicting intentions. Annals of the New York Academy of Sciences, 1224:9?21, 2011.\\n[17] P. Haggard. Decision time for free will. Neuron, 69:404?406, 2011.\\n[18] J. D. Haynes. Beyond libet. In W. Sinnott-Armstrong and L. Nadel, editors, Conscious will\\nand responsibility, pages 85?96. Oxford University Press, 2011.\\n[19] A. Muralidharan, J. Chae, and D. M. Taylor. Extracting attempted hand movements from EEGs\\nin people with complete hand paralysis following stroke. Frontiers in neuroscience, 5, 2011.\\n[20] E. Lew, R. Chavarriaga, S. Silvoni, and J. R. Milln. Detection of self-paced reaching movement\\nintention from EEG signals. Frontiers in Neuroengineering, 5:13, 2012.\\n\\n9\\n\\n\\f\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "from io import BytesIO\n",
        "from zipfile import ZipFile\n",
        "import urllib.request\n",
        "\n",
        "url = urllib.request.urlopen(\"https://github.com/Ali-Alameer/NLP/raw/main/data/NIPS%20Papers.zip\")\n",
        "\n",
        "with ZipFile(BytesIO(url.read())) as my_zip_file:\n",
        "    temp = my_zip_file.open('NIPS Papers/papers.csv')\n",
        "\n",
        "papers = pd.read_csv(temp)\n",
        "\n",
        "# Print head\n",
        "papers.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S06w8sgcz7Fk"
      },
      "source": [
        "Read data into papers, the file can be downloaded from https://github.com/Ali-Alameer/NLP/raw/main/data/NIPS%20Papers.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        },
        "id": "t755sUX4z7Fk"
      },
      "outputs": [],
      "source": [
        "# uncomment below if you have the csv file in your directory\n",
        "\n",
        "# papers = pd.read_csv('papers.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        },
        "id": "LLZDiaYxz7Fl"
      },
      "outputs": [],
      "source": [
        "# uncomment below if you have the xls file in your directory\n",
        "\n",
        "# !pip install --upgrade xlrd\n",
        "# papers = pd.read_excel('savedrecs.xls')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "vscode": {
          "languageId": "python"
        },
        "id": "CbogKaqmz7Fl",
        "outputId": "98062281-ca34-4715-8fda-32e4dbc9300b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [id, year, title, event_type, pdf_name, abstract, paper_text]\n",
              "Index: []"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0c85eddc-daa4-45aa-a01b-6abec26e94c5\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>year</th>\n",
              "      <th>title</th>\n",
              "      <th>event_type</th>\n",
              "      <th>pdf_name</th>\n",
              "      <th>abstract</th>\n",
              "      <th>paper_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0c85eddc-daa4-45aa-a01b-6abec26e94c5')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-0c85eddc-daa4-45aa-a01b-6abec26e94c5 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-0c85eddc-daa4-45aa-a01b-6abec26e94c5');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "papers",
              "summary": "{\n  \"name\": \"papers\",\n  \"rows\": 6560,\n  \"fields\": [\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1901,\n        \"min\": 1,\n        \"max\": 6603,\n        \"num_unique_values\": 6560,\n        \"samples\": [\n          3087,\n          78,\n          5412\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"year\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 8,\n        \"min\": 1987,\n        \"max\": 2016,\n        \"num_unique_values\": 30,\n        \"samples\": [\n          1992,\n          1990,\n          2012\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"title\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 6560,\n        \"samples\": [\n          \"Natural Actor-Critic for Road Traffic Optimisation\",\n          \"Learning Representations by Recirculation\",\n          \"Quantized Kernel Learning for Feature Matching\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"event_type\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"Oral\",\n          \"Spotlight\",\n          \"Poster\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pdf_name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 6560,\n        \"samples\": [\n          \"3087-natural-actor-critic-for-road-traffic-optimisation.pdf\",\n          \"78-learning-representations-by-recirculation.pdf\",\n          \"5412-quantized-kernel-learning-for-feature-matching.pdf\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"abstract\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3244,\n        \"samples\": [\n          \"Tensor CANDECOMP/PARAFAC (CP) decomposition has wide applications in statistical learning of latent variable models and in data mining. In this paper, we propose fast and randomized tensor CP decomposition algorithms based on sketching. We build on the idea of count sketches, but introduce many novel ideas which are unique to tensors. We develop novel methods for randomized com- putation of tensor contractions via FFTs, without explicitly forming the tensors. Such tensor contractions are encountered in decomposition methods such as ten- sor power iterations and alternating least squares. We also design novel colliding hashes for symmetric tensors to further save time in computing the sketches. We then combine these sketching ideas with existing whitening and tensor power iter- ative techniques to obtain the fastest algorithm on both sparse and dense tensors. The quality of approximation under our method does not depend on properties such as sparsity, uniformity of elements, etc. We apply the method for topic mod- eling and obtain competitive results.\",\n          \"Many spectral unmixing methods rely on the non-negative decomposition of spectral data onto a dictionary of spectral templates. In particular, state-of-the-art music transcription systems decompose the spectrogram of the input signal onto a dictionary of representative note spectra. The typical measures of fit used to quantify the adequacy of the decomposition compare the data and template entries frequency-wise. As such, small displacements of energy from a frequency bin to another as well as variations of timber can disproportionally harm the fit. We address these issues by means of optimal transportation and propose a new measure of fit that treats the frequency distributions of energy holistically as opposed to frequency-wise. Building on the harmonic nature of sound, the new measure is invariant to shifts of energy to harmonically-related frequencies, as well as to small and local displacements of energy. Equipped with this new measure of fit, the dictionary of note templates can be considerably simplified to a set of Dirac vectors located at the target fundamental frequencies (musical pitch values). This in turns gives ground to a very fast and simple decomposition algorithm that achieves state-of-the-art performance on real musical data.\",\n          \"The problem of  multiclass boosting is considered. A new framework,based on multi-dimensional codewords and predictors is introduced. The optimal set of codewords is derived, and a margin enforcing loss proposed. The resulting risk is minimized by gradient descent on a multidimensional functional space. Two algorithms are proposed: 1) CD-MCBoost, based on coordinate descent, updates one predictor component at a time, 2) GD-MCBoost, based on gradient descent, updates all components jointly. The algorithms differ in the weak learners that they support but are both shown to be 1) Bayes consistent, 2) margin enforcing, and 3) convergent to the global minimum of the risk. They also reduce to AdaBoost when there are only two classes. Experiments show that both methods outperform previous multiclass boosting approaches on a number of datasets.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"paper_text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 6553,\n        \"samples\": [\n          \"550\\n\\nAckley and Littman\\n\\nGeneralization and scaling in reinforcement\\nlearning\\nDavid H. Ackley\\nMichael L. Littman\\nCognitive Science Research Group\\nBellcore\\nMorristown, NJ 07960\\n\\nABSTRACT\\nIn associative reinforcement learning, an environment generates input\\nvectors, a learning system generates possible output vectors, and a reinforcement function computes feedback signals from the input-output\\npairs. The task is to discover and remember input-output pairs that\\ngenerate rewards. Especially difficult cases occur when rewards are\\nrare, since the expected time for any algorithm can grow exponentially\\nwith the size of the problem. Nonetheless, if a reinforcement function\\npossesses regularities, and a learning algorithm exploits them, learning\\ntime can be reduced below that of non-generalizing algorithms. This\\npaper describes a neural network algorithm called complementary reinforcement back-propagation (CRBP), and reports simulation results\\non problems designed to offer differing opportunities for generalization.\\n\\n1\\n\\nREINFORCEMENT LEARNING REQUIRES SEARCH\\n\\nReinforcement learning (Sutton, 1984; Barto & Anandan, 1985; Ackley, 1988; Allen,\\n1989) requires more from a learner than does the more familiar supervised learning\\nparadigm. Supervised learning supplies the correct answers to the learner, whereas\\nreinforcement learning requires the learner to discover the correct outputs before\\nthey can be stored. The reinforcement paradigm divides neatly into search and\\nlearning aspects: When rewarded the system makes internal adjustments to learn\\nthe discovered input-output pair; when punished the system makes internal adjustments to search elsewhere.\\n\\n\\fGeneralization and Scaling in Reinforcement Learning\\n1.1\\n\\nMAKING REINFORCEMENT INTO ERROR\\n\\nFollowing work by Anderson (1986) and Williams (1988), we extend the backpropagation algorithm to associative reinforcement learning. Start with a \\\"garden variety\\\" backpropagation network: A vector i of n binary input units propagates\\nthrough zero or more layers of hidden units, ultimately reaching a vector 8 of m\\nsigmoid units, each taking continuous values in the range (0,1). Interpret each 8j\\nas the probability that an associated random bit OJ takes on value 1. Let us call\\nthe continuous, deterministic vector 8 the search vector to distinguish it from the\\nstochastic binary output vector o.\\nGiven an input vector, we forward propagate to produce a search vector 8, and\\nthen perform m independent Bernoulli trials to produce an output vector o. The\\ni - 0 pair is evaluated by the reinforcement function and reward or punishment\\nensues. Suppose reward occurs. We therefore want to make 0 more likely given i.\\nBackpropagation will do just that if we take 0 as the desired target to produce an\\nerror vector (0 - 8) and adjust weights normally.\\nNow suppose punishment occurs, indicating 0 does not correspond with i. By choice\\nof error vector, backpropagation allows us to push the search vector in any direction;\\nwhich way should we go? In absence of problem-specific information, we cannot pick\\nan appropriate direction with certainty. Any decision will involve assumptions. A\\nvery minimal \\\"don't be like 0\\\" assumption-employed in Anderson (1986), Williams\\n(1988), and Ackley (1989)-pushes s directly away from 0 by taking (8 - 0) as the\\nerror vector. A slightly stronger \\\"be like not-o\\\" assumption-employed in Barto &\\nAnandan (1985) and Ackley (1987)-pushes s directly toward the complement of 0\\nby taking ((1 - 0) - 8) as the error vector. Although the two approaches always\\nagree on the signs of the error terms, they differ in magnitudes. In this work,\\nwe explore the second possibility, embodied in an algorithm called complementary\\nreinforcement back-propagation ( CRBP).\\nFigure 1 summarizes the CRBP algorithm. The algorithm in the figure reflects three\\nmodifications to the basic approach just sketched. First, in step 2, instead of using\\nthe 8j'S directly as probabilities, we found it advantageous to \\\"stretch\\\" the values\\nusing a parameter v. When v < 1, it is not necessary for the 8i'S to reach zero or\\none to produce a deterministic output. Second, in step 6, we found it important\\nto use a smaller learning rate for punishment compared to reward. Third, consider\\nstep 7: Another forward propagation is performed, another stochastic binary output vector 0* is generated (using the procedure from step 2), and 0* is compared\\nto o. If they are identical and punishment occurred, or if they are different and\\nreward occurred, then another error vector is generated and another weight update\\nis performed. This loop continues until a different output is generated (in the case\\nof failure) or until the original output is regenerated (in the case of success). This\\nmodification improved performance significantly, and added only a small percentage\\nto the total number of weight updates performed.\\n\\n551\\n\\n\\f552\\n\\nAckley and Littman\\n\\nO. Build a back propagation network with input dimensionality n and output\\ndimensionality m. Let t = 0 and te = O.\\n1. Pick random i E 2n and forward propagate to produce a/s.\\n2. Generate a binary output vector o. Given a uniform random variable ~ E [0,1]\\nand parameter 0 < v < 1,\\nOJ\\n\\n=\\n\\n{1,\\n\\n0,\\n\\nif(sj - !)/v+! ~ ~j\\notherwise.\\n\\n3. Compute reinforcement r = f(i,o). Increment t. If r < 0, let te = t.\\n4. Generate output errors ej. If r > 0, let tj = OJ, otherwise let tj = 1- OJ. Let\\nej = (tj - sj)sj(l- Sj).\\n5. Backpropagate errors.\\n6. Update weights. 1:::..Wjk = 1]ekSj, using 1] = 1]+ if r ~ 0, and 1] = 1]- otherwise,\\nwith parameters 1]+,1]- > o.\\n7. Forward propagate again to produce new Sj's. Generate temporary output\\nvector 0*. If (r > 0 and 0* #- 0) or (r < 0 and 0* = 0), go to 4.\\n8. If te ~ t, exit returning te, else go to 1.\\n\\nFigure 1: Complementary Reinforcement Back Propagation-CRBP\\n\\n2\\n\\nON-LINE GENERALIZATION\\n\\nWhen there are many possible outputs and correct pairings are rare, the computational cost associated with the search for the correct answers can be profound.\\nThe search for correct pairings will be accelerated if the search strategy can effectively generalize the reinforcement received on one input to others. The speed of\\nan algorithm on a given problem relative to non-generalizing algorithms provides a\\nmeasure of generalization that we call on-line generalization.\\nO. Let z be an array of length 2n. Set the z[i] to random numbers from 0 to\\n2m - 1. Let t = te = O.\\n1. Pick a random input i E 2n.\\n2. Compute reinforcement r = f(i, z[i]). Increment t.\\n3. If r < 0 let z[i] = (z[i] + 1) mod 2m , and let te = t.\\n4. If te <t:: t exit returning t e, else go to 1.\\n\\nFigure 2: The Table Lookup Reference Algorithm Tref(f, n, m)\\nConsider the table-lookup algorithm Tref(f, n, m) summarized in Figure 2. In this\\nalgorithm, a separate storage location is used for each possible input. This prevents\\nthe memorization of one i - 0 pair from interfering with any other. Similarly,\\nthe selection of a candidate output vector depends only on the slot of the table\\ncorresponding to the given input. The learning speed of T ref depends only on the\\ninput and output dimensionalities and the number of correct outputs associated\\n\\n\\fGeneralization and Scaling in Reinforcement Learning\\n\\nwith each input. When a problem possesses n input bits and n output bits, and\\nthere is only one correct output vector for each input vector, Tre{ runs in about 4n\\ntime (counting each input-output judgment as one.) In such cases one expects to\\ntake at least 2n - 1 just to find one correct i - 0 pair, so exponential time cannot be\\navoided without a priori information. How does a generalizing algorithm such as\\nCRBP compare to Trer?\\n\\n3\\n\\nSIMULATIONS ON SCALABLE PROBLEMS\\n\\nWe have tested CRBP on several simple problems designed to offer varying degrees\\nand types of generalization. In all of the simulations in this section, the following\\ndetails apply: Input and output bit counts are equal (n). Parameters are dependent\\non n but independent of the reinforcement function f. '7+ is hand-picked for each\\nn,l 11- = 11+/10 and II = 0.5. All data points are medians of five runs. The stopping\\ncriterion te ~ t is interpreted as te +max(2000, 2n+l) < t. The fit lines in the figures\\nare least squares solutions to a x bn , to two significant digits.\\nAs a notational convenience, let c = ~\\n\\n3.1\\n\\nn\\n\\nE ij\\n\\n;=1\\n\\n-\\n\\nthe fraction of ones in the input.\\n\\nn-MAJORlTY\\n\\nConsider this \\\"majority rules\\\" problem: [if c > ~ then 0 = In else 0 = on]. The i-o\\nmapping is many-to-l. This problem provides an opportunity for what Anderson\\n(1986) called \\\"output generalization\\\": since there are only two correct output states,\\nevery pair of output bits are completely correlated in the cases when reward occurs.\\n\\nG)\\n\\n'iii\\nu\\nrn\\n\\nC)\\n\\n0\\n\\n::::.\\nG)\\n\\nE\\n\\n;\\n\\n10 7\\n10 6\\n10 5\\n10 4\\n\\nx\\n\\nTable\\n\\nD\\n\\nCRBP n-n-n\\n\\n+ CRBP n-n\\n\\n10 3\\n10 2\\n10 1\\n10 0\\n0\\n\\n1\\n\\n2\\n\\n3\\n\\n456\\n\\n78\\n\\n91011121314\\n\\nn\\nFigure 3: The n-majority problem\\n\\nFigure 3 displays the simulation results. Note that although Trer is faster than\\nCRBP at small values of n, CRBP's slower growth rate (1.6n vs 4.2n ) allows it to\\ncross over and begin outperforming Trer at about 6 bits. Note also--in violation of\\n1 For n = 1 to 12. we used '1+\\n0.219. 0.170. 0.121}.\\n\\n= {2.000. 1.550. 1.130.0.979.0.783.0.709.0.623.0.525.0.280.\\n\\n553\\n\\n\\f554\\n\\nAckley and Littman\\n\\nsome conventional wisdom-that although n-majority is a linearly separable problem, the performance of CRBP with hidden units is better than without. Hidden\\nunits can be helpful--even on linearly separable problems-when there are opportunities for output generalization.\\n\\n3.2\\n\\nn-COPY AND THE 2k -ATTRACTORS FAMILY\\n\\nAs a second example, consider the n-copy problem: [0 = i]. The i-o mapping is now\\n1-1, and the values of output bits in rewarding states are completely uncorrelated,\\nbut the value of each output bit is completely correlated with the value of the\\ncorresponding input bit. Figure 4 displays the simulation results. Once again, at\\n\\nG)\\n\\n'ii\\n\\ntA\\nQ\\n0\\n\\n::::.\\nG)\\n\\n-\\n\\n.5\\n\\n10 7\\n10 6\\n10 5\\n10 4\\n\\nx\\n150*2.0I\\\\n\\n\\nD\\n\\n10 3\\n10 2\\n\\n12*2.2I\\\\n\\n\\n+\\n\\nTable\\nCRBP n-n-n\\nCRBP n-n\\n\\n10 1\\n10 0\\n0\\n\\n1\\n\\n2\\n\\n3\\n\\n4\\n\\n5\\n\\n6\\n\\n7\\n\\n8\\n\\n9\\n\\n10 1112\\n\\nn\\nFigure 4: The n-copy problem\\nlow values of n, Trer is faster, but CRBP rapidly overtakes Trer as n increases. In\\nn-copy, unlike n-majority, CRBP performs better without hidden units.\\nThe n-majority and n-copy problems are extreme cases of a spectrum. n-majority\\ncan be viewed as a \\\"2-attractors\\\" problem in that there are only two correct\\noutputs-all zeros and all ones-and the correct output is the one that i is closer\\nto in hamming distance. By dividing the input and output bits into two groups\\nand performing the majority function independently on each group, one generates\\na \\\"4-aUractors\\\" problem. In general, by dividing the input and output bits into\\n1 ~ Ie ~ n groups, one generates a \\\"2i:-attractors\\\" problem. When Ie = 1, nmajority results, and when Ie n, n-copy results.\\n\\n=\\n\\nFigure 5 displays simulation results on the n = 8-bit problems generated when Ie is\\nvaried from 1 to n. The advantage of hidden units for low values of Ie is evident,\\nas is the advantage of \\\"shortcut connections\\\" (direct input-to-output weights) for\\nlarger values of Ie. Note also that combination of both hidden units and shortcut\\nconnections performs better than either alone.\\n\\n\\fGeneralization and Scaling in Reinforcement Learning\\n\\n105~--------------------------------~\\n\\nCASP 8-10-8\\n-+- CASP 8-8\\n.... CASP 8-10-Sls\\n-0-\\n\\n... Table\\n\\n3\\n\\n2\\n\\n1\\n\\n5\\n\\n4\\n\\n7\\n\\n6\\n\\n8\\n\\nk\\n\\nFigure 5: The 21:- attractors family at n = 8\\n\\n3.3\\n\\nn-EXCLUDED MIDDLE\\n\\nAll of the functions considered so far have been linearly separable. Consider this\\n\\\"folded majority\\\" function: [if\\n< c < then 0 on else 0 In]. Now, like\\nn-majority, there are only two rewarding output states, but the determination of\\nwhich output state is correct is not linearly separable in the input space. When\\nn = 2, the n-excluded middle problem yields the EQV (i.e., the complement of\\nXOR) function, but whereas functions such as n-parity [if nc is even then 0\\non\\nelse 0 = In] get more non-linear with increasing n, n-excluded middle does not.\\n\\ni\\n\\ni\\n\\n=\\n\\n=\\n\\n=\\n\\n107~------------------------------~~\\n\\n-\\n\\n10 6\\n10 5\\n\\nD)\\n\\n10 4\\n10 3\\n\\nI)\\n\\n'ii\\nu\\nf)\\n\\n.2\\n\\nI)\\n\\nE\\n\\n:::\\n\\nx\\nc\\n\\n17oo*1.6\\\"n\\n\\nTable\\n\\nCRSP n-n-n/s\\n\\n10 2\\n10 1\\n10 0\\n0\\n\\n1\\n\\n2\\n\\n3\\n\\n4\\n\\n5\\n\\n6\\n\\n7\\n\\n8\\n\\n9\\n\\n10 1112\\n\\nn\\nFigure 6: The n-excluded middle problem\\nFigure 6 displays the simulation results. CRBP is slowed somewhat compared to\\nthe linearly separable problems, yielding a higher \\\"cross over point\\\" of about 8 bits.\\n\\n555\\n\\n\\f556\\n\\nAckley and Littman\\n\\n4\\n\\nSTRUCTURING DEGENERATE OUTPUT SPACES\\n\\nAll of the scaling problems in the previous section are designed so that there is\\na single correct output for each possible input. This allows for difficult problems\\neven at small sizes, but it rules out an important aspect of generalizing algorithms\\nfor associative reinforcement learning: If there are multiple satisfactory outputs\\nfor given inputs, a generalizing algorithm may impose structure on the mapping it\\nproduces.\\nWe have two demonstrations of this effect, \\\"Bit Count\\\" and \\\"Inverse Arithmetic.\\\"\\nThe Bit Count problem simply states that the number of I-bits in the output should\\nequal the number of I-bits in the input. When n = 9, Tref rapidly finds solutions\\ninvolving hundreds of different output patterns. CRBP is slower--especially with\\nrelatively few hidden units-but it regularly finds solutions involving just 10 output\\npatterns that form a sequence from 09 to 19 with one bit changing per step.\\n0+Ox4=0\\n1+0x4=1\\n2+0x4=2\\n3+0x4=3\\n\\n0+2x4=8\\n1+2x4=9\\n2 + 2 x 4 = 10\\n3+2x4=11\\n\\n4+0x4=4 4+ 2 x 4 =\\n5+0x4=5 5 + 2 x 4 =\\n6+0x4=6 6 + 2 x 4 =\\n7+0x4=7 7 + 2 x 4 =\\n\\n12\\n13\\n14\\n15\\n\\n2+2-4=0 2+2+4=8\\n3+2-4=1 3+2+4=9\\n2+2+4=2 2 + 2 x 4 = 10\\n3+2+4=3 3+2x4=1l\\n6+2-4=4\\n7+2-4=5\\n6+2+4=6\\n7+2-.;-4=7\\n\\n6+\\n7+\\n6+\\n7+\\n\\n2+ 4 =\\n2+ 4 =\\n2x4=\\n2x4=\\n\\n0+4 x 4 = 16 0+6 x 4 =\\n1+4x4=17 1 + 6 x 4 =\\n2 + 4 x 4 = 18 2 + 6 x 4 =\\n3 +4 x 4 = 19 3 + 6 x 4 =\\n\\n24\\n25\\n26\\n27\\n\\n4+4\\n5+ 4\\n6+ 4\\n7+ 4\\n\\n=\\n=\\n=\\n=\\n\\n28\\n29\\n30\\n31\\n24\\n25\\n26\\n27\\n\\nx\\nx\\nx\\nx\\n\\n4=\\n4=\\n4=\\n4=\\n\\n6+ 6 + 4 =\\n7+6+4=\\n2+ 4 x 4 =\\n3+ 4 x 4=\\n\\n12 4 x 4 +\\n13 5 + 4 x\\n14 6 + 4 x\\n15 7 +4 x\\n\\n4=\\n4=\\n4\\n4=\\n\\n=\\n\\n20 4 + 6 x\\n21 5 + 6 x\\n22 6 + 6 x\\n23 7 + 6 x\\n\\n4\\n4\\n4\\n4\\n\\n16\\n17\\n18\\n19\\n\\n0+6 x\\n1+ 6 x\\n2+ 6x\\n3+ 6x\\n\\n4=\\n4=\\n4=\\n4=\\n\\n20\\n21\\n22\\n23\\n\\n4+\\n5+\\n6+\\n7+\\n\\n4 = 28\\n4 = 29\\n4 30\\n4 = 31\\n\\n6\\n6\\n6\\n6\\n\\nx\\nx\\nx\\nx\\n\\n=\\n\\nFigure 7: Sample CRBP solutions to Inverse Arithmetic\\n\\nThe Inverse Arithmetic problem can be summarized as follows: Given i E 25 , find\\n:1:, y, z E 23 and 0, <> E {+(OO)' -(01)' X (10)' +(11)} such that :I: oy<>z = i. In all there are\\n13 bits of output, interpreted as three 3-bit binary numbers and two 2-bit operators,\\nand the task is to pick an output that evaluates to the given 5-bit binary input\\nunder the usual rules: operator precedence, left-right evaluation, integer division,\\nand division by zero fails.\\nAs shown in Figure 7, CRBP sometimes solves this problem essentially by discovering positional notation, and sometimes produces less-globally structured solutions,\\nparticularly as outputs for lower-valued i's, which have a wider range of solutions.\\n\\n\\fGeneralization and Scaling in Reinforcement Learning\\n\\n5\\n\\nCONCLUSIONS\\n\\nSome basic concepts of supervised learning appear in different guises when the\\nparadigm of reinforcement learning is applied to large output spaces. Rather than\\na \\\"learning phase\\\" followed by a \\\"generalization test,\\\" in reinforcement learning\\nthe search problem is a generalization test, performed simultaneously with learning.\\nInformation is put to work as soon as it is acquired.\\nThe problem of of \\\"overfitting\\\" or \\\"learning the noise\\\" seems to be less of an issue,\\nsince learning stops automatically when consistent success is reached. In experiments not reported here we gradually increased the number of hidden units on\\nthe 8-bit copy problem from 8 to 25 without observing the performance decline\\nassociated with \\\"too many free parameters.\\\"\\nThe 2 k -attractors (and 2 k -folds-generalizing Excluded Middle) families provide\\na starter set of sample problems with easily understood and distinctly different\\nextreme cases.\\nIn degenerate output spaces, generalization decisions can be seen directly in the\\ndiscovered mapping. Network analysis is not required to \\\"see how the net does it.\\\"\\nThe possibility of ultimately generating useful new knowledge via reinforcement\\nlearning algorithms cannot be ruled out.\\nReferences\\nAckley, D.H. (1987) A connectionist machine for genetic hillclimbing. Boston, MA: Kluwer\\nAcademic Press.\\nAckley, D.H. (1989) Associative learning via inhibitory search. In D.S. Touretzky (ed.),\\nAdvances in Neural Information Processing Systems 1, 20-28. San Mateo, CA: Morgan\\nKaufmann.\\nAllen, R.B. (1989) Developing agent models with a neural reinforcement technique. IEEE\\nSystems, Man, and Cybernetics Conference. Cambridge, MA.\\nAnderson, C.W. (1986) Learning and problem solving with multilayer connectionist systems. University of Mass. Ph.D. dissertation. COINS TR 86-50. Amherst, MA.\\nBarto, A.G. (1985) Learning by statistical cooperation of self-interested neuron-like computing elements. Human Neurobiology, 4:229-256.\\nBarto, A.G., & Anandan, P. (1985) Pattern recognizing stochastic learning automata.\\nIEEE Transactions on Systems, Man, and Cybernetics, 15, 360-374.\\nRumelhart, D.E., Hinton, G.E., & Williams, R.J. (1986) Learning representations by backpropagating errors. Nature, 323, 533-536.\\nSutton, R.S. (1984) Temporal credit assignment in reinforcement learning. University of\\nMass. Ph.D. dissertation. COINS TR 84-2. Amherst, MA.\\nWilliams, R.J. (1988) Toward a theory of reinforcement-learning connectionist systems.\\nCollege of Computer Science of Northeastern University Technical Report NU-CCS-88-3.\\nBoston, MA.\\n\\n557\\n\\n\\f\",\n          \"Dynamics of Supervised Learning with\\nRestricted Training Sets and Noisy Teachers\\n\\nA.C.C. Coolen\\nDept of Mathematics\\nKing's College London\\nThe Strand, London WC2R 2LS, UK\\ntcoolen@mth.kc1.ac.uk\\n\\nC.W.H.Mace\\nDept of Mathematics\\nKing's College London\\nThe Strand, London WC2R 2LS, UK\\ncmace@mth.kc1.ac.uk\\n\\nAbstract\\nWe generalize a recent formalism to describe the dynamics of supervised\\nlearning in layered neural networks, in the regime where data recycling\\nis inevitable, to the case of noisy teachers. Our theory generates reliable\\npredictions for the evolution in time of training- and generalization errors, and extends the class of mathematically solvable learning processes\\nin large neural networks to those situations where overfitting can occur.\\n\\n1 Introduction\\nTools from statistical mechanics have been used successfully over the last decade to study\\nthe dynamics of learning in layered neural networks (for reviews see e.g. [1] or [2]). The\\nsimplest theories result upon assuming the data set to be much larger than the number\\nof weight updates made, which rules out recycling and ensures that any distribution of\\nrelevance will be Gaussian. Unfortunately, both in terms of applications and in terms of\\nmathematical interest, this regime is not the most relevant one. Most complications and\\npeculiarities in the dynamics of learning arise precisely due to data recycling, which creates\\nfor the system the possibility to improve performance by memorizing answers rather than\\nby learning an underlying rule. The dynamics of learning with restricted training sets was\\nfirst studied analytically in [3] (linear learning rules) and [4] (systems with binary weights).\\nThe latter studies were ahead of their time, and did not get the attention they deserved just\\nbecause at that stage even the simpler learning dynamics without data recycling had not\\nyet been studied. More recently attention has moved back to the dynamics of learning\\nin the recycling regime. Some studies aimed at developing a general theory [5, 6, 7],\\nsome at finding exact solutions for special cases [8]. All general theories published so far\\nhave in common that they as yet considered realizable scenario's: the rule to be learned\\nwas implementable by the student, and overfitting could not yet occur. The next hurdle is\\nthat where restricted training sets are combined with unrealizable rules. Again some have\\nturned to non-typical but solvable cases, involving Hebbian rules and noisy [9] or 'reverse\\nwedge' teachers [10]. More recently the cavity method has been used to build a general\\ntheory [11] (as yet for batch learning only). In this paper we generalize the general theory\\nlaunched in [6,5,7], which applies to arbitrary learning rules, to the case of noisy teachers.\\nWe will mirror closely the presentation in [6] (dealing with the simpler case of noise-free\\nteachers), and we refer to [5, 7] for background reading on the ideas behind the formalism.\\n\\n\\fA. C. C. Coolen and C. W. H. Mace\\n\\n238\\n\\n2 Definitions\\nAs in [6, 5] we restrict ourselves for simplicity to perceptrons. A student perceptron operates a linear separation, parametrised by a weight vector J E iRN :\\nS:{-I,I}N -t{-I,I}\\n\\nS(e) = sgn[J?e]\\n\\nIt aims to emulate a teacher o~erating a similar rule, which, however, is characterized by a\\nvariable weight vector BE iR ,drawn at random from a distribution P(B) such as\\nP(B) = >'6[B+B*]\\n\\noutput noise:\\n\\n+ (1->')6[B-B*]\\n\\n(1)\\n\\nP(B) = [~~/NrN e- tN (B-B')2/E2\\n(2)\\nThe parameters>. and ~ control the amount of teacher noise, with the noise-free teacher\\nB = B* recovered in the limits>. -t 0 and ~ -t O. The student modifies J iteratively, using\\nexamples of input vectors which are drawn at random from a fixed (randomly composed)\\nE {-I, I}N with a> 0, and the corresponding\\ntraining set containing p = aN vectors\\nvalues of the teacher outputs. We choose the teacher noise to be consistent, i.e. the answer\\nwill remain the same when that particular question\\ngiven by the teacher to a question\\nre-appears during the learning process. Thus T(e?) = sgn[BJL . e], with p teacher weight\\nvectors BJL, drawn randomly and independently from P(B), and we generalize the training\\nl , B l ), . .. , (e, BP)}. Consistency of teacher noise is natural\\nset accordingly to jj =\\nin terms of applications, and a prerequisite for overfitting phenomena. Averages over the\\ntraining set will be denoted as ( ... ) b; averages over all possible input vectors E {-I, I}N\\nas ( ... )e. We analyze two classes of learning rules, of the form J (? + 1) = J (?) + f).J (?):\\n\\nGaussian weight noise:\\n\\ne\\n\\ne\\n\\ne\\n\\nHe\\n\\ne\\n\\n= 11 {e(?) 9 [J(?)?e(?), B(?)?e(?)] - ,J(?) }\\nf).J(?) = 11 {(e 9 [J(?)?e, B?eDl> - ,J(m) }\\n\\non-line:\\n\\nf).J(?)\\n\\nbatch :\\n\\n(3)\\n\\nIn on-line learning one draws at each step ? a question/answer pair (e (?), B (?)) at random from the training set. In batch learning one iterates a deterministic map which is an\\naverage over all data in the training set. Our performance measures are the training- and\\ngeneralization errors, defined as follows (with the step function O[x > 0] = 1, O[x < 0] = 0):\\nEt(J)\\n\\n= (O[-(J ?e)(B ?em b\\n\\nEg(J)\\n\\n= (O[-(J ?e)(B* ?e)])e\\n\\n(4)\\n\\nWe introduce macroscopic observables, taylored to the present problem, generalizing [5, 6]:\\nQ[J]=J 2,\\nR[J]=J?B*,\\nP[x,y,z;J]=(6[x-J?e]6[y-B*?e]6[z-B?eDl> (5)\\nAs in [5, 6] we eliminate technical subtleties by assuming the number of arguments (x, y, z)\\nfor which P[x, y, z; J] is evaluated to go to infinity after the limit N -t 00 has been taken.\\n\\n3 Derivation of Macroscopic Laws\\nUpon generalizing the calculations in [6, 5], one finds for on-line learning:\\n\\n!\\n!\\n\\nQ = 2'f} !dXdydZ P[x, y, z] xg[x, z] - 2'f},Q + 'f}2!dXdYdZ P[x, y, z] g2[x, z]\\n\\n(6)\\n\\nR = 'f} !dXdydZ P[x, y, z] y9[x, z]- 'f},R\\n\\n(7)\\n\\n:t\\n\\nP[x, y, z] =\\n\\n~\\n\\n!\\n\\ndx' P[x', y, z] {6[x-x' -'f}G[x', z]] -6[x-x']}\\n\\n-'f}! / dx'dy'dz' / dx'dy'dz'9[x', z]A[x, y, z; x',y', z']\\n\\n1\\n+'i'f}2\\n\\n!\\n\\n+ 'f}, :x\\n\\nEP2P[x, y, z]\\ndx'dy'dz' P[x', y', z']92[x', z'] 8x\\n\\n{xP[x , y, z]}\\n\\n(8)\\n\\n\\fSupervised Learning with Restricted Training Sets\\n\\n239\\n\\nThe complexity of the problem is concentrated in a Green's function:\\nA[x, y, Zj x', y', z'] = lim\\nN-+oo\\n\\n(( ([1-6ee , ]6[x-J?e]6[y-B*?e]6[z-B?e] (e?e')6[x' -J?e']6[y' - B*?e']6[y' - B?e'])i?i> )QW;t\\n\\nJ\\n\\nIt involves a conditional average of the form (K[J])QW;t = dJ Pt(JIQ,R,P)K[J], with\\nPt(J) 6[Q-Q[J]]6[R- R[J]] nXYZ 6[P[x, y, z] -P[x, y, Zj J]]\\nPt(JIQ,R,P)\\nJdJ Pt(J) 6[Q - Q[J]]6[R- R[J]] nXYZ 6[P[x, y, z] - P[x, y, z; J]]\\n\\n=\\n\\nin which Pt (J) is the weight probability density at time t. The solution of (6,7,8) can be\\nused to generate the N -+ 00 performance measures (4) at any time:\\nEt\\n\\n=/\\n\\ndxdydz P[x, y, z]O[-xz]\\n\\nEg\\n\\n= 11\\\"-1 arccos[RIVQ]\\n\\n(9)\\n\\nExpansion of these equations in powers of\\\"\\\" and retaining only the terms linear in \\\"\\\" gives\\nthe corresponding equations describing batch learning. So far this analysis is exact.\\n\\n4\\n\\nClosure of Macroscopic Laws\\n\\nAs in [6, 5] we close our macroscopic laws (6,7,8) by making the two key assumptions\\nunderlying dynamical replica theory:\\n(i) For N -+ 00 our macroscopic observables obey closed dynamic equations.\\n(ii) These equations are self-averaging with respect to the specific realization of D.\\n\\n(i) implies that probability variations within {Q, R, P} subshells are either absent or irrelevant to the macroscopic laws. We may thus make the simplest choice for Pt (J IQ, R, P):\\nPt(JIQ,R,P) -+ 6[Q-Q[J]] 6[R-R[J]]\\n\\nII 6[P[x,y,z]-P[x,y,ZjJ]]\\n\\n(10)\\n\\nxyz\\n\\nThe procedure (10) leads to exact laws if our observables {Q, R, P} indeed obey closed\\nequations for N -+ 00. It is a maximum entropy approximation if not. (ii) allows us\\nto average the macroscopic laws over all training sets; it is observed in simulations, and\\nproven using the formalism of [4]. Our assumptions (10) result in the closure of (6,7,8),\\nsince now the Green's function can be written in terms of {Q, R, Pl. The final ingredient\\nof dynamical replica theory is doing the average of fractions with the replica identity\\n\\n/ JdJ W[JID]GIJID])\\n\\n\\\\\\n\\nJdJ W[JID]\\n\\n= lim\\nsets\\n\\n/dJ I\\n\\n???\\n\\ndJn (G[J 1 ID]\\n\\nn-+O\\n\\nIT\\n\\nW[JO<ID])sets\\n\\na=1\\n\\nOur problem has been reduced to calculating (non-trivial) integrals and averages. One\\nfinds that P[x, y, z] P[x, zly]P[y] with Ply] (211\\\")-!exp[-!y 21With the short-hands\\nDy = P[y]dy and (f(x, y, z)) = Dydxdz P[x, zly]f(x, y, z) we can write the resulting\\nmacroscopic laws, for the case of output noise (1), in the following compact way:\\n\\n=\\n\\nd\\n\\ndt Q = 2\\\",(V - ,Q)\\n\\n[)\\n\\n[)tP[x,zly] =\\n\\n=\\n\\nJ\\n\\n+ rJ2 Z\\n\\nd\\n\\ndtR = \\\",(W - ,R)\\n\\n(11)\\n\\n1 [)x[)22P[x,zIY]\\na1/dx'P[x',zly] {6[x-x'-\\\",G[x',z]]-6[x-x'] }+2\\\",2Z\\n\\n-\\\",:x {P[x,zly]\\n\\n[U(x-RY)+Wy-,x+[V-RW-(Q-R2)U]~[x,y,z])}\\n\\n(12)\\n\\nwith\\n\\nU = (~[x, y, z]9[x, z]),\\n\\nv = (x9[x, z]),\\n\\nW = (y9[x, z]),\\n\\nZ = (9 2[x, z])\\n\\nThe solution of (12) is at any time of the following form:\\n\\nP[x,zly]\\n\\n= (1-,x)6[y-z]P+[xly] + ,x6[y+z]P-[xly]\\n\\n(13)\\n\\n\\fA. C. C. Coolen and C. W. H. Mace\\n\\n240\\n\\nFinding the function <I> [x, y, z] (in replica symmetric ansatz) requires solving a saddle-point\\nproblem for a scalar observable q and two functions M?[xly]. Upon introducing\\n\\nB = . . :. V. .,. .q.,-Q___R,-2\\nQ(I-q)\\n(with Jdx M?[xly]\\n\\nJdx M?[xly]eBxs J[x, y]\\nJdx M?[xly]eBxs\\n\\n(f[x, y])? =\\n*\\n\\n= 1 for all y) the saddle-point equations acquire the fonn\\np?[Xly] =\\n\\nfor all X, y :\\n\\n((x-Ry)2) + (qQ-R 2)[I-!:.]\\na\\n\\n!\\n\\nDs (O[X -xl);\\n\\n2 !DYDS S[(I-A)(X); + A(X);]\\n= qQ+Q-2R\\n..jqQ_R2\\n\\n(14)\\n(15)\\n\\nThe equations (14) which detennine M?[xly] have the same structure as the corresponding\\n(single) equation in [5, 6], so the proofs in [5, 6] again apply, and the solutions M?[xly],\\ngiven a q in the physical range q E [R2/Q, 1], are unique. The function <I> [x, y, z] is then\\ngiven by\\n<I> [X,\\n\\ny, z]\\n\\n=!\\n\\nDs s\\n{(I-A)O[Z-y](o[X -x)); + AO[Z+Y](o[X -xl);}\\n..jqQ_R2 P[X, zly]\\n(16)\\n\\nWorking out predictions from these equations is generally CPU-intensive, mainly due to\\nthe functional saddle-point equation (14) to be solved at each time step. However, as in [7]\\none can construct useful approximations of the theory, with increasing complexity:\\n\\n(i) Large a approximation (giving the simplest theory, without saddle-point equations)\\n(ii) Conditionally Gaussian approximation for M[xly] (with y-dependent moments)\\n(iii) Annealed approximation of the functional saddle-point equation\\n\\n5 Benchmark Tests: The Limits a --+ 00 and ,\\\\ --+ 0\\nWe first show that in the limit a --+ 00 our theory reduces to the simple (Q, R) formalism\\nof infinite training sets, as worked out for noisy teachers in [12]. Upon making the ansatz\\n\\np?[xly] = P[xly] = [27r(Q-R 2)]-t e- t [x- Rv]2/(Q-R 2)\\n\\n(17)\\n\\none finds\\n\\n<I>[x,y,Z] = (x-Ry)/(Q-R 2)\\n\\nM?[xly] = P[xly],\\n\\nInsertion of our ansatz into (12), followed by rearranging of terms and usage of the above\\nexpression for <I> [x, y, z], shows that (12) is satisfied. The remaining equations (11) involve\\nonly averages over the Gaussian distribution (17), and indeed reduce to those of [12]:\\n\\n~! Q =\\n\\n(I-A) { 2(x9[x, y))\\n1 d\\n--d R\\n1} t\\n\\n+ 1}{92[x, y)) } + A {2(x9[x,-y)) + 1}(92[x,-y)) } - 2,Q\\n\\n= (I-A)(y9[x,y)) + A(y9[x,-yl) -,R\\n\\nNext we turn to the limit A --+ 0 (restricted training sets & noise-free teachers) and show that\\nhere our theory reproduces the fonnalism of [6,5]. Now we make the following ansatz:\\n\\nP+[xly] = P[xly],\\n\\nP[x, zly]\\n\\n= o[z-y]P[xIY]\\n\\n(18)\\n\\nInsertion shows that for A = 0 solutions of this fonn indeed solve our equations, giving\\n<p[x, y, z]--+ <I> [x, y] and M+[xly]\\nM[xly), and leaving us exactly with the fonnalism\\nof [6, 5] describing the case of noise-free teachers and restricted training sets (apart from\\nsome new tenns due to the presence of weight decay, which was absent in [6, 5]).\\n\\n=\\n\\n\\f241\\n\\nSupervised Learning with Restricted Training Sets\\n0. , r------~--__,\\n\\n0..4\\n\\n~-------_____I\\n\\n0..4\\n\\n11>=0.'\\n\\n0..3\\n\\na=4\\n\\n0. ,\\n\\n0..0.\\n\\n--\\n\\n, 0.\\n\\n0.2\\n\\n_ __ ___ _____ _\\n\\na= 1\\n\\n0;=1\\n\\n------- ---- -- --- -\\n\\n0.\\n\\n0;=2\\n\\n=-=\\n-\\n\\n0;=2\\n\\n- - ----- -\\n\\na=4\\na=4\\n\\n= =-=\\n--=-=--=-=--=-=-=-- -=-=-_oed\\n\\na=4\\n\\n,\\n\\n0;=2\\n\\n':::::========:::j\\n\\n0..3\\n\\n-- - ----\\n\\n0;=1\\n\\n:::---- - -----1\\n\\n0;=2\\n\\n0..2\\n\\n11>=0.'\\n\\n~-------~\\n\\n0;=1\\n\\n0.,\\n\\n11>=0,\\n\\n\\\"\\n\\n,\\n\\nno. I\\n\\n0.\\n\\n, 0.\\n\\n\\\"\\n\\nFigure 1: On-line Hebbian learning: conditionally Gaussian approximation versus exact\\nsolution in [9] (.,., = 1, ,X = 0.2). Left: \\\"I = 0.1, right: \\\"I = 0.5. Solid lines: approximated\\ntheory, dashed lines: exact result. Upper curves: Eg as functions of time (here the two\\ntheories agree), lower curves: E t as functions of time.\\n\\n6\\n\\nBenchmark Tests: Hebbian Learning\\n\\nThe special case of Hebbian learning, i.e. Q[x, z] = sgn(z), can be solved exactly at any\\ntime, for arbitrary {a, ,x, \\\"I} [9], providing yet another excellent benchmark for our theory.\\nFor batch execution of Hebbian learning the macroscopic laws are obtained upon expanding\\n(11,12) and retaining only those terms which are linear in.,.,. All integrations can now be\\ndone and all equations solved explicitly, resulting in U =0, Z = 1, W = (I-2,X)J2/7r, and\\n\\nQ\\n\\n= Qo e-2rryt +\\n\\n2Ro(I-2'x) e-17\\\"Yt[I_e-rrrt]\\n\\\"I\\n\\nf{ + [~(I-2,X)2+.!.]\\n\\nV:;\\n\\n7r\\n\\na\\n\\n[I-e- 17 \\\"Y tF\\n\\\"12\\n\\nR = Ro e- 17\\\"Y t +(I-2'x)J2/7r[I-e- 17\\\"Y t ]/\\\"I\\nq = [aR2+(I_e- 17\\\"Yt)2 i'l]/aQ\\np?[xIY] = [27r(Q-R2)] -t e-tlz-RH sgn(y)[1-e-\\\"..,t]/a\\\"Y]2/(Q-R2)\\n(19)\\nFrom these results, in tum, follow the performance measures Eg = 7r- 1 arccos[ R/ JQ) and\\n\\nE = ! - !(1-,X)!D\\n2\\n\\nt\\n\\n2\\n\\nerf[IYIR+[I-e- 77\\\"Y t ]/a\\\"l] + !,X!D erf[IYIR-[I-e- 17\\\"Y t ]/a\\\"l]\\nY\\nJ2(Q-R2)\\n2\\ny\\nJ2(Q-R2)\\n\\nComparison with the exact solution, calculated along the lines of [9] or, equivalently, obtained upon putting t ?\\nin [9], shows that the above expressions are all exact.\\n\\n.,.,-2\\n\\nFor on-line execution we cannot (yet) solve the functional saddle-point equation in general.\\nHowever, some analytical predictions can still be extracted from (11,12,13):\\n\\nQ = Qo e-217\\\"Yt + 2Ro(I-2,X) e-77\\\"Yt[I_e-17\\\"Yt]\\n\\\"I\\n\\nR = Ro e- 17\\\"Y t + (I-2,X)J2/7r[I-e- 17\\\"Y t ]/\\\"I\\n\\nJ\\n\\nf{ + [~(I-2,X)2+.!.]\\n\\nV:;\\n\\n7r\\n\\na\\n\\n[I_e- 17\\\"Y t ]2\\n\\\"12\\n\\n+ !L[I_e- 217\\\"Y t ]\\n2\\\"1\\n\\ndx xP?[xIY] = Ry ? sgn(y)[I-e- 17\\\"Y t ]/a\\\"l\\n\\nwith U =0, W = (I-2,X)J2/7r, V = W R+[I-e- 17\\\"Y t ]/a\\\"l, and Z = 1. Comparison with the\\nresults in [9] shows that the above expressions, and thus also that of E g , are all fully exact,\\nat any time. Observables involving P[x, y, z] (including the training error) are not as easily\\nsolved from our equations. Instead we used the conditionally Gaussian approximation\\n(found to be adequate for the noiseless Hebbian case [5, 6, 7]). The result is shown in\\nfigure 1. The agreement is reasonable, but significantly less than that in [6]; apparently\\nteacher noise adds to the deformation of the field distribution away from a Gaussian shape.\\n\\n\\f242\\n\\nA. C. C. Coolen and C. W H. Mac\\n\\n~\\n\\n0.6\\n\\n000000\\n\\n0.4\\n\\n0.4\\n\\nE\\n\\n~\\n\\n0.2\\n\\nI\\ni\\n0.0\\n\\n0\\n\\n4\\n\\n2\\n\\n6\\n\\n10\\n\\n0.0\\n\\n-3\\n\\n-2\\n\\n-I\\n\\n0\\nX\\n\\n0.6\\n\\nf\\n\\n0.4\\n\\n0.4 [\\n\\nE\\n0.2\\n\\n0.2\\n\\n0.0\\n\\nL-o!i6iIII.\\\"\\\"\\\"\\\"\\\"',-\\\"--~_~~_ _--'\\n\\n-3\\n\\n-2\\n\\n-I\\n\\n0\\n\\n2\\n\\n3\\n\\nX\\n\\n,=\\n\\nFigure 2: Large a approximation versus numerical simulations (with N = 10,000), for\\n0 and A = 0.2. Top row: Perceptron rule, with.,., = ~. Bottom row: Adatron rule,\\nwith.,., = ~. Left: training errors E t and generalisation errors Eg as functions of time, for\\naE {~, 1, 2}. Lines: approximated theory, markers: simulations (circles: E t , squares: Eg) .\\nRight: joint distributions for student field and teacher noise p?[x] = dy P[x, y, z = ?y]\\n(upper: P+[x], lower: P-[x]). Histograms: simulations, lines: approximated theory.\\n\\nJ\\n\\n7\\n\\nNon-Linear Learning Rules: Theory versus Simulations\\n\\nIn the case of non-linear learning rules no exact solution is known against which to test our\\nformalism, leaving numerical simulations as the yardstick. We have evaluated numerically\\nthe large a approximation of our theory for Perceptron learning, 9[x, z] = sgn(z)O[-xz],\\nand for Adatron learning, 9[x, z] = sgn(z)lzIO[-xz]. This approximation leads to the\\nfollowing fully explicit equation for the field distributions:\\n\\n1/\\n\\nd\\n-p?[xly]\\n= dt\\na\\n.\\n\\nWith\\n\\nU=\\n\\n' +1\\n\\ndx' p?[x'ly]{o[x-x'-.,.,.1'[x', ?y]] -o[x-x]}\\n\\n_ ~ {P[ I ] [W _\\n.,., 8\\nx y\\ny\\n\\nJ\\n\\nX\\n\\n~ p?[xly]\\n\\n_.,.,2 Z!:I 2\\n2\\nuX\\n\\n,X + U[X?(y)-RY]+(V-RW)[X-X?(y)]]}\\nQ _ R2\\n\\nDydx {(I-A)P+[xly][x-P(y)]9[x,Y]+AP-[xly][x-x-(y)]9[x,-y])\\nV =\\nW=\\nZ=\\n\\n!\\n1\\n1\\n\\nDydx x {(I-A)P+[xly]9[x, Y]+AP-[xly]9[x,-y])\\nDydx y {(1-A)P+[xly]9[x, Y]+AP-[xly]9[x,-y])\\n\\nDydx {(I-A)P+[xly]92[x, Y]+AP-[xly]9 2[x,-yJ)\\n\\n\\fSupervised Learning with Restricted Training Sets\\n\\n243\\n\\nJ\\n\\nand with the short-hands X?(y) = dx xP?[xly). The result of our comparison is shown\\nin figure 2. Note: E t increases monotonically with a, and Eg decreases monotonically\\nwith a, at any t. As in the noise-free formalism [7], the large a approximation appears to\\ncapture the dominant terms both for a -7 00 and for a -7 O. The predicting power of our\\ntheory is mainly limited by numerical constraints. For instance, the Adatron learning rule\\ngenerates singularities at x = 0 in the distributions P?[xly) (especially for small \\\"I) which,\\nalthough predicted by our theory, are almost impossible to capture in numerical solutions.\\n\\n8 Discussion\\nWe have shown how a recent theory to describe the dynamics of supervised learning with\\nrestricted training sets (designed to apply in the data recycling regime, and for arbitrary online and batch learning rules) [5, 6, 7] in large layered neural networks can be generalized\\nsuccessfully in order to deal also with noisy teachers. In our generalized approach the joint\\ndistribution P[x, y, z) for the fields of student, 'clean' teacher, and noisy teacher is taken to\\nbe a dynamical order parameter, in addition to the conventional observables Q and R. From\\nthe order parameter set {Q, R, P} we derive the generalization error Eg and the training\\nerror E t . Following the prescriptions of dynamical replica theory one finds a diffusion\\nequation for P[x, y, z], which we have evaluated by making the replica-symmetric ansatz.\\nWe have carried out several orthogonal benchmark tests of our theory: (i) for a -7 00 (no\\ndata recycling) our theory is exact, (ii) for A -7 0 (no teacher noise) our theory reduces\\nto that of [5, 6, 7], and (iii) for batch Hebbian learning our theory is exact. For on-line\\nHebbian learning our theory is exact with regard to the predictions for Q, R, Eg and the\\ny-dependent conditional averages Jdx xP?[xly), at any time, and a crude approximation\\nof our equations already gives reasonable agreement with the exact results [9] for E t . For\\nnon-linear learning rules (Perceptron and Adatron) we have compared numerical solution\\nof a simple large a aproximation of our equations to numerical simulations, and found\\nsatisfactory agreement. This paper is a preliminary presentation of results obtained in the\\nsecond stage of a research programme aimed at extending our theoretical tools in the arena\\nof learning dynamics, building on [5, 6, 7]. Ongoing work is aimed at systematic application of our theory and its approximations to various types of non-linear learning rules, and\\nat generalization of the theory to multi-layer networks.\\n\\nReferences\\n[1]\\n[2]\\n[3]\\n[4]\\n[5]\\n[6]\\n[7]\\n[8]\\n[9]\\n[10]\\n[11]\\n[12]\\n\\nMace C.W.H. and Coolen AC.C (1998), Statistics and Computing 8, 55\\nSaad D. (ed.) (1998), On-Line Learning in Neural Networks (Cambridge: CUP)\\nHertz J.A., Krogh A and Thorgersson G.I. (1989), J. Phys. A 22, 2133\\nHomerH. (1992a), Z. Phys. B 86, 291 and Homer H. (1992b), Z. Phys. B 87,371\\nCoolen A.C.C. and Saad D. (1998), in On-Line Learning in Neural Networks, Saad\\nD. (ed.), (Cambridge: CUP)\\nCoolen AC.C. and Saad D. (1999), in Advances in Neural Information Processing\\nSystems 11, Kearns D., Solla S.A., Cohn D.A (eds.), (MIT press)\\nCoolen A.C.C. and Saad D. (1999), preprints KCL-MTH-99-32 & KCL-MTH-99-33\\nRae H.C., Sollich P. and Coolen AC.C. (1999), in Advances in Neural Information\\nProcessing Systems 11, Kearns D., Solla S.A., Cohn D.A. (eds.), (MIT press)\\nRae H.C., Sollich P. and Coolen AC.C. (1999),J. Phys. A 32, 3321\\nInoue J.I. (1999) private communication\\nWong K.YM., Li S. and Tong YW. (1999),preprint cond-mat19909004\\nBiehl M., Riegler P. and Stechert M. (1995), Phys. Rev. E 52, 4624\\n\\n\\f\",\n          \"Predicting Action Content On-Line and in\\nReal Time before Action Onset ? an\\nIntracranial Human Study\\n\\nShengxuan Ye\\nCalifornia Institute of Technology\\nPasadena, CA\\nsye@caltech.edu\\n\\nUri Maoz\\nCalifornia Institute of Technology\\nPasadena, CA\\nurim@caltech.edu\\nIan Ross\\nHuntington Hospital\\nPasadena, CA\\nianrossmd@aol.com\\n\\nAdam Mamelak\\nCedars-Sinai Medical Center\\nLos Angeles, CA\\nadam.mamelak@cshs.org\\n\\nChristof Koch\\nCalifornia Institute of Technology\\nPasadena, CA\\nAllen Institute for Brain Science\\nSeattle, WA\\nkoch@klab.caltech.edu\\n\\nAbstract\\nThe ability to predict action content from neural signals in real time before the action occurs has been long sought in the neuroscientific study of decision-making,\\nagency and volition. On-line real-time (ORT) prediction is important for understanding the relation between neural correlates of decision-making and conscious,\\nvoluntary action as well as for brain-machine interfaces. Here, epilepsy patients,\\nimplanted with intracranial depth microelectrodes or subdural grid electrodes for\\nclinical purposes, participated in a ?matching-pennies? game against an opponent.\\nIn each trial, subjects were given a 5 s countdown, after which they had to raise\\ntheir left or right hand immediately as the ?go? signal appeared on a computer\\nscreen. They won a fixed amount of money if they raised a different hand than\\ntheir opponent and lost that amount otherwise. The question we here studied was\\nthe extent to which neural precursors of the subjects? decisions can be detected in\\nintracranial local field potentials (LFP) prior to the onset of the action.\\nWe found that combined low-frequency (0.1?5 Hz) LFP signals from 10 electrodes\\nwere predictive of the intended left-/right-hand movements before the onset of the\\ngo signal. Our ORT system predicted which hand the patient would raise 0.5 s\\nbefore the go signal with 68?3% accuracy in two patients. Based on these results,\\nwe constructed an ORT system that tracked up to 30 electrodes simultaneously,\\nand tested it on retrospective data from 7 patients. On average, we could predict\\nthe correct hand choice in 83% of the trials, which rose to 92% if we let the system\\ndrop 3/10 of the trials on which it was less confident. Our system demonstrates?\\nfor the first time?the feasibility of accurately predicting a binary action on single\\ntrials in real time for patients with intracranial recordings, well before the action\\noccurs.\\n\\n1\\n\\n\\f1\\n\\nIntroduction\\n\\nThe work of Benjamin Libet [1, 2] and others [3, 4] has challenged our intuitive notions of the relation between decision making and conscious voluntary action. Using electrocorticography (EEG),\\nthese experiments measured brain potentials from subjects that were instructed to flex their wrist at a\\ntime of their choice and note the position of a rotating dot on a clock when they felt the urge to move.\\nThe results suggested that a slow cortical wave measured over motor areas?termed ?readiness potential? [5], and known to precede voluntary movement [6]?begins a few hundred milliseconds before the average reported time of the subjective ?urge? to move. This suggested that action onset and\\ncontents could be decoded from preparatory motor signals in the brain before the subject becomes\\naware of an intention to move and of the contents of the action. However, the readiness potential\\nwas computed by averaging over 40 or more trials aligned to movement onset after the fact. More\\nrecently, it was shown that action contents can be decoded using functional magnetic-resonance\\nimaging (fMRI) several seconds before movement onset [7]. But, while done on a single-trial basis,\\ndecoding the neural signals took place off-line, after the experiment was concluded, as the sluggish\\nnature of fMRI hemodynamic signals precluded real-time analysis. Moreover, the above studies\\nfocused on arbitrary and meaningless action?purposelessly raising the left or right hand?while\\nwe wanted to investigate prediction of reasoned action in more realistic, everyday situations with\\nconsequences for the subject.\\nIntracranial recordings are good candidates for single-trial, ORT analysis of action onset and contents [8, 9], because of the tight temporal pairing of LFP to the underlying neuronal signals. Moreover, such recordings are known to be cleaner and more robust, with signal-to-noise ratios up to\\n100 times larger than surface recordings like EEG [10, 11]. We therefore took advantage of a rare\\nopportunity to work with epilepsy patients implanted with intracranial electrodes for clinical purposes. Our ORT system (Fig. 1) predicts, with far above chance accuracy, which one of two future\\nactions is about to occur on this one trial and feeds the prediction back to the experimenter, all\\nbefore the onset of the go signal that triggers the patient?s movement (see Experimental Methods).\\nWe achieve relatively high prediction performance using only part of the data?learning from brain\\nactivity in past trials only (Fig. 2) to predict future ones (Fig. 3)?while still running the analysis\\nquickly enough to act upon the prediction before the subject moved.\\n\\n2\\n2.1\\n\\nExperimental Methods\\nSubjects\\n\\nSubjects in this experiment were 8 consenting intractable epilepsy patients that were implanted with\\nintracranial electrodes as part of their presurgical clinical evaluation (ages 18?60, 3 males). They\\nwere inpatients in the neuro-telemetry ward at the Cedars Sinai Medical Center or the Huntington\\nMemorial Hospital, and are designated with CS or HMH after their patient numbers, respectively. Six\\nof them?P12CS, P15CS, P22CS and P29?31HMH were implanted with intracortical depth electrodes targeting their bilateral anterior-cingulate cortex, amygdala, hippocampus and orbitofrontal\\ncortex. These electrodes had eight 40 ?m microwires at their tips, 7 for recording and 1 serving as\\na local ground. Two patients, P15CS and P22CS, had additional microwires in the supplementary\\nmotor area. We utilized the LFP recorded from the microwires in this study. Two other patients,\\nP16CS and P19CS, were implanted with an 8?8 subdural grid (64 electrodes) over parts of their\\ntemporal and prefrontal dorsolateral cortices. The data of one patient?P31HMH?was excluded\\nbecause microwire signals were too noisy for meaningful analysis. The institutional review boards\\nof Cedars Sinai Medical Center, the Huntington Memorial Hospital and the California Institute of\\nTechnology approved the experiments.\\nDuring the experiment, the subject sat in a hospital bed in a semi-inclined ?lounge chair? position.\\nThe stimulus/analysis computer (bottom left of Fig. 4) displaying the game screen (bottom right\\ninset of Fig. 4) was positioned to be easily viewable for the subject. When playing against the\\nexperimenter, the latter sat beside the bed. The response box was placed within easy reach of the\\nsubject (Fig. 4).\\n2\\n\\n\\f2.2\\n\\nExperiment Design\\n\\nAs part of our focus on purposeful, reasoned action, we had the subjects play a matching-pennies\\ngame?a 2-choice version of ?rock paper scissors??either against the experimenter or against a\\ncomputer. The subjects pressed down a button with their left hand and another with their right on a\\nresponse box. Then, in each trial, there was a 5 s countdown followed by a go signal, after which\\nthey had to immediately lift one of their hands. It was agreed beforehand that the patient would win\\nthe trial if she lifted a different hand than her opponent, and lose if she raised the same hand as her\\nopponent. Both players started off with a fixed amount of money, $5, and in each trial $0.10 was\\ndeducted from the loser and awarded to the winner. If a player lifted her hand before the go signal,\\ndid not lift her hand within 500 ms of the go signal, or lifted no hand or both hands at the go signal?\\nan error trial?she lost $0.10 without her opponent gaining any money. The subjects were shown the\\ncountdown, the go signal, the overall score, and various instructions on a stimulus computer placed\\nbefore them (Fig. 4). Each game consisted of 50 trials. If, at the end of the game, the subject had\\nmore money than her opponent, she received that money in cash from the experimenter.\\nBefore the experimental session began, the experimenter explained the rules of the game to the subject, and she could practice playing the game until she was familiar with it. Consequently, patients\\nusually made only few errors during the games (<6% of the trials). Following the tutorial, the subject played 1?3 games against the computer and then once against the experimenter, depending on\\ntheir availability and clinical circumstances. The first 2 games of P12CS were removed because\\nthe subject tended to constantly raise the right hand regardless of winning or losing. Two patients,\\nP15CS and P19CS, were tested in actual ORT conditions. In such sessions?3 games each?the\\nsubjects always played against the experimenter. These ORT games were different from the other\\ngames in two respects. First, a computer screen was placed behind the patient, in a location where\\nshe could not see it. Second, the experimenter was wearing earphones (Fig. 1,4). Half a second before go-signal onset, an arrow pointing towards the hand that the system predicted the experimenter\\nhad to raise to win the trial was displayed on that screen. Simultaneously, a monophonic tone was\\nplayed in the experimenter?s earphone ipsilateral to that hand. The experimenter then lifted that hand\\nat the go signal (see Supplemental Movie).\\n\\nCheetah Machine\\nCollect\\nand save\\ndata\\n\\nPatient\\nwith intracranial electrodes\\n\\nDown\\nsampling\\n\\nBuffer\\n\\n1Gbps\\nRouter\\n\\nTTL Signal\\n\\nThe winner is\\nPlayer 1\\nPLAYER 1 PLAYER 2\\nSCORE 1\\n\\nAnalysis/stimulus machine\\n\\nSCORE 2\\n\\nResponse Box Game Screen\\n\\n/\\nExperimenter\\n\\nResult\\nInterpreta\\ntion\\n\\nAnalysis\\n\\nFiltering\\n\\nDisplay/Sound\\n\\nFigure 1: A schematic diagram of the on-line real-time (ORT) system. Neural signals flow from\\nthe patient through the Cheetah machine to the analysis/stimulus computer, which controls the input\\nand output of the game and computes the prediction of the hand the patient would raise at the go\\nsignal. It displays it on a screen behind the patient and informs the experimenter which hand to raise\\nby playing a tone in his ipsilateral ear using earphones.\\n\\n3\\n\\n\\f3\\n3.1\\n\\nThe real-time system\\nHardware and software overview\\n\\n?V\\n\\n?V\\n\\n?V\\n\\nNeural data from the intracranial electrodes were transferred to a recording system (Neuralynx,\\nDigital Lynx), where it was collected and saved to the local Cheetah machine, down sampled\\nfrom 32 kHz to 2 kHz and buffered. The data were then transferred, through a dedicated 1 Gbps\\nlocal-area network, to the analysis/stimulus machine. This computer first band-pass-filtered the\\ndata to the 0.1?5 Hz range (delta and lower theta bands) using a second-order zero-lag elliptic\\nfilter with an attenuation of 40 dB (cf. Figs. 2a and 2b). We found that this frequency range?\\ngenerally comparable to that of the readiness potential?resulted in optimal prediction performance.\\nIt then ran the analysis algorithm (see below) on the filtered data. This computer also controlled\\nthe game screen, displaying the names of the players, their current scores and various instructions.\\nThe analysis/stimulus computer further\\ncontrolled the response box, which con- (a)\\n800\\nsisted of 4 LED-lit buttons. The buttons of the subject and her opponent\\n600\\nflashed red or blue whenever she or her\\n?5\\n?4\\n?3\\n?2\\n?1\\n0\\nopponent won, respectively. Addition(b)100\\nally, the analysis/stimulus computer sent\\n0\\na unique transistor-transistor logic (TTL)\\n?100\\n?200\\npulse whenever the game screen changed\\n?5\\n?4\\n?3\\n?2\\n?1\\n0\\nor a button was pressed on the response\\nbox, which synchronized the timing of (c) 100\\n0\\nthese events with the LFP recordings.\\n?100\\nIn real-time game sessions, the analy?200\\n?5\\n?4\\n?3\\n?2\\n?1\\n0\\nsis/stimulus computer also displayed the\\nappropriate arrow on the computer screen (d) 1\\nbehind the subject and played the tone\\n0\\nto the appropriate ear of the experimenter\\n?1\\n0.5 s before go-signal onset (Figs. 1,4).\\n?5\\n?4\\n?3\\n?2\\n?1\\n0\\nThe analysis software was based on a\\nmachine-learning algorithm that trained\\non past-trials data to predict the current\\ntrial and is detailed below. The training phase included the first 70% of the\\ntrials, with the prediction carried out on\\nthe remaining 30% using the trained parameters, together with an online weighting system (see below). The system examined only neural activity, and had no\\naccess to the subject?s left/right-choice\\nhistory. After filtering all the training\\ntrials (Fig. 2b), the system found the\\nmean and standard error over all leftward\\nand rightward training trials, separately\\n(Fig. 2c, left designated in red). It then\\nfound the electrodes and time windows\\nwhere the left/right separation was high\\n(Fig. 2d,e; see below), and trained the classifiers on these time windows (Fig. 2f?g).\\nThe best electrode/time-window/classifier\\n(ETC) combinations were then used to\\npredict the current trial in the prediction\\nphase (Fig. 3). The number of ETCs that\\ncan be actively monitored is currently limited to 10 due to the computational power\\nof the real-time system.\\n\\nEl 49?T1\\n\\n(e)\\n\\nEl 49?T2\\n\\nEl 49?T3\\n\\n1\\n0\\n?1\\n?5\\n\\n?4\\n\\n?3\\n?2\\n?1\\nCountdown to go signal at t=0 (seconds)\\n\\n0\\n\\n(f)\\nClassifier\\nCf1\\n\\nClassifier\\nCf2\\n\\n...\\n\\nClassifier\\nCf6\\n\\nEl 49?T1?Cf1\\nEl 49?T1?Cf2\\nEl 49?T1?Cf6\\n...\\nEl 49?T2?Cf1\\nEl 49?T2?Cf2\\nEl 49?T2?Cf6\\nEl 49?T3?Cf1\\nEl 49?T3?Cf2\\nEl 49?T3?Cf6\\n\\n(g)\\nCombination\\nEl49-T1-Cf2\\n\\nCombination\\nEl49-T2-Cf2\\n\\n...\\n\\nCombination\\nEl49-T2-Cf6\\n\\nFigure 2: The ORT-system?s training phase. Left (in\\nred) and right (in blue) raw signals (a) are low-pass filtered (b). Mean?standard errors of signals preceeding left- and right-hand movments (c) are used to compute a left/right separability index (d), from which time\\nwindows with good separation are found (e). Seven\\nclassifiers are then applied to all the time windows (f)\\nand the best electrode/time-window/classifier combinations are selected (g) and used in the prediction phase\\n(Fig. 3).\\n\\n4\\n\\n\\f?V\\n\\n100\\n0\\n?100\\n?200\\n?5\\n\\n?4\\n\\n?3\\n\\n?2\\n\\n?1\\n\\n0\\n\\nTrained classifiers\\n\\nCombination\\nE l 49?T1?Cf2\\n\\nCombination\\nE l 49?T2?Cf2\\n\\nWeight = 1\\n\\nWeight = 1\\n\\nCombination\\nE l 49?T2?Cf6\\n\\n&\\n\\nWeight = 1\\n\\nPredicted result\\nL\\n\\nL\\n\\nL\\n\\nL\\n\\nL\\n\\nR\\n\\nL\\n\\n&\\n\\nR\\n\\nL\\nReal result\\n\\nAdjust the weights\\n\\nL\\n\\n==\\n\\nFigure 3: The ORT-system?s prediction phase. A new signal?from 5 to 0.5 seconds before the\\ngo signal?is received in real time, and each electrode/time-window/classifier combination (ETC)\\nclassifies it as resulting in left- or right-hand movement. These predictions are then compared to the\\nactual hand movement, with the weights associated with ETCs that correctly (incorrectly) predicted\\nincreasing (decreasing).\\n\\n3.2\\n\\nComputing optimal left/right-separating time windows\\n\\nThe algorithm focused on finding the time windows with the best left/right separation for the different recording electrodes over the training set (Fig. 2c?e). That is, we wanted to predict whether\\nthe signal aN (t) on trial N will result in a leftward or rightward movement?i.e., whether the label of the N th trial will be Lt or Rt, respectively. For each electrode, we looked at the N ? 1\\nprevious trials a1 (t), a2 (t), . . . , aN ?1 (t), and their associated labels as l1 , l2 , . . . , lN ?1 . Now, let\\nN ?1\\n?1\\nL(t) = {ai (t) | li = Lt}N\\ni=1 and R(t) = {ai (t) | li = Rt}i=1 be the set of previous leftward and\\nrightward trials in the training set, respectively. Furthermore, let Lm (t) (Rm (t)) and Ls (t) (Rs (t))\\nbe the mean and standard error of L(t) (R(t)), respectively. We can now define the normalized\\nrelative left/right separation for each electrode at time t (see Fig. 2d):\\n?\\n[Lm (t) ? Ls (t)] ? [Rm (t) + Rs (t)]\\n?\\n?\\nif [Lm (t) ? Ls (t)] ? [Rm (t) + Rs (t)] > 0\\n?\\n?\\nLm (t) ? Rm (t)\\n?\\n?\\n?\\n?\\n?\\n[Rm (t) ? Rs (t)] ? [Lm (t) + Ls (t)]\\n?(t) =\\n?\\nif [Rm (t) ? Rs (t)] ? [Lm (t) + Ls (t)] > 0\\n?\\n?\\n?\\nRm (t) ? Lm (t)\\n?\\n?\\n?\\n?\\n?\\n?\\n0\\notherwise\\nThus, ?(t) > 0 (?(t) < 0) means that the leftward trials tend to be considerably higher (lower)\\nthan rightward trials for that electrode at time t, while ?(t) = 0 suggests no left/right separation at\\ntime t. We define a consecutive time period of |?(t)| > 0 for t < prediction time (the time before\\nthe go signal when we want the system to output a prediction; -0.5 s for the ORT trials) as a time\\nwindow (Fig. 2e). After all time windows are found for all electrodes, time windows lessRthan M ms\\nt\\napart are combined into one. Then, for each time window from t1 to t2 we define a = t12 |?(t)|dt.\\nWe then eliminate all time windows satisfying a < A. We found the values M = 200 ms and\\nA = 4, 500 ?V ? ms to be optimal for real-time analysis. This resulted in 20?30 time windows over\\nall 64 electrodes that we monitored.\\n5\\n\\n\\f1\\n$4.80\\n\\n$5.20\\n\\nP15CS\\n\\nUri\\n\\nFigure 4: The experimental setup in the clinic. At 400 ms before the go signal, the patient and\\nexperimenter are watching the game screen (inset on bottom right) on the analysis/stimulus computer\\n(bottom left) and still pressing down the buttons of the response box. The realtime system already\\ncomputed a prediction, and thus displays an arrow on the screen behind the patient and plays a tone\\nin the experimenter?s ear ipsilateral to the hand it predicts he should raise to beat the patient (see\\nSupplemental Movie).\\n3.3\\n\\nClassifiers selection and ETC determination\\n\\nWe used ensemble learning with 7 types of relatively simple binary classifiers (due to real-time\\nprocessing considerations) on every electrode?s time windows (Fig. 2f). Classifiers A to G would\\nclassify aN (t) as Lt if:\\nP\\nP\\nP\\n(A) Defining aN,M , Lm,M and Rm,M as aN (t), Lm (t) and Rm (t) over time window M ,\\n\\u0001\\n\\u0001\\n\\u0001\\n(i) sign Rm,M 6= sign aN,M = sign Lm,M , or\\n\\f\\n\\f\\n\\f \\f\\n\\u0001\\n\\u0001\\n\\u0001\\n(ii) sign Rm,M = sign aN,M = sign Lm,M and \\fLm,M \\f > \\fRm,M \\f, or\\n\\f\\n\\f\\n\\f \\f\\n\\u0001\\n\\u0001\\n\\u0001\\n(iii) sign Rm (t) 6= sign SN,M 6= sign Lm (t) and \\fLm,M \\f < \\fRm,M \\f;\\n\\f\\n\\u0001\\n\\u0001\\f \\f\\n\\u0001\\n\\u0001\\f\\n(B) \\fmean aN (t) ? mean Lm (t) \\f < \\fmean aN (t) ? mean Rm (t) \\f;\\n\\f\\n\\f\\n\\u0001\\n\\u0001\\f\\n\\u0001\\n\\u0001\\f\\n(C) \\fmedian aN (t) ? median Lm (t) \\f < \\fmedian aN (t) ? median Rm (t) \\f over the time\\nwindow;\\n\\f\\n\\f\\n\\f\\n\\f\\n\\f\\n(D) aN (t) ? Lm (t)\\fL2 < \\faN (t) ? Rm (t)\\fL2 over the time window;\\n(E) aN (t) is convex/concave like Lm (t) while Rm (t) is concave/convex, respectively;\\n(F) Linear support-vector machine (SVM) designates it as so; and\\n(G) k-nearest neighbors (KNN) with Euclidean distance designates it as so.\\nEach classifier is optimized for certain types of features. To estimate how well its classification\\nwould generalize from the training to the test set, we trained and tested it using a 70/30 crossvalidation procedure within the training set. We tested each classifier on every time window of every\\nelectrode, discarding those with accuracy <0.68, which left 12.0 ? 1.6% of the original 232 ? 18\\nETCs, on average (?standard error). The training phase therefore ultimately output a set of S binary\\nETC combinations (Fig. 2g) that were used in the prediction phase (Fig. 3).\\n3.4\\n\\nThe prediction-phase weighting system\\n\\nIn the prediction phase, each of the overall S binary ETCs calculates a prediction, ci ? {?1, 1} (for\\nright and left, respectively), independently at the desired prediction time. All classifiers are initially\\n6\\n\\n\\fPS\\ngiven the same weight, w1 = w2 = ? ? ? = wS = 1. We then calculate ? = i=1 wi ? ci and predict\\nleft (right) if ? > d (? < ?d), or declare it an undetermined trial if ?d < ? < d. Here d is the\\ndrop-off threshold for the prediction. Thus the larger d is, the more confident the system needs to be\\nto make a prediction, and the larger the proportion of trials on which the system abstains?the dropoff rate. Weight wi associated with ETCi is increased (decreased) by 0.1 whenever ETCi predicts\\nthe hand movement correctly (incorrectly). A constantly erring ETC would therefore be associated\\nwith an increasingly small and then increasingly negative weight.\\n3.5\\n\\nImplementation\\n\\nThe algorithm was implemented in MATLAB 2011a (MathWorks, Natick, MA) as well as in C++\\non Visual Studio 2008 (Microsoft, Redmond, WA) for enhanced performance. The neural signals\\nwere collected by the Digital Lynx S system using Cheetah 5.4.0 (Neuralynx, Redmond, WA). The\\nsimulated-ORT system was also implemented in MATLAB 2011a. The simulated-ORT analyses\\ncarried out in this paper used real patient data saved on the Digital Lynx system.\\n1\\n\\n0.9\\n\\nDrop rate:\\nNone\\n0.18\\n0\\u0011\\u0016\\u0013\\n\\nPrediction accuracy\\n\\n0.8\\n\\n0.7\\nSignificant accuracy\\n(p=0.05)\\n0.6\\n\\n0.5\\n\\n?5\\n\\n?4.5\\n\\n?4\\n\\n?3.5\\n\\n?3\\n\\n?2.5\\nTime (s)\\n\\n?2\\n\\n?1.5\\n\\n?1\\n\\n?0.5\\n\\n0\\nGo-signal\\nonset\\n\\nFigure 5: Across-subjects average of the prediction accuracy of simulated-ORT versus time before\\nthe go signal. The mean accuracies over time when the system predicts on every trial, is allowed\\nto drop 19% or 30% of the trials, are depicted in blue, green and red, respectively (?standard error\\nshaded). Values above the dashed horizontal line are significant at p = 0.05.\\n\\n4\\n\\nResults\\n\\nWe tested our prediction system in actual real time on 2 patients?P15CS and P19CS (a depth\\nand grid patient, respectively), with a prediction time of 0.5 s before the go signal (see Supplementary Movie). Because of computational limitations, the ORT system could only track 10\\nelectrodes with just 1 ETC per electrode in real time. For P15CS, we achieved an accuracy of\\n72?2% (?standard error; accuracy = number of accurately predicted trials / [total number of trials - number of dropped trials]; p = 10?8 , binomial test) without modifying the weights online during the prediction (see Section 3.4). For P19CS we did not run patient-specific training of the ORT system, and used parameter values that were good on average over previous patients instead. The prediction accuracy was significantly above chance 63?2% (?standard error; p = 7 ? 10?4 , binomial test). To understand how much we could improve our accuracy\\nwith optimized hardware/software, we ran the simulated-ORT at various prediction times along\\n7\\n\\n\\fAccuracy\\n\\nthe 5 s countdown leading to the go signal. We further tested 3 drop-off rates?0, 0.19 and\\n0.30 (Fig. 5; drop-off rate = number of dropped trials / total number of trials; these resulted\\nfrom 3 drop-off thresholds?0, 0.1 and 0.2?respectively, see Section 3.4:). Running offline,\\nwe were able to track 20?30 ETCs, which resulted in considerably higher accuracies (Figs. 5,6).\\nAveraged over all subjects, the accuracy rose from about 65% more than\\n1\\n4 s before the go signal to 83?92%\\nclose to go-signal onset, depending\\n0.9\\non the allowed drop-off rate. In particular, we found that for a predic0.8\\ntion time of 0.5 s before go-signal\\nonset, we could achieve accuracies\\n0.7\\nof 81?5% and 90?3% (?standard\\nerror) for P15CS and P19CS, re0.6\\nspectively, with no drop off (Fig. 6).\\nPatients:\\nP12CS\\nWe also analyzed the weights that\\nP15CS\\nour weighting system assigned to the\\n0.5\\nP16CS\\nP19CS\\ndifferent ETCs. We found that the\\nP22CS\\nempirical distribution of weights to\\nP29HMH\\n0.4\\nP30HMH\\nETCs associated with classifiers A to\\nG was, on average: 0.15, 0.12, 0.16,\\n?5 ?4.5 ?4 ?3.5 ?3 ?2.5 ?2 ?1.5 ?1 ?0.5 0\\n0.22, 0.01, 0.26 and 0.07, respecTime before go signal (at t=0) (seconds)\\ntively. This suggests that the linear\\nSVM and L2-norm comparisons (of\\naN to Lm and Rm ) together make up Figure 6: Simulated-ORT accuracy over time for individual\\nnearly half of the overall weights at- patients with no drop off.\\ntributed to the classifiers, while the\\ncurrent concave/convex measure is of\\nlittle use as a classifier.\\n\\n5\\n\\nDiscussion\\n\\nWe constructed an ORT system that, based on intracranial recordings, predicted which hand a person would raise well before movement onset at accuracies much greater than chance in a competitive environment. We further tested this system off-line, which suggested that with optimized\\nhardware/software, such action contents would be predictable in real time at relatively high accuracies already several seconds before movement onset. Both our prediction accuracy and drop-off\\nrates close to movement onset are superior to those achieved before movement onset with noninvasive methods like EEG and fMRI [7, 12?14]. Importantly, our subjects played a matching pennies game?a 2-choice version of rock-paper-scissors [15]?to keep their task realistic, with minor\\nthough real consequences, unlike the Libet-type paradigms whose outcome bears no consequences\\nfor the subjects. It was suggested that accurate online, real-time prediction before movement onset\\nis key to investigating the relation between the neural correlates of decisions, their awareness, and\\nvoluntary action [16, 17]. Such prediction capabilities would facilitate many types of experiments\\nthat are currently infeasible. For example, it would make it possible to study decision reversals on\\na single-trial basis, or to test whether subjects can guess above chance which of their action contents are predictable from their current brain activity, potentially before having consciously made up\\ntheir mind [16, 18]. Accurately decoding these preparatory motor signals may also result in earlier\\nand improved classification for brain-computer interfaces [13, 19, 20]. The work we present here\\nsuggests that such ORT analysis might well be possible.\\nAcknowledgements\\nWe thank Ueli Rutishauser, Regan Blythe Towel, Liad Mudrik and Ralph Adolphs for meaningful\\ndiscussions. This research was supported by the Ralph Schlaeger Charitable Foundation, Florida\\nState University?s ?Big Questions in Free Will? initiative and the G. Harold & Leila Y. Mathers\\nCharitable Foundation.\\n8\\n\\n\\fReferences\\n[1] B. Libet, C. Gleason, E. Wright, and D. Pearl. Time of conscious intention to act in relation to\\nonset of cerebral activity (readiness-potential): The unconscious initiation of a freely voluntary\\nact. Brain, 106:623, 1983.\\n[2] B. Libet. Unconscious cerebral initiative and the role of conscious will in voluntary action.\\nBehavioral and brain sciences, 8:529?539, 1985.\\n[3] P. Haggard and M. Eimer. On the relation between brain potentials and the awareness of\\nvoluntary movements. Experimental Brain Research, 126:128?133, 1999.\\n[4] A. Sirigu, E. Daprati, S. Ciancia, P. Giraux, N. Nighoghossian, A. Posada, and P. Haggard.\\nAltered awareness of voluntary action after damage to the parietal cortex. Nature Neuroscience,\\n7:80?84, 2003.\\n[5] H. Kornhuber and L. Deecke. Hirnpotenti?alanderungen bei Willk?urbewegungen und passiven\\nBewegungen des Menschen: Bereitschaftspotential und reafferente Potentiale. Pfl?ugers Archiv\\nEuropean Journal of Physiology, 284:1?17, 1965.\\n[6] H. Shibasaki and M. Hallett. What is the Bereitschaftspotential? Clinical Neurophysiology,\\n117:2341?2356, 2006.\\n[7] C. Soon, M. Brass, H. Heinze, and J. Haynes. Unconscious determinants of free decisions in\\nthe human brain. Nature Neuroscience, 11:543?545, 2008.\\n[8] I. Fried, R. Mukamel, and G. Kreiman. Internally generated preactivation of single neurons in\\nhuman medial frontal cortex predicts volition. Neuron, 69:548?562, 2011.\\n[9] M. Cerf, N. Thiruvengadam, F. Mormann, A. Kraskov, R. Quian Quiorga, C. Koch, and\\nI. Fried. On-line, voluntary control of human temporal lobe neurons. Nature, 467:1104?1108,\\n2010.\\n[10] T. Ball, M. Kern, I. Mutschler, A. Aertsen, and A. Schulze-Bonhage. Signal quality of simultaneously recorded invasive and non-invasive EEG. Neuroimage, 46:708?716, 2009.\\n[11] G. Schalk, J. Kubanek, K. Miller, N. Anderson, E. Leuthardt, J. Ojemann, D. Limbrick,\\nD. Moran, L. Gerhardt, and J. Wolpaw. Decoding two-dimensional movement trajectories\\nusing electrocorticographic signals in humans. Journal of Neural engineering, 4:264, 2007.\\n[12] O. Bai, V. Rathi, P. Lin, D. Huang, H. Battapady, D. Y. Fei, L. Schneider, E. Houdayer, X. Chen,\\nand M. Hallett. Prediction of human voluntary movement before it occurs. Clinical Neurophysiology, 122:364?372, 2011.\\n[13] O. Bai, P. Lin, S. Vorbach, J. Li, S. Furlani, and M. Hallett. Exploration of computational\\nmethods for classification of movement intention during human voluntary movement from\\nsingle trial EEG. Clinical Neurophysiology, 118:2637?2655, 2007.\\n[14] U. Maoz, A. Arieli, S. Ullman, and C. Koch. Using single-trial EEG data to predict laterality\\nof voluntary motor decisions. Society for Neuroscience, 38:289.6, 2008.\\n[15] C. Camerer. Behavioral game theory: Experiments in strategic interaction. Princeton University Press, 2003.\\n[16] J. D. Haynes. Decoding and predicting intentions. Annals of the New York Academy of Sciences, 1224:9?21, 2011.\\n[17] P. Haggard. Decision time for free will. Neuron, 69:404?406, 2011.\\n[18] J. D. Haynes. Beyond libet. In W. Sinnott-Armstrong and L. Nadel, editors, Conscious will\\nand responsibility, pages 85?96. Oxford University Press, 2011.\\n[19] A. Muralidharan, J. Chae, and D. M. Taylor. Extracting attempted hand movements from EEGs\\nin people with complete hand paralysis following stroke. Frontiers in neuroscience, 5, 2011.\\n[20] E. Lew, R. Chavarriaga, S. Silvoni, and J. R. Milln. Detection of self-paced reaching movement\\nintention from EEG signals. Frontiers in Neuroengineering, 5:13, 2012.\\n\\n9\\n\\n\\f\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "# Print head\n",
        "papers.head()\n",
        "papers.head(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "vscode": {
          "languageId": "python"
        },
        "id": "NVls5Rqtz7Fl",
        "outputId": "4e830537-9730-42cd-9dfb-63a857ff124a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 412
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                 id         year  \\\n",
              "count   6560.000000  6560.000000   \n",
              "unique          NaN          NaN   \n",
              "top             NaN          NaN   \n",
              "freq            NaN          NaN   \n",
              "mean    3314.574238  2005.343750   \n",
              "std     1901.990197     8.481128   \n",
              "min        1.000000  1987.000000   \n",
              "25%     1675.750000  1999.000000   \n",
              "50%     3318.500000  2007.000000   \n",
              "75%     4959.250000  2013.000000   \n",
              "max     6603.000000  2016.000000   \n",
              "\n",
              "                                                    title event_type  \\\n",
              "count                                                6560       1741   \n",
              "unique                                               6560          3   \n",
              "top     Self-Organization of Associative Database and ...     Poster   \n",
              "freq                                                    1       1505   \n",
              "mean                                                  NaN        NaN   \n",
              "std                                                   NaN        NaN   \n",
              "min                                                   NaN        NaN   \n",
              "25%                                                   NaN        NaN   \n",
              "50%                                                   NaN        NaN   \n",
              "75%                                                   NaN        NaN   \n",
              "max                                                   NaN        NaN   \n",
              "\n",
              "                                                 pdf_name          abstract  \\\n",
              "count                                                6560              6560   \n",
              "unique                                               6560              3244   \n",
              "top     1-self-organization-of-associative-database-an...  Abstract Missing   \n",
              "freq                                                    1              3317   \n",
              "mean                                                  NaN               NaN   \n",
              "std                                                   NaN               NaN   \n",
              "min                                                   NaN               NaN   \n",
              "25%                                                   NaN               NaN   \n",
              "50%                                                   NaN               NaN   \n",
              "75%                                                   NaN               NaN   \n",
              "max                                                   NaN               NaN   \n",
              "\n",
              "                                               paper_text  \n",
              "count                                                6560  \n",
              "unique                                               6553  \n",
              "top     Dialog-based Language Learning\\n\\nJason Weston...  \n",
              "freq                                                    2  \n",
              "mean                                                  NaN  \n",
              "std                                                   NaN  \n",
              "min                                                   NaN  \n",
              "25%                                                   NaN  \n",
              "50%                                                   NaN  \n",
              "75%                                                   NaN  \n",
              "max                                                   NaN  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-64ef53fd-397c-4172-bce3-18637d7a81ba\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>year</th>\n",
              "      <th>title</th>\n",
              "      <th>event_type</th>\n",
              "      <th>pdf_name</th>\n",
              "      <th>abstract</th>\n",
              "      <th>paper_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>6560.000000</td>\n",
              "      <td>6560.000000</td>\n",
              "      <td>6560</td>\n",
              "      <td>1741</td>\n",
              "      <td>6560</td>\n",
              "      <td>6560</td>\n",
              "      <td>6560</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>unique</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>6560</td>\n",
              "      <td>3</td>\n",
              "      <td>6560</td>\n",
              "      <td>3244</td>\n",
              "      <td>6553</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>top</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Self-Organization of Associative Database and ...</td>\n",
              "      <td>Poster</td>\n",
              "      <td>1-self-organization-of-associative-database-an...</td>\n",
              "      <td>Abstract Missing</td>\n",
              "      <td>Dialog-based Language Learning\\n\\nJason Weston...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>freq</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>1505</td>\n",
              "      <td>1</td>\n",
              "      <td>3317</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>3314.574238</td>\n",
              "      <td>2005.343750</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>1901.990197</td>\n",
              "      <td>8.481128</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>1987.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>1675.750000</td>\n",
              "      <td>1999.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>3318.500000</td>\n",
              "      <td>2007.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>4959.250000</td>\n",
              "      <td>2013.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>6603.000000</td>\n",
              "      <td>2016.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-64ef53fd-397c-4172-bce3-18637d7a81ba')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-64ef53fd-397c-4172-bce3-18637d7a81ba button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-64ef53fd-397c-4172-bce3-18637d7a81ba');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-4f1eac7e-89e5-4462-a9d4-e3fae6cde13a\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-4f1eac7e-89e5-4462-a9d4-e3fae6cde13a')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-4f1eac7e-89e5-4462-a9d4-e3fae6cde13a button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"papers\",\n  \"rows\": 11,\n  \"fields\": [\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2369.4338997298355,\n        \"min\": 1.0,\n        \"max\": 6603.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          3314.574237804878,\n          3318.5,\n          6560.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"year\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1848.4793604387764,\n        \"min\": 8.48112838076802,\n        \"max\": 6560.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          2005.34375,\n          2007.0,\n          6560.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"title\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"6560\",\n          \"Self-Organization of Associative Database and Its Applications\",\n          \"1\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"event_type\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          3,\n          \"1505\",\n          \"1741\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pdf_name\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"6560\",\n          \"1-self-organization-of-associative-database-and-its-applications.pdf\",\n          \"1\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"abstract\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          3244,\n          \"3317\",\n          \"6560\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"paper_text\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          6553,\n          \"2\",\n          \"6560\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "papers.describe(include='all')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jJu-Ghp2z7Fl"
      },
      "source": [
        "** **\n",
        "#### Step 2: Data Cleaning <a class=\"anchor\\\" id=\"clean_data\"></a>\n",
        "** **\n",
        "\n",
        "Since the goal of this analysis is to perform topic modeling, let's focus only on the text data from each paper, and drop other metadata columns. Also, for the demonstration, we'll only look at 100 papers\n",
        "\n",
        "\n",
        "After completion, try and sample more papers and look at the results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "vscode": {
          "languageId": "python"
        },
        "id": "_RGy6ODkz7Fm",
        "outputId": "e9f22ee0-3896-4f20-86a1-c86ee7df1ab9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Empty DataFrame\n",
            "Columns: [id, year, title, event_type, pdf_name, abstract, paper_text]\n",
            "Index: []\n"
          ]
        }
      ],
      "source": [
        "print(papers.head(0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "vscode": {
          "languageId": "python"
        },
        "id": "xbkkjiQZz7Fm",
        "outputId": "9d385d3e-563e-47ee-994f-bee7659bad96",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      year                                              title  \\\n",
              "2098  2005  Divergences, surrogate loss functions and expe...   \n",
              "2766  2008  Learning to Use Working Memory in Partially Ob...   \n",
              "1784  2004  Learning Efficient Auditory Codes Using Spikes...   \n",
              "3040  2009         Nash Equilibria of Static Prediction Games   \n",
              "4383  2013  Approximate Gaussian process inference for the...   \n",
              "\n",
              "                                               abstract  \\\n",
              "2098                                   Abstract Missing   \n",
              "2766  Working memory is a central topic of cognitive...   \n",
              "1784                                   Abstract Missing   \n",
              "3040  The standard assumption of identically distrib...   \n",
              "4383  We introduce a nonparametric approach for esti...   \n",
              "\n",
              "                                             paper_text  \n",
              "2098  Divergences, surrogate loss functions and\\nexp...  \n",
              "2766  Learning to use Working Memory in Partially\\nO...  \n",
              "1784  Learning efficient auditory codes using spikes...  \n",
              "3040  Nash Equilibria of Static Prediction Games\\n\\n...  \n",
              "4383  Approximate Gaussian process inference for the...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-fab45d62-cf8c-40c0-a077-057d01c4c0c7\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>year</th>\n",
              "      <th>title</th>\n",
              "      <th>abstract</th>\n",
              "      <th>paper_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2098</th>\n",
              "      <td>2005</td>\n",
              "      <td>Divergences, surrogate loss functions and expe...</td>\n",
              "      <td>Abstract Missing</td>\n",
              "      <td>Divergences, surrogate loss functions and\\nexp...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2766</th>\n",
              "      <td>2008</td>\n",
              "      <td>Learning to Use Working Memory in Partially Ob...</td>\n",
              "      <td>Working memory is a central topic of cognitive...</td>\n",
              "      <td>Learning to use Working Memory in Partially\\nO...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1784</th>\n",
              "      <td>2004</td>\n",
              "      <td>Learning Efficient Auditory Codes Using Spikes...</td>\n",
              "      <td>Abstract Missing</td>\n",
              "      <td>Learning efficient auditory codes using spikes...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3040</th>\n",
              "      <td>2009</td>\n",
              "      <td>Nash Equilibria of Static Prediction Games</td>\n",
              "      <td>The standard assumption of identically distrib...</td>\n",
              "      <td>Nash Equilibria of Static Prediction Games\\n\\n...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4383</th>\n",
              "      <td>2013</td>\n",
              "      <td>Approximate Gaussian process inference for the...</td>\n",
              "      <td>We introduce a nonparametric approach for esti...</td>\n",
              "      <td>Approximate Gaussian process inference for the...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fab45d62-cf8c-40c0-a077-057d01c4c0c7')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-fab45d62-cf8c-40c0-a077-057d01c4c0c7 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-fab45d62-cf8c-40c0-a077-057d01c4c0c7');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-88cd9511-7dfb-4d87-986e-7112a2b8bc32\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-88cd9511-7dfb-4d87-986e-7112a2b8bc32')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-88cd9511-7dfb-4d87-986e-7112a2b8bc32 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "papers",
              "summary": "{\n  \"name\": \"papers\",\n  \"rows\": 100,\n  \"fields\": [\n    {\n      \"column\": \"year\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 8,\n        \"min\": 1987,\n        \"max\": 2016,\n        \"num_unique_values\": 29,\n        \"samples\": [\n          2011,\n          2012,\n          1995\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"title\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 100,\n        \"samples\": [\n          \"Induction of Multiscale Temporal Structure\",\n          \"Layer-wise analysis of deep networks with Gaussian kernels\",\n          \"A Hierarchical Model of Visual Rivalry\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"abstract\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 44,\n        \"samples\": [\n          \"ROC curves are one of the most widely used displays to evaluate performance of scoring functions. In the paper, we propose a statistical method for directly optimizing the ROC curve. The target is known to be the regression function up to an increasing transformation and this boils down to recovering the level sets of the latter. We propose to use classifiers obtained by empirical risk minimization of a weighted classification error and then to construct a scoring rule by overlaying these classifiers. We show the consistency and rate of convergence to the optimal ROC curve of this procedure in terms of supremum norm and also, as a byproduct of the analysis, we derive an empirical estimate of the optimal ROC curve.\",\n          \"We present a nonparametric Bayesian approach to inverse reinforcement learning (IRL) for multiple reward functions. Most previous IRL algorithms assume that the behaviour data is obtained from an agent who is optimizing a single reward function, but this assumption is hard to be met in practice. Our approach is based on integrating the Dirichlet process mixture model into Bayesian IRL. We provide an efficient Metropolis-Hastings sampling algorithm utilizing the gradient of the posterior to estimate the underlying reward functions, and demonstrate that our approach outperforms the previous ones via experiments on a number of problem domains.\",\n          \"We propose probabilistic latent variable models for multi-view anomaly detection, which is the task of finding instances that have inconsistent views given multi-view data. With the proposed model, all views of a non-anomalous instance are assumed to be generated from a single latent vector. On the other hand, an anomalous instance is assumed to have multiple latent vectors, and its different views are generated from different latent vectors. By inferring the number of latent vectors used for each instance with Dirichlet process priors, we obtain multi-view anomaly scores. The proposed model can be seen as a robust extension of probabilistic canonical correlation analysis for noisy multi-view data. We present Bayesian inference procedures for the proposed model based on a stochastic EM algorithm. The effectiveness of the proposed model is demonstrated in terms of performance when detecting multi-view anomalies.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"paper_text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 100,\n        \"samples\": [\n          \"Induction of Multiscale Temporal Structure\\n\\nMichael C. Moser\\nDepartment of Computer Science &:\\nInstitute of Cognitive Science\\nUniversity of Colorado\\nBoulder, CO 80309-0430\\n\\nAbstract\\nLearning structure in temporally-extended sequences is a difficult computational problem because only a fraction of the relevant information is\\navailable at any instant. Although variants of back propagation can in\\nprinciple be used to find structure in sequences, in practice they are not\\nsufficiently powerful to discover arbitrary contingencies, especially those\\nspanning long temporal intervals or involving high order statistics. For\\nexample, in designing a connectionist network for music composition, we\\nhave encountered the problem that the net is able to learn musical structure that occurs locally in time-e.g., relations among notes within a musical phrase-but not structure that occurs over longer time periods--e.g.,\\nrelations among phrases. To address this problem, we require a means\\nof constructing a reduced deacription of the sequence that makes global\\naspects more explicit or more readily detectable. I propose to achieve this\\nusing hidden units that operate with different time constants. Simulation\\nexperiments indicate that slower time-scale hidden units are able to pick\\nup global structure, structure that simply can not be learned by standard\\nback propagation.\\nMany patterns in the world are intrinsically temporal, e.g., speech, music, the unfolding of events. Recurrent neural net architectures have been devised to accommodate time-varying sequences. For example, the architecture shown in Figure 1\\ncan map a sequence of inputs to a sequence of outputs. Learning structure in\\ntemporally-extended sequences is a difficult computational problem because the input pattern may not contain all the task-relevant information at any instant. Thus,\\n275\\n\\n\\f276\\n\\nMozer\\n\\nFigure 1: A generic recurrent network architecture for processing input and output\\nsequences. Each box corresponds to a layer of units, each line to full connectivity\\nbetween layers.\\n\\nthe context layer must hold on to relevant aspects of the input history until a later\\npoint in time at which they can be used.\\n\\nIn principle, variants of back propagation for recurrent networks (Rumelhart, Hinton, &; Williams, 1986; Williams &; Zipser, 1989) can discover an appropriate representation in the context layer for a particular task. In practice, however, back\\npropagation is not sufficiently powerful to discover arbitrary contingencies, especially those that span long temporal intervals or that involve high order statistics\\n(e.g., Mozer, 1989j Rohwer, 1990j Schmidhuber, 1991).\\nLet me present a simple situation where back propagation fails. It involves remembering an event over an interval of time. A variant of this task was first studied\\nby Schmid huber (1991). The input is a sequence of discrete symbols: A, B, C, D,\\n. \\\", I, Y. The task is to predict the next symbol in the sequence. Each sequence\\nbegins with either an I or a Y-call this the trigger .ymbol--and is followed by a\\nfixed sequence such as ABCDE, which in turn is followed by a second instance of the\\ntrigger symbol, i.e., IABCDEI or or YABCDEY. To perform the prediction task, it is\\nnecessary to store the trigger symbol when it is first presented, and then to recall\\nthe same symbol five time steps later.\\nThe number of symbols intervening between the two triggers-call this the gapcan be varied. By training different networks on different gaps, we can examine\\nhow difficult the learning task is as a function of gap. To better control the experiments, all input sequences had the same length and consisted of either I or Y\\nfollowed by ABCDEFGHIJK. The second instance of the trigger symbol was inserted\\nat various points in the sequence. For example, IABCDIEFGHIJK represents a gap of\\n4, YABCDEFGHYIJK a gap of 8.\\nEach training set consisted of two sequences, one with I and one with Y. Different\\nnetworks were trained on different gaps. The network architecture consisted of one\\ninput and output unit per symbol, and ten context units. Twenty-five replications\\nof each network were run with different random initial weights. IT the training set\\nwas not learned within 10000 epochs, the replication was counted as a \\\"failure.\\\"\\nThe primary result was that training sets with gaps of 4 or more could not be\\nlearned reliably, as shown in Table 1.\\n\\n\\fInduction of Multiscale Temporal Structure\\n\\nTable 1: LearnIng conf mgencles across Eaps\\ngap % failure. mean # epoch.\\nto learn\\n2\\n468\\n0\\n7406\\n4\\n36\\n6\\n92\\n9830\\n8\\n10000\\n100\\n10\\n10000\\n100\\nThe results are suprisingly poor. My general impression is that back propagation\\nis powerful enough to learn only structure that is fairly local in time. For instance,\\nin earlier work on neural net music composition (Mozer & Soukup, 1991), we found\\nthat our network could master the rules of composition for notes within a musical\\nphrase, but not rules operating at a more global level-rules for how phrases are\\ninterrelated.\\nThe focus of the present work is on devising learning algorithms and architectures\\nfor better handling temporal structure at more global scales, as well as multiscale\\nor hierarchical structure. This difficult problem has been identified and studied by\\nseveral other researchers, including Miyata and Burr (1990), Rohwer (1990), and\\nSchmidhuber (1991).\\n\\n1\\n\\nBUILDING A REDUCED DESCRIPTION\\n\\nThe basic idea behind my work involves building a redueed de.eription (Hinton,\\n1988) of the sequence that makes global aspects more explicit or more readily detectable. The challenge of this approach is to devise an appropriate reduced description. I've experimented with a scheme that constructs a reduced description that is\\nessentially a bud's eye view of the sequence, sacrificing a representation of individual elements for the overall contour of the sequence. Imagine a musical tape played\\nat double the regular speed. Individual sounds are blended together and become\\nindistinguishable. However, coarser time-scale events become more explicit, such as\\nan ascending trend in pitch or a repeated progression of notes. Figure 2 illustrates\\nthe idea. The curve in the left graph, depicting a sequence of individual pitches,\\nhas been smoothed and compressed to produce the right graph. Mathematically,\\n\\\"smoothed and compressed\\\" means that the waveform has been low-pass filtered\\nand sampled at a lower rate. The result is a waveform in which the alternating\\nupwards and downwards :ftow is unmistakable.\\nMultiple views of the sequence are realized using context units that operate with\\ndifferent time eon.tantl:\\n\\n(1)\\nwhere Ci(t) is the activity of context unit i at time t, net,(t) is the net input to\\nunit i at time t, including activity both from the input layer and the recurrent\\ncontext connections, and\\nis a time constant associated with each unit that has\\nthe range (0,1) and determines the responsiveness of the unit-the rate at which\\n\\nT,\\n\\n277\\n\\n\\f278\\n\\nMozer\\n\\n(a)\\n\\np\\ni\\nt\\n\\n(b)\\n\\nP\\ni\\nt\\n\\nc\\n\\nc\\n\\nh\\n\\nh\\n\\ntime\\n\\nreduced\\ndescription\\n\\ntime\\n(compressed)\\n\\nFigure 2: (a) A sequence of musical notes. The vertical axis indicates the pitch, the\\nhorizontal axis time. Each point corresponds to a particular note. (b) A smoothed,\\ncompact view of the sequence.\\n\\nits activity changes. With 7'i == 0, the activation rule reduces to the standard one\\nand the unit can sharply change its response based on a new input. With large 7'i,\\nthe unit is sluggish, holding on to much of its previous value and thereby averaging\\nthe response to the net input over time. At the extreme of 7'i == 1, the second term\\ndrops out and the unit's activity becomes fixed. Thus, large 7'i smooth out the\\nresponse of a context unit over time. Note, however, that what is smoothed is the\\nactivity of the context units, not the input itself as Figure 2 might suggest.\\nSmoothing is one property that distinguishes the waveform in Figure 2b from the\\noriginal. The other property, compactness, is also achieved by a large 7'i, although\\nsomewhat indirectly. The key benefit of the compact waveform in Figure 2b is that\\nit allows a longer period of time to be viewed in a single glance, thereby explicating\\ncontingencies occurring in this interval during learning. The context unit activation\\nrule (Equation 1) permits this. To see why this is the case, consider the relation\\nbetween the error derivative with respect to the context units at time t, 8E/8c(t),\\nand the error back propagated to the previous step, t - 1. One contribution to\\n8E/8ci(t - 1), from the first term in Equation 1, is\\n\\n(2)\\nThis means that when\\n\\n7'i\\n\\nis large, most of the error signal in context unit i at time\\n\\nt is carried back to time t - 1. Intuitively, just as the activation of units with large\\nchanges slowly forward in time, the error propagated back through these units\\nchanges slowly too. Thus, the back propagated error signal can make contact with\\npoints further back in time, facilitating the learning of more global structure in the\\ninput sequence.\\n7'i\\n\\nTime constants have been incorporated into the activation rules of other connectionist architectures (Jordan, 1987; McClelland, 1979; Mozer, 1989; Pearlmutter,\\n1989; Pineda, 1987). However, none of this work has exploited time constants to\\ncontrol the temporal responsivity of individual units.\\n\\n\\fInduction of Multiscale Temporal Structure\\n\\n2\\n\\nLEARNING AABA PHRASE PATTERNS\\n\\nA simple simulation illustrates the benefits of temporal reduced descriptions. I\\ngenerated pseudo musical phrases consisting of five notes in ascending chromatic\\norder, e.g., F#2 G2 G#2 12 1#2 or C4 C#4 Dot D#4 &ot, where the first pitch was selected\\nat random. 1 Pairs of phrases-call them A and B-were concatenated to form an\\nAABA pattern, terminated by a special EID marker. The complete melody then\\nconsisted of 21 elements-four phrases offive notes followed by the EID marker-an\\nexample of which is:\\n\\nTwo versions of CONCERT were tested, each with 35 context units. In the ,tandard\\nversion, all 35 units had T\\n0; in the reduced de.eMption or RD version, 30 had\\nT\\n0 and 5 had T\\n0.8. The training set consisted of 200 examples and the test set\\nanother 100 examples. Ten replications of each simulation were run for 300 passes\\nthrough the training set. See Mozer and Soukup (1991) for details of the network\\narchitecture and note representations.\\n\\n=\\n\\n=\\n\\n=\\n\\nBecause ofthe way that the sequences are organized, certain pitches can be predicted\\nbased on local structure whereas other pitches require a more global memory of\\nthe sequence. In particular, the second through fifth pitches within a phrase can\\nbe predicted based on knowledge of the immediately preceding pitch. To predict\\nthe first pitch in the repeated A phrases and to predict the EID marker, more\\nglobal information is necessary. Thus, the analysis was split to distinguish between\\npitches requiring only local structure and pitches requiring more global structure.\\nAs Table 2 shows, performance requiring global structure was significantly better\\nfor the RD version (F(l,9)=179.8, p < .001), but there was only a marginally\\nreliable difference for performance involving local structure (F(l,9)=3.82, p=.08).\\nThe global structure can be further broken down to prediction of the EID marker\\nand prediction of the first pitch of the repeated A phrases. In both cases, the\\nperformance improvement for the RD version was significant: 88.0% versus 52.9%\\nfor the end of sequence (F(l,9)=220, p < .001); 69.4% versus 61.2% for the first\\npitch (F(l,9)=77.6, p < .001).\\nExperiments with different values of T in the range .7-.95 yielded qualitatively\\nsimilar results, as did experiments in which the A and B phrases were formed by\\nrandom walks in the key of C major.\\nlOne need not understand the musical notation to make sense of this example. Simply\\nconsider each note to be a unique symbol in a set of symbols having a fixed ordering. The\\nexample is framed in terms of music because my original work involved music composition.\\n\\nTable 2: Performance on AABA phrases\\n.trueture .tandard ver,ion RD ver.ion\\nlocal\\n96.7%\\n97.3%\\nglobal\\n58.4%\\n75.6%\\n\\n279\\n\\n\\f280\\n\\nMozer\\n\\n3\\n\\nDETECTING CONTINGENCIES ACROSS GAPSREVISITED\\n\\nI now return to the prediction task involving sequences containing two I's or Y's\\nseparated by a stream of intervening symbols. A reduced description network had\\nno problem learning the contingency across wide gaps. Table 3 compares the results\\npresented earlier for a standard net with ten context units and the results for an\\nRD net having six standard context units (T\\n0) and four units having identical\\nnonzero T, in the range of .75-.95. More on the choice of T below, but first observe\\nthat the reduced description net had a100% success rate. Indeed, it had no difficulty\\nwith much wider gaps: I tested gaps of up to 25 symbols. The number of epochs to\\nlearn scales roughly linearly with the gap.\\n\\n=\\n\\nWhen the task was modified slightly such that the intervening symbols were randomly selected from the set {!,B,e,D}, the RD net still had no difficulty with the\\nprediction task.\\nThe bad news here is that the choice of T can be important. In the results reported\\nabove, T was selected to optimize performance. In general, a larger T was needed\\nto span larger gaps. For sma.ll gaps, performance was insensitive to the particular T\\nchosen. However, the larger the temporal gap that had to be spanned, the sma.ller\\nthe range of T values that gave acceptable results. This would appear to be a serious\\nlimitation of the approach. However, there are several potential solutions.\\n1. One might try using back propagation to train the time constants directly. This\\ndoes not work particularly well on the problems I've examined, apparently\\nbecause the path to an appropriate T is fraught with local optima. Using\\ngradient descent to fine tune T, once it's in the right neighborhood, is somewhat\\nmore successful.\\n\\n2. One might include a complete range of T values in the context layer. It is not\\ndifficult to determine a rough correspondence between the choice of T and the\\ntemporal interval to which a unit is optimally tuned. If sufficient units are\\nused to span a range of intervals, the network should perform well. The down\\nside, of course, is that this gives the network an excess of weight parameters\\nwith which it could potentia.lly overfit the training data. However, because the\\ndifferent T correspond to different temporal scales, there is much less freedom\\nto abuse the weights here than, say, in a situation where additional hidden\\nunits are added to a feedforward network.\\n\\ngap\\n2\\n4\\n6\\n8\\n10\\n\\nTable 3: Learning contingencies across gaps (revisited)\\n,tandard net\\nreduced de,criptaon net\\n% failure, mean # epoch,\\n% failure, mean # epoch,\\nto learn\\nto learn\\n0\\n468\\n0\\n328\\n36\\n7406\\n0\\n584\\n92\\n9830\\n0\\n992\\n100\\n10000\\n0\\n1312\\n100\\n10000\\n0\\n1630\\n\\n\\fInduction of Multiscale Temporal Structure\\n\\nupper\\nnet\\n\\nlower\\nnet\\n\\nFigure 3: A sketch of the Schmidhuber (1991) architecture\\n\\n3. One might dynamically adjust T as a sequence is presented based on external\\ncriteria. In Section 5, I discuss one such criterion.\\n\\n4\\n\\nMUSIC COMPOSITION\\n\\nI have used music composition as a domain for testing and evaluating different\\napproaches to learning multiscale temporal structure. In previous work (Mozer &;\\nSoukup, 1991), we designed a sequential prediction network, called CONCERT, that\\nlearns to reproduce a set of pieces of a particular musical style. CONCERT also\\nlearns structural regularities of the musical style, and can be used to compose new\\npieces in the same style. CONCERT was trained on a set of Bach pieces and a set of\\ntraditional European folk melodies. The compositions it produces were reasonably\\npleasant, but were lacking in global coherence. The compositions tended to wander\\nrandomly with little direction, modulating haphazardly from major to minor keys,\\nflip-flopping from the style of a march to that of a minuet. I attribute these problems\\nto the fact that CONCERT had learned only local temporal structure.\\nI have recently trained CONCERT on a third set of examples-waltzes-and have\\nincluded context units that operate with a range of time constants. There is a\\nconsensus among listeners that the new compositions are more coherent. I am\\npresently running more controlled simulations using the same musical training set\\nand versions of CONCERT with and without reduced descriptions, and am attempting\\nto quantify CONCERT'S abilities at various temporal scales.\\n\\n5\\n\\nA HYBRID APPROACH\\n\\nSchmidhuber (1991; this volume) has proposed an alternative approach to learning\\nmultiscale temporal structure in sequences. His approach, the chunking architecture,\\nbasically involves two (or more) sequential prediction networks cascaded together\\n(Figure 3). The lower net receives each input and attempts to predict the next\\ninput. When it fails to predict reliably, the next input is passed to the upper net.\\nThus, once the lower net has been trained to predict local temporal structure, such\\nstructure is removed from the input to the upper net. This simplifies the task of\\nlearning global structure in the upper net.\\n\\n281\\n\\n\\f282\\n\\nMozer\\n\\nSchmidhuber's approach has some serious limitations, as does the approach I've described. We have thus merged the two in a scheme that incorporates the strengths\\nof each approach (Schmidhuber, Prelinger, Mozer, Blumenthal, &: Mathis, in preparation). The architecture is the same as depicted in Figure 3, except that all units\\nin the upper net have associated with them a time constant Tu , and the prediction\\nerror in the lower net determines Tu. In effect, this allows the upper net to kick in\\nonly when the lower net fails to predict. This avoid the problem of selecting time\\nconstants, which my approach suffers. This also avoids the drawback of Schmidhuber's approach that yes-or-no decisions must be made about whether the lower net\\nwas successful. Initial simulation experiments indicate robust performance of the\\nhybrid algorithm.\\nAcknowledgements\\nThis research was supported by NSF Presidential Young Investigator award ffiI-9058450,\\ngrant 90--21 from the James S. McDonnell Foundation, and DEC extemal research grant\\n1250. Thanks to Jiirgen Schmidhuber and Paul Smolensky for helpful comments regarding\\nthis work, and to Darren Hardy for technical assistance.\\n\\nReferences\\nHinton, G. E. (1988). Representing part-whole hierarchies in connectionist networks.\\nProceeding' of the Eighth Annual Conference of the Cognitive Science Society.\\nJordan, M. I. (1987). Attractor dynamics and parallelism in a connectionist sequential\\nmachine. In Proceeding, of the Eighth Annual Conference of the Cognitive Science\\nSociety (pp. 531-546). Hillsdale, NJ: Erlbaum.\\nMcClelland, J. L. (1979). On the time relations of mental processes: An examination of\\nsystems of processes in cascade. P,ychological Review, 86, 287-330.\\nMiyata, Y., k Burr, D. (1990). Hierarchical recurrent networks for learning musical structure. Unpublished Manuscript.\\nMoser, M. C. (1989). A focused back-propagation algorithm for temporal pattem recognition. Complez Syltem\\\" 3, 349-381.\\nMoser, M. C., k Soukup, T. (1991). CONCERT: A connectionist composer of erudite\\ntunes. In R. P. Lippmann, J. Moody, k D. S. Tourebky (Eds.), Advance, in neural\\ninformation proce\\\"ing ,ylteml 3 (pp. 789-796). San Mateo, CA: Morgan Kaufmann.\\nPearlmutter, B. A. (1989). Learning state space trajectories in recurrent neural networks.\\nNeural Computation, 1, 263-269.\\nPineda, F. (1987). Generalisation of back propagation to recurrent neural networks. Phy,ical Review Letter\\\" 19, 2229-2232.\\nRohwer, R. (1990). The 'moving targets' training algorithm. In D. S. Tourebky (Ed.),\\nAdvance, in neural information proce\\\"ing ,yltem, I (pp. 558-565). San Mateo, CA:\\nMorgan Kaufmann.\\nRumelhart, D. E., Hinton, G. E., k Williams, R. J. (1986). Learning intemal representations by error propagation. In D. E. Rumelhart k J. L. McClelland (Eds.), Parallel\\ndi,tributed proce\\\"ing: Ezploration, in the microltructure of cognition. Volume I:\\nFoundation, (pp. 318-362). Cambridge, MA: MIT Press/Bradford Books.\\nSchmidhuber, J. (1991). Neural ,equence chunker, (Report FKI-148-91). Munich, Germany: Technische Universitaet Muenchen, Institut fuel Informatik.\\nWilliams, R. J., k Zipser, D. (1989). A learning algorithm for continually running fully\\nrecurrent neural networks. Neural Computation, 1, 270--280.\\n\\n\\f\",\n          \"Layer-wise analysis of deep networks with Gaussian\\nkernels\\nGr?egoire Montavon\\nMachine Learning Group\\nTU Berlin\\n\\nMikio L. Braun\\nMachine Learning Group\\nTU Berlin\\n\\n?\\nKlaus-Robert Muller\\nMachine Learning Group\\nTU Berlin\\n\\ngmontavon@cs.tu-berlin.de\\n\\nmikio@cs.tu-berlin.de\\n\\nkrm@cs.tu-berlin.de\\n\\nAbstract\\nDeep networks can potentially express a learning problem more efficiently than local learning machines. While deep networks outperform local learning machines\\non some problems, it is still unclear how their nice representation emerges from\\ntheir complex structure. We present an analysis based on Gaussian kernels that\\nmeasures how the representation of the learning problem evolves layer after layer\\nas the deep network builds higher-level abstract representations of the input. We\\nuse this analysis to show empirically that deep networks build progressively better representations of the learning problem and that the best representations are\\nobtained when the deep network discriminates only in the last layers.\\n\\n1\\n\\nIntroduction\\n\\nLocal learning machines such as nearest neighbors classifiers, radial basis function (RBF) kernel\\nmachines or linear classifiers predict the class of new data points from their neighbors in the input\\nspace. A limitation of local learning machines is that they cannot generalize beyond the notion\\nof continuity in the input space. This limitation becomes detrimental when the Bayes classifier\\nhas more variations (ups and downs) than the number of labeled samples available. This situation\\ntypically occurs on problems where an instance ? let?s say, a handwritten digit ? can take various\\nforms due to irrelevant variation factors such as its position, its size, its thickness and more complex\\ndeformations. These multiple factors of variation can greatly increase the complexity of the learning\\nproblem (Bengio, 2009).\\nThis limitation motivates the creation of learning machines that can map the input space into a\\nhigher-level representation where regularities of higher order than simple continuity in the input\\nspace can be expressed. Engineered feature extractors, nonlocal kernel machines (Zien et al., 2000)\\nor deep networks (Rumelhart et al., 1986; LeCun et al., 1998; Hinton et al., 2006; Bengio et al., 2007)\\ncan implement these more complex regularities. Deep networks implement them by distorting the\\ninput space so that initially distant points in the input space appear closer. Also, their multilayered\\nnature acts as a regularizer, allowing them to share at a given layer features computed at the previous\\nlayer (Bengio, 2009). Understanding how the representation is built in a deep network and how to\\ntrain it efficiently received a lot of attention (Goodfellow et al., 2009; Larochelle et al., 2009; Erhan\\net al., 2010). However, it is still unclear how their nice representation emerges from their complex\\nstructure, in particular, how the representation evolves from layer to layer.\\nThe main contribution of this paper is to introduce an analysis based on RBF kernels and on the\\nkernel principal component analysis (kPCA, Sch?olkopf et al., 1998) that can capture and quantify the\\nlayer-wise evolution of the representation in a deep network. In practice, for each layer 1 ? l ? L\\nof the deep network, we take a small labeled dataset D, compute its image D(l) at the layer l of the\\ndeep network and measure what dimensionality the local model built on top of D(l) must have in\\norder to solve the learning problem with a certain accuracy.\\n1\\n\\n\\fl=0\\n\\ny\\n\\nf2\\nl=1\\n\\ny\\nx\\n\\nf3\\nl=2\\n\\ny\\nf1 (x)\\n\\nl=3\\n\\ny\\nf2 (f1 (x))\\n\\nf3 (f2 (f1 (x)))\\n\\nl\\nl\\nl\\nl\\n\\n=\\n=\\n=\\n=\\n\\n0\\n1\\n2\\n3\\n\\ndimensionality d\\nerror e(do )\\n\\nf1\\n\\nerror e(d)\\n\\noutput\\n\\ninput\\n\\nlayer l\\n\\nFigure 1: As we move from the input to the output of the deep network, better representations of\\nthe learning problem are built. We measure this improvement with the layer-wise RBF analysis\\npresented in Section 2 and Section 3.2. This analysis relates the prediction error e(d) to the dimensionality d of a local model built at each layer of the deep network. As the data is propagated\\nthrough the deep network, lower errors are obtained with lower-dimensional local models. The plots\\non the right illustrate this dynamic where the thick gray arrows indicate the forward path of the deep\\nnetwork and where do is a fixed number of dimensions.\\n\\nWe apply this novel analysis to a multilayer perceptron (MLP), a pretrained multilayer perceptron\\n(PMLP) and a convolutional neural network (CNN). We observe in each case that the error and the\\ndimensionality of the local model decrease as we propagate the dataset through the deep network.\\nThis reveals that the deep network improves the representation of the learning problem layer after\\nlayer. This progressive layer-wise simplification is illustrated in Figure 1. In addition, we observe\\nthat the CNN and the PMLP tend to postpone the discrimination to the last layers, leading to more\\ntransferable features and better-generalizing representations than for the simple MLP. This result\\nsuggests that the structure of a deep network, by enforcing a separation of concerns between lowlevel generic features and high-level task-specific features, has an important role to play in order to\\nbuild good representations.\\n\\n2\\n\\nRBF analysis of a learning problem\\n\\nWe would like to quantify the complexity of a learning problem p(y | x) where samples are drawn\\nindependently from a probability distribution p(x, y). A simple way to do it is to measure how many\\ndegrees of freedom (or dimensionality d) a local model must have in order to solve the learning\\nproblem with a certain error e. This analysis relates the dimensionality d of the local model to its\\nprediction error e(d).\\nIn practice, there are many ways to define the dimensionality of a model, for example, (1) the\\nnumber of samples given to the learning machine, (2) the number of required hidden nodes of a\\nneural network (Murata et al., 1994), (3) the number of support vectors of a SVM or (4) the number\\nof leading kPCA components of the input distribution p(x) used in the model. The last option is\\nchosen for the following two reasons:\\nFirst, the kPCA components are added cumulatively to the prediction model as the dimensionality of\\nthe model increases, thus offering stability, while in the case of support vector machines, previously\\nchosen support vectors might be dropped in favor of other support vectors in higher-dimensional\\nmodels.\\nSecond, the leading kPCA components obtained with a finite and typically small number of samples\\nn are similar to those that would be obtained in the asymptotic case where p(x, y) is fully observed\\n(n ? ?). This property is shown by Braun (2006) and Braun et al. (2008) in the case of a single\\nkernel, and by extension, in the case of a finite set of kernels.\\nThis last property is particularly useful since p(x, y) is unknown and only a finite number of observations are available. The analysis presented here is strongly inspired from the relevant dimensionality\\nestimation (RDE) method of Braun et al. (2008) and is illustrated in Figure 2 for a small two2\\n\\n\\fd=1\\ne(d) = 0.5\\n\\nd=2\\ne(d) = 0.25\\n\\nd=3\\ne(d) = 0.25\\n\\nd=4\\ne(d) = 0\\n\\nd=5\\ne(d) = 0\\n\\nd=6\\ne(d) = 0\\n\\nFigure 2: Illustration of the RBF analysis on a toy dataset of 12 samples. As we add more and more\\nleading kPCA components, the model becomes more flexible, creating a better decision boundary.\\nNote that with four leading kPCA components out of the 12 kPCA components, all the samples are\\nalready classified perfectly.\\ndimensional toy example. In the next lines, we present the computation steps required to estimate\\nthe error as a function of the dimensionality.\\nLet {(x1 , y1 ), . . . , (xn , yn )} be a dataset of n points drawn independently from p(x, y) where yi is\\nan indicator vector having value 1 at the index corresponding to the class of xi and 0 elsewhere. Let\\nX = (x1 , . . . , xn ) and Y = (y1 , . . . , yn ) be the matrices associated to the inputs and labels of the\\ndataset. We compute the kernel matrix K associated to the dataset:\\n\\u0013\\n\\u0012\\nkx ? x? k2\\n?\\n.\\n[K]ij = k(xi , xj )\\nwhere k(x, x ) = exp ?\\n2? 2\\nThe kPCA components u1 , . . . , un are obtained by performing an eigendecomposition of K where\\neigenvectors u1 , . . . , un have unit length and eigenvalues ?1 , . . . , ?n are sorted by decreasing magnitude:\\nK = (u1 | . . . |un ) ? diag(?1 , . . . , ?n ) ? (u1 | . . . |un )\\n\\n?\\n\\n? = (u1 | . . . |ud ) and ?\\n? = diag(?1 , . . . , ?d ) be a d-dimensional approximation of the eigendeLet U\\ncomposition. We fit a linear model ? ? that maps the projection on the d leading components of the\\ntraining data to the log-likelihood of the classes\\n?U\\n? ? ?) ? Y ||2\\n? ? = argmin? || exp(U\\nF\\nwhere ? is a matrix of same size as Y and where the exponential function is applied element-wise.\\nThe predicted class log-probability log(?\\ny ) of a test point (x, y) is computed as\\n??\\n? ?1 U\\n? ??? + C\\nlog(?\\ny ) = k(x, X)U\\nwhere k(x, X) is a matrix of size 1 ? n computing the similarities between the new point and each\\ntraining point and where C is a normalization constant. The test error is defined as:\\ne(d) = Pr(argmax y? 6= argmax y)\\nThe training and test error can be used as an approximation bound for the asymptotic case n ? ?\\nwhere the data would be projected on the real eigenvectors of the input distribution. In the next\\nsections, the training and test error are depicted respectively as dotted and solid lines in Figure 3 and\\nas the bottom and the top of error bars in Figure 4. For each dimension, the kernel scale parameter ?\\nthat minimizes e(d) is retained, leading to a different kernel for each dimensionality. The rationale\\nfor taking a different kernel for each model is that the optimal scale parameter typically shrinks as\\nmore leading components of the input distribution are observed.\\n\\n3\\n\\nMethodology\\n\\nIn order to test our two hypotheses (the progressive emergence of good representations in deep\\nnetworks and the role of the structure for postponing discrimination), we consider three deep networks of interest, namely a convolutional neural network (CNN), a multilayer perceptron (MLP)\\nand a variant of the multilayer perceptron pretrained in an unsupervised fashion with a deep belief\\n3\\n\\n\\fnetwork (PMLP). These three deep networks are chosen in order to evaluate how the two types of\\nregularizers implemented respectively by the CNN and the PMLP impact on the evolution of the\\nrepresentation layer after layer. We describe how they are built, how they are trained and how they\\nare analyzed layer-wise with the RBF analysis described in Section 2.\\nThe multilayer perceptron (MLP) is a deep network obtained by alternating linear transformations\\nand element-wise nonlinearities. Each layer maps an input vector of size m into an output vector\\nof size n and consists of (1) a linear transformation linearm?n (x) = w ? x + b where w is a\\nweight matrix of size n ? m learned from the data and (2) a non-linearity applied element-wise\\nto the output of the linear transformation. Our implementation of the MLP maps two-dimensional\\nimages of 28 ? 28 pixels into a vector of size 10 (the 10 possible digits) by applying successively\\nthe following functions:\\nf1 (x) = tanh(linear28?28?784 (x))\\nf2 (x) = tanh(linear784?784 (x))\\nf3 (x) = tanh(linear784?784 (x))\\nf4 (x) = softmax(linear784?10 (x))\\nThe pretrained multilayer perceptron (Hinton et al., 2006) that we abbreviate PMLP in this paper\\nis a variant of the MLP where weights are initialized with a deep belief network (DBN, Hinton\\net al., 2006) using an unsupervised greedy layer-wise pretraining procedure. This particular weight\\ninitialization acts as a regularizer, allowing to learn better-generalizing representation of the learning\\nproblem than the simple MLP.\\nThe convolutional neural network (CNN, LeCun et al., 1998) is a deep network obtained by ala set of m input features maps\\nternating convolution filters y = convolvea?b\\nm?n (x) transforming\\nPm\\n{x1 , . . . , xm } into a set of n output features maps {yi = j=1 wij ? xj + bi , i = 1 . . . , n} where\\nthe convolution filters wij of size a ? b are learned from data, and pooling units subsampling each\\nfeature map by a factor two. Our implementation maps images of 32 ? 32 pixels into a vector of\\nsize 10 (the 10 possible digits) by applying successively the following functions:\\n5?5\\n(x)))\\nf1 (x) = tanh(pool(convolve1?36\\n5?5\\nf2 (x) = tanh(pool(convolve36?36\\n(x)))\\nf3 (x) = tanh(linear5?5?36?400 (x))\\nf4 (x) = softmax(linear400?10 (x))\\n\\nThe CNN is inspired by the structure of biological visual systems (Hubel and Wiesel, 1962). It\\ncombines three ideas into a single architecture: (1) only local connections between neighboring\\npixels are allowed, (2) the convolution operator applies the same filter over the whole feature map\\nand (3) a pooling mechanism at the top of each convolution filter adds robustness to input distortion.\\nThese mechanisms act as a regularizer on images and other types of sequential data, and learn wellgeneralizing models from few data points.\\n3.1\\n\\nTraining the deep networks\\n\\nEach deep network is trained on the MNIST handwriting digit recognition dataset (LeCun et al.,\\n1998). The MNIST dataset consists of predicting the digit 0 ? 9 from scanned handwritten digits of\\n28 ? 28 pixels. We partition randomly the MNIST training set in three subsets of 45000, 5000 and\\n10000 samples that are respectively used for training the deep network, selecting the parameters of\\nthe deep network and performing the RBF analysis.\\nWe consider three training procedures:\\n1. No training: the weights of the deep network are left at their initial value. If the deep\\nnetwork hasn?t received unsupervised pretraining, the weights are set randomly according\\nto a normal distribution N (0, ? ?1 ) where ? denotes for a given layer the number of input\\nnodes that are connected to a single output node.\\n2. Training on an alternate task: the deep network is trained on a binary classification task that\\nconsists of determining whether the digit is original (positive example) or whether it has\\n4\\n\\n\\fbeen transformed by one of the 11 possible rotation/flip combinations that differs from the\\noriginal (negative example). This problem has therefore 540000 labeled samples (45000\\npositives and 495000 negatives). The goal of training a deep network on an alternate task\\nis to learn features on a problem where the number of labeled samples is abundant and then\\nreuse these features to learn the target task that has typically few labels. In the alternate task\\ndescribed earlier, negative examples form a cloud around the manifold of positive examples\\nand learning this manifold potentially allows the deep network to learn features that can be\\ntransfered to the digit recognition task.\\n3. Training on the target task: the deep network is trained on the digit recognition task using\\nthe 45000 labeled training samples.\\nThese procedures are chosen in order to assess the forming of good representations in deep networks\\nand to test the role of the structure of deep networks on different aspects of learning, such as the\\neffectiveness of random projections, the transferability of features from one task to another and the\\ngeneralization to new samples of the same distribution.\\n3.2\\n\\nApplying the RBF analysis to deep networks\\n\\nIn this section, we explain how the RBF analysis described in Section 2 is applied to analyze layerwise the deep networks presented in Section 3.\\nLet f = fL ?? ? ??f1 be the trained deep network of depth L. Let D be the analysis dataset containing\\nthe 10000 samples of the MNIST dataset on which the deep network hasn?t been trained. For each\\nlayer, we build a new dataset D(l) corresponding to the mapping of the original dataset D to the l\\nfirst layers of the deep network. Note that by definition, the index zero corresponds to the raw input\\ndata (mapped through zero layers):\\n\\u001a\\nD\\nl=0 ,\\n(l)\\nD =\\n{(fl ? ? ? ? ? f1 (x), t) | (x, t) ? D)}\\n1?l?L .\\nThen, for each dataset D(0) , . . . , D(L) we perform the RBF analysis described in Section 2. We use\\nn = 2500 samples for computing the eigenvectors and the remaining 7500 samples to estimate the\\nprediction error of the model. This analysis yields for each dataset D(l) the error as a function of the\\ndimensionality of the model e(d). A typical evolution of e(d) is depicted in Figure 1.\\nThe goal of this analysis is to observe the evolution of e(d) layer after layer for the deep networks\\nand training procedures presented in Section 3 and to test the two hypotheses formulated in Section 1\\n(the progressive emergence of good representations in deep networks and the role of the structure\\nfor postponing discrimination). The interest of using a local model to solve the learning problem\\nis that the local models are blind with respect to possibly better representations that could be obtained in previous or subsequent layers. This local scoping property allows for fine isolation of the\\nrepresentations in the deep network. The need for local scoping also arises when ?debugging? deep\\narchitectures. Sometimes, deep architectures perform reasonably well even when the first layers do\\nsomething wrong. This analysis is therefore able to detect these ?bugs?.\\nThe size n of the dataset is selected so that it is large enough to approximate well the asymptotic\\ncase (n ? ?) but also be small enough so that computing the eigendecomposition of the kernel\\nmatrix of size n ? n is fast. We choose a set of scale parameters for the RBF kernel corresponding\\nto the 0.01, 0.05, 0.10, 0.25, 0.5, 0.75, 0.9, 0.95 and 0.99 quantiles of the distribution of distances\\nbetween pairs of data points.\\n\\n4\\n\\nResults\\n\\nLayer-wise evolution of the error e(d) is plotted in Figure 3 in the supervised training case. The\\nlayer-wise evolution of the error when d is fixed to 16 dimensions is plotted in Figure 4. Both figures\\ncapture the simultaneous reduction of error and dimensionality performed by the deep network when\\ntrained on the target task. In particular, they illustrate that in the last layers, a few number of\\ndimensions is sufficient to build a good model of the target task.\\n5\\n\\n\\fFigure 3: Layer-wise evolution of the error e(d) when the deep network has been trained on the\\ntarget task. The solid line and the dotted line represent respectively the test error and the training\\nerror. As the data distribution is mapped through more and more layers, more accurate and lowerdimensional models of the learning problem can be obtained.\\nFrom these results, we first demonstrate some properties of deep networks trained on an ?asymptotically? large number of samples. Then, we demonstrate the important role of structure in deep\\nnetworks.\\n4.1\\n\\nAsymptotic properties of deep networks\\n\\nWhen the deep network is trained on the target task with an ?asymptotically? large number of samples (45000 samples) compared to the number of dimensions of the local model, the deep network\\nbuilds representations layer after layer in which a low number of dimensions can create more accurate models of the learning problem.\\nThis asymptotic property of deep networks should not be thought of as a statistical superiority of\\ndeep networks over local models. Indeed, it is still possible that a higher-dimensional local model\\napplied directly on the raw data performs as well as a local model applied at the output of the deep\\nnetwork. Instead, this asymptotic property has the following consequence:\\nDespite the internal complexity of deep networks a local interpretation of the representation is possible at each stage of the processing. This means that deep networks do not explode the original data\\ndistribution into a statistically intractable distribution before recombining everything at the output,\\nbut instead, apply controlled distortions and reductions of the input space that preserve the statistical\\ntractability of the data distribution at every layer.\\n4.2\\n\\nRole of the structure of deep networks\\n\\nWe can observe in Figure 4 (left) that even when the convolutional neural network (CNN) and the\\npretrained MLP (PMLP) have not received supervised training, the first layers slightly improve the\\nrepresentation with respect to the target task. On the other hand, the representation built by a simple\\nMLP with random weights degrades layer after layer. This observation highlights the structural\\nprior encoded by the CNN: by convolving the input with several random convolution filters and\\nsubsampling subsequent feature maps by a factor two, we obtain a random projection of the input\\ndata that outperforms the implicit projection performed by an RBF kernel in terms of task relevance.\\nThis observation closely relates to results obtained in (Ranzato et al., 2007; Jarrett et al., 2009) where\\nit is observed that training the deep network while keeping random weights in the first layers still\\nallows for good predictions by the subsequent layers. In the case of the PMLP, the successive layers\\nprogressively disentangle the factors of variation (Hinton and Salakhutdinov, 2006; Bengio, 2009)\\nand simplify the learning problem.\\nWe can observe in Figure 4 (middle) that the phenomenon is even clearer when the CNN and the\\nPMLP are trained on an alternate task: they are able to create generic features in the first layers\\nthat transfer well to the target task. This observation suggests that the structure embedded in the\\nCNN and the PMLP enforces a separation of concerns between the first layers that encode lowlevel features, for example, edge detectors, and the last layers that encode high-level task-specific\\n6\\n\\n\\fFigure 4: Evolution of the error e(do ) as a function of the layer l when do has been fixed to 16\\ndimensions. The top and the bottom of the error bars represent respectively the test error and the\\ntraining error of the local model.\\nMLP, alternate task\\nMLP, target task\\nPMLP, alternate task\\nPMLP, target task\\nCNN, alternate task\\nCNN, target task\\n\\nFigure 5: Leading components of the weights (receptive fields) obtained in the first layer of each\\narchitecture. The filters learned by the CNN and the pretrained MLP are richer than the filters\\nlearned by the MLP. The first component of the MLP trained on the alternate task dominates all\\nother components and prevents good transfer on the target task.\\nfeatures. On the other hand, the standard MLP trained on the alternate task leads to a degradation of\\nrepresentations. This degradation is even higher than in the case of random weights, despite all the\\nprior knowledge on pixel neighborhood contained implicitly in the alternate task.\\nFigure 5 shows that the MLP builds receptive fields that are spatially informative but dissimilar\\nbetween the two tasks. The fact that receptive fields are different for each task indicates that the\\nMLP tries to discriminate already in the first layers. The absence of a built-in separation of concerns\\nbetween low-level and high-level feature extractors seems to be a reason for the inability to learn\\ntransferable features. It indicates that end-to-end transfer learning on unstructured learning machines is in general not appropriate and supports the recent success of transfer learning on restricted\\nportions of the deep network (Collobert and Weston, 2008; Weston et al., 2008) or on structured\\ndeep networks (Mobahi et al., 2009).\\nWhen the deep networks are trained on the target task, the CNN and the PMLP solve the problem\\ndifferently as the MLP. In Figure 4 (right), we can observe that the CNN and the PMLP tend to\\npostpone the discrimination to the last layers while the MLP starts to discriminate already in the first\\nlayers. This result suggests that again, the structure contained in the CNN and the PMLP enforces\\na separation of concerns between the first layers encoding low-level generic features and the last\\nlayers encoding high-level task-specific features. This separation of concerns might explain the\\nbetter generalization of the CNN and PMLP observed respectively in (LeCun et al., 1998; Hinton\\net al., 2006). It also rejoins the findings of Larochelle et al. (2009) showing that the pretraining of the\\nPMLP must be unsupervised and not supervised in order to build well-generalizing representations.\\n\\n5\\n\\nConclusion\\n\\nWe present a layer-wise analysis of deep networks based on RBF kernels. This analysis estimates\\nfor each layer of the deep network the number of dimensions that is necessary in order to model well\\na learning problem based on the representation obtained at the output of this layer.\\n7\\n\\n\\fWe observe that a properly trained deep network creates representations layer after layer in which a\\nmore accurate and lower-dimensional local model of the learning problem can be built.\\nWe also observe that despite a steady improvement of representations for each architecture of interest\\n(the CNN, the MLP and the pretrained MLP), they do not solve the problem in the same way: the\\nCNN and the pretrained MLP seem to separate concerns by building low-level generic features in\\nthe first layers and high-level task-specific features in the last layers while the MLP does not enforce\\nthis separation. This observation emphasizes the limitations of black box transfer learning and, more\\ngenerally, of black box training of deep architectures.\\n\\nReferences\\nY. Bengio, P. Lamblin, D. Popovici, and H. Larochelle. Greedy layer-wise training of deep networks.\\nIn Advances in Neural Information Processing Systems 19, pages 153?160. MIT Press, 2007.\\nYoshua Bengio. Learning deep architectures for AI. Foundations and Trends in Machine Learning,\\n2(1):1?127, 2009.\\nMikio L. Braun. Accurate bounds for the eigenvalues of the kernel matrix. Journal of Machine\\nLearning Research, 7:2303?2328, Nov 2006.\\nMikio L. Braun, Joachim Buhmann, and Klaus-Robert M?uller. On relevant dimensions in kernel\\nfeature spaces. Journal of Machine Learning Research, 9:1875?1908, Aug 2008.\\nR. Collobert and J. Weston. A unified architecture for natural language processing: Deep neural\\nnetworks with multitask learning. In International Conference on Machine Learning, ICML,\\n2008.\\nDumitru Erhan, Yoshua Bengio, Aaron C. Courville, Pierre-Antoine Manzagol, Pascal Vincent, and\\nSamy Bengio. Why does unsupervised pre-training help deep learning? Journal of Machine\\nLearning Research, 11:625?660, 2010.\\nIan Goodfellow, Quoc Le, Andrew Saxe, and Andrew Y. Ng. Measuring invariances in deep networks. In Advances in Neural Information Processing Systems 22, pages 646?654, 2009.\\nG. E. Hinton and R. R. Salakhutdinov. Reducing the dimensionality of data with neural networks.\\nScience, 313(5786):504?507, July 2006.\\nGeoffrey E. Hinton, Simon Osindero, and Yee-Whye Teh. A fast learning algorithm for deep belief\\nnets. Neural Comput., 18(7):1527?1554, 2006.\\nD. H. Hubel and T. N. Wiesel. Receptive fields, binocular interaction and functional architecture in\\nthe cat?s visual cortex. The Journal of physiology, 160:106?154, January 1962.\\nKevin Jarrett, Koray Kavukcuoglu, Marc?Aurelio Ranzato, and Yann LeCun. What is the best multistage architecture for object recognition? In Proc. International Conference on Computer Vision\\n(ICCV?09). IEEE, 2009.\\nHugo Larochelle, Yoshua Bengio, J?er?ome Louradour, and Pascal Lamblin. Exploring strategies for\\ntraining deep neural networks. J. Mach. Learn. Res., 10:1?40, 2009. ISSN 1532-4435.\\nY. LeCun, L. Bottou, Y. Bengio, and P. Haffner. Gradient-based learning applied to document\\nrecognition. Proceedings of the IEEE, 86(1):2278?2324, November 1998.\\nHossein Mobahi, Ronan Collobert, and Jason Weston. Deep learning from temporal coherence\\nin video. In L?eon Bottou and Michael Littman, editors, Proceedings of the 26th International\\nConference on Machine Learning, pages 737?744, Montreal, June 2009. Omnipress.\\nNoboru Murata, Shuji Yoshizawa, and Shun ichi Amari. Network information criterion - determining the number of hidden units for an artificial neural network model. IEEE Transactions on\\nNeural Networks, 5:865?872, 1994.\\nGenevieve B. Orr and Klaus-Robert M?uller, editors. Neural Networks: Tricks of the Trade, this book\\nis an outgrowth of a 1996 NIPS workshop, volume 1524 of Lecture Notes in Computer Science,\\n1998. Springer.\\nM. A. Ranzato, Fu J. Huang, Y. L. Boureau, and Y. LeCun. Unsupervised learning of invariant feature hierarchies with applications to object recognition. In Computer Vision and Pattern Recognition, 2007. CVPR ?07. IEEE Conference on, pages 1?8, 2007.\\n8\\n\\n\\fD. E. Rumelhart, G. E. Hinton, and R. J. Williams. Learning representations by back-propagating\\nerrors. Nature, 323(6088):533?536, 1986.\\nBernhard Sch?olkopf, Alexander Smola, and Klaus-Robert M?uller. Nonlinear component analysis as\\na kernel eigenvalue problem. Neural Comput., 10(5):1299?1319, 1998.\\nJason Weston, Fr?ed?eric Ratle, and Ronan Collobert. Deep learning via semi-supervised embedding.\\nIn ICML ?08: Proceedings of the 25th international conference on Machine learning, pages 1168?\\n1175, 2008.\\nAlexander Zien, Gunnar R?atsch, Sebastian Mika, Bernhard Sch?olkopf, Thomas Lengauer, and\\nKlaus-Robert M?uller. Engineering support vector machine kernels that recognize translation initiation sites. Bioinformatics, 16(9):799?807, 2000.\\n\\n9\\n\\n\\f\",\n          \"An Hierarchical Model of Visual Rivalry\\nPeter Dayan\\nDepartment of Brain and Cognitive Sciences\\nE25-21O Massachusetts Institute of Technology\\nCambridge, MA 02139\\ndayan@psyche.mit.edu 1\\n\\nAbstract\\nBinocular rivalry is the alternating percept that can result when\\nthe two eyes see different scenes. Recent psychophysical evidence\\nsupports an account for one component of binocular rivalry similar\\nto that for other bistable percepts. We test the hypothesisl9, 16, 18\\nthat alternation can be generated by competition between topdown cortical explanations for the inputs, rather than by direct\\ncompetition between the inputs. Recent neurophysiological evidence shows that some binocular neurons are modulated with\\nthe changing percept; others are not, even if they are selective between the stimuli presented to the eyes. We extend our model to\\na hierarchy to address these effects.\\n\\n1\\n\\nIntroduction\\n\\nAlthough binocular rivalry leads to distinct perceptual distress, it is revealing\\nabout the mechanisms of visual information processing. The first accounts for\\nrivalry argued on the basis of phenomena such as increases in thresholds for test\\nstimuli presented in the suppressed eye 24 , 8, 3 that there was a early competitive\\nprocess, the outcome of which meant that the system would just ignore input\\nfrom one eye in favour of the other. Various experiments have suggested that\\nsimple input competition cannot be the whole story. For instance, in a case in\\nwhich rivalry is between a vertical grating in the left eye and a horizontal one\\nin the right, and in which a vertical grating is presented prior to rivalry to cause\\nadaptation, the relative suppression of vertical during rivalry is independent of\\n1 I am very grateful to Bart Anderson, Adam Elga, Geoff Goodhill, Geoff Hinton, David\\nLeopold, Earl Miller, Read Montague, Bruno Olshausen, Pawan Sinha, Rich Zemel, and\\nparticularly Zhaoping Li and Tommi Jaakkola for their comments on earlier drafts and\\ndiscussions. This work was supported by the NIH.\\n\\n\\fA Hierarchical Model of Visual Rivalry\\n\\n49\\n\\nthe eye of origin of the adapting grating. 4 Even more compelling, if the rivalrous\\nstimuli in the two eyes are switched rapidly, the percept switches only slowly competition is more between coherent percepts than merely inputs. Rivalry is an\\nattractive paradigm for studying models of cortex like the Helmholtz machine 12 , 7\\nthat construct coherent percepts, and in particular for studying hierarchical models,\\nbecause of electrophysiological data on the behaviour during rivalry of cells at\\ndifferent levels of the visual processing hierarchy.16\\nLeopold & Logothetis16 trained monkeys to report their percepts during rivalrous\\nand non-rivalrous stimuli whilst recording from neurons VI/2 and V4. Important\\nfindings are that striate monocular neurons are unaffected by rivalry; some striate\\nbinocular neurons that are selective between the stimuli modulate their activities\\nduring rivalry; others do not; some fire more when their preferred stimuli are\\nsuppressed; others still are only selective during rivalry. In this paper we consider\\none form of analysis-by-synthesis model of cortical processing7 and show how it\\ncan exhibit rivalry between explanations in the case that the eyes receive different\\ninput. This model can provide an account for many of the behaviours described\\nabove.\\n\\n2 The Model\\nFigure Ia shows the full generative model. Units in layers y (modeling VI) and\\nx and w (modeling early and late extra-striate areas) are all binocular and jointly\\nexplain successively more complex features in the input z according to a top-down\\ngenerative model. Apart from the half bars in y, the model is similar to that\\nlearned by the Helmholtz machine 12 , 7for which increasing complexity in higher\\nlayers rather than the increasing input scale is key. In this case, for instance, w2\\nspecifies the occurrence of vertical bars anywhere in the 8 x 8 input grids; X16\\nspecifies the rightmost vertical bar; and Y31 and Y32 the top and bottom half of this\\nvertical bar. These specifications are provided by a top-down generative model in\\nwhich the activations of units are specified by probabilities such as P[Yi = Ilx] =\\na (by + Lk xkJ!~) where the sum k is over all the units in the x layer, and 0'0\\nis a robust normal distribution function. We model the percept in terms of the\\nactivation in the w layer.\\nWe model differing input contrasts by representing the input to Zi by di , where\\nP[Zi = 1] = O'(di ) and all the Zi are independent. Recognition is formally the statistical inverse to generation, and should produce distribution P[w, x, yld] over all\\nthe choices of the hidden activations. We use a mean field inversion method,13\\nusing a factorised approximation Q[w,x, y; Il,~,~] = Q[w; Il]Q][x; ~]Q[y; ~], with\\nQ[w; Il] = TIi O'(lli)Wi (1 - O'(lli))l- Wi, etc, and fitting the parameters Il,~, ~ to minimise the approximation cost:\\nd] ' \\\" Q[\\nC .1']1\\nQ[w,x,y;Il,~,~]\\n:F [Il,~, ~ ] = \\\"'P[\\nL.J z;\\nL.J\\nw, x, y; Il, ,-, 'f/ og\\nP[w x Iz] .\\nz\\n\\nwxy\\n, ,\\n\\n,\\n\\n,y\\n\\nWe report the mean activities of the units in the graphs and use a modified gradient\\ndescent method to find appropriate parameters. Figure Ib shows the resulting\\nactivities of units in response to binocular horizontal (i) and vertical (ii) bars, and\\nalso the two equally likely explanations for rivalrous input (iii and iv). For rivalry,\\n\\n\\fP. Dayan\\n\\n50\\n\\n(a)\\n\\n(b)\\n\\nLAYER\\n\\nwi\\n\\n???????\\n??????\\n........\\n??????\\n\\nb? ?\\n\\n~\\n\\ny\\n\\n_\\n\\n? ? ? ?\\n\\nYII\\n\\nwi Ia:::::QJ\\nlib\\n\\n\\\"II~I\\n\\nwl~\\n\\n,,11l1lil1li1111 II\\n\\nyl- ylllllill\\n?1_ ?111111111\\nL\\n\\nL\\n\\nR\\n\\nR\\n\\n(ii)\\n\\n(i)\\n\\nwi !I:::::iJI\\n\\nwl~\\n\\n\\\"II~I\\n\\n\\\"llmBEl\\n\\nyllil yl-\\n\\n?1_ ?1_\\nL\\n\\nR\\n\\nL\\n\\nR\\n\\n(iv)\\n\\n(iii)\\n%\\n\\nL\\n\\nR\\n\\nFigure 1: a) Hierarchical generative model for 8 x 8 bar patterns across the two eyes. Units are\\ndepicted by their net projective (generative) fields, and characteristic weights are shown. Even though\\nthe net projective field of Xl is the top horizontal bar in both eyes, note that it generates this by increasing\\nthe probability that units YI and Y9 in the y layer will be active, not by having direct connections to\\nthe input z. Unit WI connects to Xl, X2, .?? Xs through J wx = 0.8; XI6 connects to Y31 , Y32 through\\nJ XY\\n1.0 and Y32 connects to the bottom right half vertical bar through J yz\\n5.8. Biases are\\nbw = -0 .75,bx = -1.5, by = -2.7 and bz = -3.3. b) Recognition activity in the network for four\\ndifferent input patterns. The units are arranged in the same order as (a), and white and black squares\\nimply activities for the units whose means are less than and greater than 0.5. (i) and (ii) represent normal\\nbinocular stimulation; (iii) and (iv) show the two alternative stable states during rivalrous stimulation,\\nwithout the fatigue process.\\n\\n=\\n\\n=\\n\\nthere is direct competition in the top left hand quadrant of z, which is reflected in the\\ncompetition between YI, Y3 and Y17, Y21. However, the input regions (top right of L\\nand bottom left of R) for which there is no competition, require the constant activity\\nof explanations Y9, Yu ,Y18 and Y22. Under the generative model, the coactivation\\nof YI and Y9 without Xl is quite unlikely (P[XI = OIYI = 1, Y3 = 1] = 0.1), which is\\nwhy XI, X3 and also WI become active with YI and Y3.\\nGiven just gradient descent for the rivalrous stimulus, the network would just find\\none of the two equally good (or rather bad) solutions in figure 1b(iii,iv). Alternation\\nensues when descent is augmented by a fatigue process:\\n\\n=\\n\\n'l/JI(t) +<5(-\\\\7I/JIF[1L,~,'l/J] + a ({3'l/JI (t)) -'l/J~(t))\\n'l/J~ (t) + <5('l/JI (t) - {3'l/J~ (t)),\\n\\nwhere {3 is a decay term. In all the simulations, a = 0.5, {3 = 0.1 and <5 = 0.01.\\nWe adopted various heuristics to simplify the process of using this rather cumbersome mean field model. First, fatigue is only implemented for the units in the y\\n\\n\\fA Hierarchical Model of Visual Rivalry\\n\\n51\\n\\nlayer, and the 'I.jJ follow the equivalent of the dynamical equations above. Although\\nadaptation processes can clearly occur at many levels in the system, and indeed\\nhave been used to try to diagnose the mechanisms of rivalry,15 their exact form is\\nnot clear. Bialek & DeWeese l argue that the rate of a switching process should be\\nadaptive to the expected rate of change of the associated signal on the basis of prior\\nobservations. This is clearly faster nearer to the input.\\nThe second heuristic is that rather than perform gradient descent for the nonfatiguing units, the optimal values of f.1. and ~ are calculated on each iteration by\\nsolving numerically equations such as\\n\\nThe dearth of connections in the network of figure la allows f.1. and ~ to be calculated\\nlocally at each unit in an efficient manner. Whether this is reasonable depends on\\nthe time constants of settling in the mean field model with respect to the dynamics\\nof switching, and, more particularly on the way that this deterministic model is\\nmade appropriately stochastic.\\nFigure 2a shows the resulting activities during rivalry of units at various levels of\\nthe hierarchy including the fatigue process. Broadly, the competing explanations\\nin figure Ib(iii;iv), ie horizontal and vertical percepts, alternate, and units without\\ncompeting inputs, such as Y9, are much less modulated than the others, such as Yl.\\nThe activity of Y9 is slightly elevated when horizontal bars are dominant, based on\\ntop-down connections. The activities of the units higher up, such as Xl and WI, do\\nnot decrease to 0 during the suppression period for horizontal bars, leaving weak\\nactivity during suppression. Many of the modulating cells in monkeys were not\\ncompletely silent during their periods of less activity.16 Figure 2b shows that the\\nhierarchical version of the model also behaves in accordance with experimental\\nresults on the effects of varying the input contrast,17, 10, 22, 16 which suggest that\\nincreasing the contrast in both eyes decreases the period of the oscillation (ie increases the frequency), and increasing the contrast in just one eye decreases the\\nsuppression period for that eye much more than it increases its dominance period.\\n\\n3\\n\\nDiscussion\\n\\nFollowing Logothetis and his colleagues l9 , 16, 18 (see also Grossberg ll ) we have\\nsuggested an account of rivalry based on competing top-down hierarchical explanations, and have shown how it models various experimental observations on\\nrivalry. Neurons explain inputs in virtue of being capable of generating their activities through a top-down statistical generative model. Competition arises between\\nhigher-level explanations of overlapping active regions (ie those involving contrast\\nchanges) of the input rather than between inputs themselves. Note that alternating\\nthe input between the two eyes would have no effect on this behaviour of the\\nmodel, since explanations are competing rather than inputs. Of course, the model\\nis greatly simplified - for instance, it only has units that are not modulating with\\nthe percept in the earliest binocular layer (layer y), whereas in the monkeys, more\\nthan half the cells in V4 were unmodulated during rivalry.I6\\nThe model's accounts of the neurophysiological findings described in the introduction are: i) monocular cells will generally not be modulated if they are involved in\\n\\n\\fP. Dayan\\n\\n52\\na)\\n\\nIterations\\n\\n------+\\n\\no\\n\\n::r\\n\\nb)\\n\\nContrast Dependence\\n\\n600 r - - - - - - - - - - - - - - - - - - - - - ,\\n\\n0.0\\n\\n::\\n\\n-\\n\\nx,\\n\\n00\\n\\n~\\n\\n- - - equal contrast\\nhorizontal dominance (1=1 .25)\\n---- vertical dominance (r)\\n\\nQ)\\n\\n~\\n3\\n\\n~\\n\\n~::n, 1 I 11.1 11-\\\"\\n\\nQ\\n\\nI\\n\\n------ -----500\\n\\n' .0~\\n0.5~-Y.\\n0,0\\n\\nO'-----,:-:':OOO:::-----::2000:::-:-----:::3000~---::.OOO\\n\\n1.0\\n\\n12\\n\\nlA\\n\\n1~\\n\\nTest vertical 'contrast' (r)\\n\\nFigure 2: a) Mean activities of units at three levels of the hierarchy in response to rivalrous stimuli\\nwith input strengths I = r = 1.75. b) Contrast dependence of the oscillation periods for equal input\\nstrengths, and when I = 1.25 and r is varied.\\n\\nexplaining local correlations in the input from a single eye. This model does not\\ndemonstrate this explicitly, but would if, for instance, each of the inputs Zi actually\\nconsisted of two units, which are always on or off together. In this case one could\\nget a compact explanation of the joint activities with a set of monocular units which\\nwould then not be modulated. ii) Units such as Y9 in the hierarchical model are\\nbinocular, are selective between the binocular version of the stimuli, and are barely\\nmodulated with the percept. iii) Units such as YI, Xl and WI are binocular, are\\nselective between the stimuli, and are significantly modulated with the percept.\\nThe final neurophysiological finding is to do with cells that fire when their preferred\\nstimuli are suppressed, or fire selectively between the stimuli only during rivalry.\\nThere are no units in this model that are selective between the stimuli and are\\npreferentially activated during suppression of their preferred stimuli. However, in\\na model with more complicated stimulus contingencies, they would emerge to\\naccount for the parts of the stimulus in the suppressed eye that are not accounted\\nfor by the explanation of the overlying parts of the dominant explanation, at least\\nprovided that this residual between the true monocular stimulus and the current\\nexplanation is sufficiently complex as to require explaining itself.\\nWe would expect to find two sets of cells that are activated during the suppressed\\nperiod by this residual, some of which will form part of the representation of the\\nstimulus when presented binocularly and some of which will not. Those that do\\nnot (class A) will only even appear to be selective between the stimuli during\\nrivalry, and will represent parts of the residual that are themselves explained by\\nmore overarching explanations for parts of the complete (binocularly presented)\\nstimulus. This suggests the experimental test of presenting binocularly a putative\\nform of the residual (eg dotted lines for competing horizontal and vertical gratings).\\nWe predict that these cells should be activated.\\n\\nIf there are cells that do participate in the binocular representation, then they will\\nbe selective, but will preferentially fire during suppression (class B). Certainly, the\\n\\n\\fA Hierarchical Model of Visual Rivalry\\n\\n53\\n\\nresidual will have a high correlation with the full suppressed pattern, and so a\\ncell that is selective for part of the residual could have appropriate properties.\\nHowever, why should such a cell not fire when the full, but currently suppressed,\\npattern is dominant? In monkeys,16 there are fewer class B than class A cells (0\\nversus 3 of 33 cells in Vl/2; 6 versus 8 of 68 cells in V4). Under the model, we\\naccount for these cells based on a competition between units that represent the\\nresidual and those that represent overlapping parts of the complete pattern. In\\nbinocular viewing, explanations are generally stronger than during rivalry. So\\neven if both such units participate in representing a binocular stimulus, the cells\\nrepresenting the residual might not reach threshold during the dominance period.\\nHowever, during suppression, they no longer suffer from competition, and so will\\nbe activated. The model's explanation for class B cells seems far less natural than\\nthat for class A cells. One experimental test would be to present the preferred\\npattern binocularly, reduce the contrast, and see if these cells are suppressed more\\nstrongly.\\nThe overall model mechanistically has much in common with models which place\\nthe competition in rivalry at the level of binocular oriented cells rather than between\\nmonocular cells. 11 ,2 Indeed, the model is based on an explanation-driven account\\nfor normal binocular processing, so this is to be expected. The advantage of\\ncouching rivalry in terms of explanations is that this provides a natural way of\\naccounting for top-down influences. In fact, one can hope to study top-down\\ncontrol through studying its effects on the behaviour of cells during rivalry.\\nThe model suffers from various lacunce. Foremost, it is necessary to model the\\nstochasticity of switching between explanations. 9 ,17 The distributions of dominance times for both humans and monkeys is well characterised by a r distribution\\n(Lehky14 argues that this is descriptive rather than normative), with strong independence between successive dominance periods. Our mean field recognition\\nprocess is deterministic. The stochastic analogue would be some form of Markov\\nchain Monte-Carlo method such as Gibbs sampling. However, it is not obvious\\nhow to incorporate the equivalent of fatigue in a computationally reasonable way.\\nIn any case, the nature of neuronal randomness is subject to significant debate at\\npresent. Note that the recognition model of a stochastic Helmholtz machine 7,6\\nwould be unsuitable, since it is purely feedforward and does not integrate bottomup and top-down information.\\nWe have adopted a very simple mean field approach to recognition, giving up\\nneurobiological plausibility for convenience. The determinism of the mean field\\nmodel in any case rules it out as a complete explanation, but it does at least\\nshow clearly the nature of competition between explanations. The architecture of\\nthe model is also incomplete. The cortex is replete with what we would model\\nas lateral connections between units within a single layer. We have constructed\\ngenerative models in which there are no such direct connections, because they\\nsignificantly complicate the mean field recognition method. It could be that these\\nconnections are important for the recognition process,6 but modeling their effect\\nwould require representing them explicitly. This would also allow modeling of the\\napparent diffusive process by which patches of dominance spread and alter. In a\\ncomplete model, it would also be necessary to account for competition between\\neyes in addition to competition between explanations. 24,8,3\\n\\n\\f54\\n\\nP. Dayan\\n\\nAnother gap is some form of contrast gain control. s The model is quite sensitive\\nto input contrast. This is obviously important for the effects shown in figures 2,\\nhowever the range of contrasts over which it works should be larger. It would be\\nparticularly revealing to explore the effects of changing the contrast in some parts\\nof images and examine the consequent effects on the spreading of dominance.\\n\\nReferences\\n[1] Bialek, W & DeWeese, M (1995). Random switching and optimal processing in the perception of\\nambiguous Signals. Physical Review Letters, 74, 3077-3080.\\n[2] Blake, R (1989). A neural theory of binocular rivalry. Psyclwlogical Review, 96, 145-167.\\n[3] Blake, R & Fox, R (1974). Binocular rivalry suppression: Insensitive to spatial frequency and\\norientation change. Vision Research, 14, 687-692.\\n[4] Blake, R, Westendorf, DH & Overton, R (1980). What is suppressed during binocular rivalry?\\nPerception, 9, 223-231.\\n[5] Carandini, M & Heeger, DJ (1994). Summation and division by neurons in primate visual cortex.\\nScience, 264, 1333-1336.\\n[6] Dayan, P & Hinton, GE (1996). Varieties of Helmholtz machine. Neural Networks, 9, 1385-1403.\\n[7] Dayan, P, Hinton, GE, Neal, RM & Zemel, RS (1995). The Helmholtz machine. Neural Computation,\\n7,889-904.\\n[8] Fox, R & Check, R (1972). Independence between binocular rivalry suppression duration and\\nmagnitude of suppression. Journal of Experimental Psyclwlogy, 93, 283-289.\\n[9] Fox, R & Herrmann, J (1%7). Stochastic properties of binocular rivalry alternations. Perception and\\nPsychophysics, 2, 432-436.\\n[10] Fox, R & Rasche, F (1969). Binocular rivalry and reciprocal inhibition. Perception and Psychophyics,\\n5,215-217.\\n[11] Grossberg, S (1987). Cortical dynamiCS of three-dimensional form, color and brightness perception: 2. Binocular theory. Perception & Psychphysics, 41, 117-158.\\n[12] Hinton, GE, Dayan, P, Frey, BJ & Neal, RM (1995). The wake-sleep algorithm for unsupervised\\nneural networks. Science, 268,1158-1160.\\n[13] Jaakkola, T, Saul, LK & Jordan, MI (1996). Fast learning by bounding likelihoods in sigmoid type\\nbelief networks. Advances in Neural Information Processing Systems, 8, forthcoming.\\n[14] Lehky, SR (1988). An astable multivibrator model of binocular rivalry. Perception, 17, 215-228.\\n[15] Lehky, SR & Blake, R (1991). Organization of binocular pathways: Modeling and data related to\\nrivalry. Neural Computation, 3,44-53.\\n[16] Leopold, DA & Logothetis, NK (1996). Activity changes in early visual cortex reflect monkeys'\\npercepts during binocular rivalry. Nature, 379, 549-554.\\n[17] Levelt, WJM (1968). On Binocular Rivalry. The Hague, Paris: Mouton.\\n[18] Logothetis, NK, Leopold, DA & Sheinberg, DL (1996). What is rivalling during binocular rivalry.\\nNature, 380, 621-624.\\n[19] Logothetis, NK & Schall, JD (1989). Neuronal correlates of subjective visual perception. Science\\\"\\n245,761-763.\\n[20] Matsuoka, K (1984). The dynamic model of binocular rivalry. Biological Cybernetics, 49, 201-208.\\n[21] Mueller, 11 (1990). A physiological model of binocular rivalry. Visual Neuroscience, 4, 63-73.\\n[22] Mueller, 11 & Blake, R (1989). A fresh look at the temporal dynamiCS of binocular rivalry. Biological\\nCybernetics, 61, 223-232.\\n[23] Pearl, J (1988). Probabilistic Reasoning in Intelligent Systems: Networks of Plausible Inference. San\\nMateo, CA: Morgan Kaufmann.\\n[24] Wales, R & Fox, R (1970). Increment detection thresholds during binocular rivalry suppression.\\nPerception and PsychophysiCS, 8, 90-94.\\n[25] Wheatstone, C (1838). Contributions to the theory of vision. I: On some remarkable and hitherto\\nunobserved phenomena of binocular vision. Philosophical Transactions of the Royal Society of London,\\n128,371-394.\\n[26] Wolfe, JM (1986). Stereopsis and binocular rivalry. PsycholOgical Review, 93,269-282.\\n\\n\\f\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "# Remove columns that does not relate to the task and select only the 100 sample for quick implementation\n",
        "papers = papers.drop(columns=['id', 'event_type', 'pdf_name'], axis=1).sample(100)\n",
        "\n",
        "# Print out the first rows of papers\n",
        "papers.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "vscode": {
          "languageId": "python"
        },
        "id": "yvx-AilZz7Fm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cbf69964-b5e3-4806-b9b6-e0715014cce7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(100, 4)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "papers.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PObUVrAhz7Fm"
      },
      "source": [
        "##### Remove punctuation/lower casing\n",
        "\n",
        "Next, let’s perform a simple preprocessing on the content of `paper_text` column to make them more amenable for analysis, and reliable results. To do that, we’ll use a regular expression to remove any punctuation, and then lowercase the text\n",
        "\n",
        "Regular Expression, is a sequence of characters that forms a search pattern. RegEx can be used to check if a string contains the specified search pattern."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "vscode": {
          "languageId": "python"
        },
        "id": "_OBK3ZTMz7Fm",
        "outputId": "2bfdaac8-8d05-4859-a56c-2cfe731bc885",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2098    divergences surrogate loss functions and\\nexpe...\n",
              "2766    learning to use working memory in partially\\no...\n",
              "1784    learning efficient auditory codes using spikes...\n",
              "3040    nash equilibria of static prediction games\\n\\n...\n",
              "4383    approximate gaussian process inference for the...\n",
              "Name: paper_text_processed, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "# Load the regular expression library\n",
        "import re\n",
        "\n",
        "# Remove punctuation\n",
        "papers['paper_text_processed'] = \\\n",
        "papers['paper_text'].map(lambda x: re.sub('[,\\.!?]', '', x))\n",
        "\n",
        "# Convert the titles to lowercase\n",
        "papers['paper_text_processed'] = \\\n",
        "papers['paper_text_processed'].map(lambda x: x.lower())\n",
        "\n",
        "# Print out the first rows of papers\n",
        "papers['paper_text_processed'].head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kpVW3Iu4z7Fm"
      },
      "source": [
        "Example on re.sub -- uncomment and try different characters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        },
        "id": "yZjfS1ICz7Fm"
      },
      "outputs": [],
      "source": [
        "a = 'cat is?'\n",
        "b = re.sub('[,\\.!?]', 'L', a)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "47az15d9z7Fm"
      },
      "source": [
        "** **\n",
        "#### Step 3: Exploratory Analysis <a class=\"anchor\\\" id=\"eda\"></a>\n",
        "** **\n",
        "\n",
        "To verify whether the preprocessing, we’ll make a simple word cloud using the `wordcloud` package to get a visual representation of most common words. It is key to understanding the data and ensuring we are on the right track, and if any more preprocessing is necessary before training the model.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WuOfOO9mz7Fn"
      },
      "source": [
        "The join() method takes all items in an iterable and joins them into one string. A string must be specified as the separator. uncomment the below to see example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "vscode": {
          "languageId": "python"
        },
        "id": "m5cSEhHFz7Fn",
        "outputId": "6f1d9fa3-da5b-4376-e337-e5413e0cb2b0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "John is good\n",
            "Peter is good\n",
            "Vicky\n"
          ]
        }
      ],
      "source": [
        "myTuple = (\"John\", \"Peter\", \"Vicky\")\n",
        "x = \" is good\\n\".join(myTuple)\n",
        "print(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "vscode": {
          "languageId": "python"
        },
        "id": "yTYZqG-az7Fn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        },
        "outputId": "0a87da90-410f-4c60-b3ec-2edd2897fd8e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=400x200>"
            ],
            "image/png": "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\n"
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "# Import the wordcloud library\n",
        "from wordcloud import WordCloud\n",
        "\n",
        "# Join the different processed titles together.\n",
        "long_string = ','.join(list(papers['paper_text_processed'].values))\n",
        "\n",
        "# Create a WordCloud object\n",
        "wordcloud = WordCloud(background_color=\"white\", max_words=1000, contour_width=3, contour_color='steelblue')\n",
        "\n",
        "# Generate a word cloud\n",
        "wordcloud.generate(long_string)\n",
        "\n",
        "# Visualize the word cloud\n",
        "wordcloud.to_image()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tCjuJQs9z7Fn"
      },
      "source": [
        "** **\n",
        "#### Step 4: Prepare text for LDA analysis <a class=\"anchor\\\" id=\"data_preparation\"></a>\n",
        "** **\n",
        "\n",
        "Next, let’s work to transform the textual data in a format that will serve as an input for training LDA model. We start by tokenizing the text and removing stopwords. Next, we convert the tokenized object into a corpus and dictionary.\n",
        "\n",
        "Stop words are a set of commonly used words in a language. Examples of stop words in English are “a”, “the”, “is”, “are” and etc. Stop words are commonly used in Text Mining and Natural Language Processing (NLP) to eliminate words that are so commonly used that they carry very little useful information.\n",
        "\n",
        "Generate Similar (gensim):\n",
        "What is Gensim? Gensim = “Generate Similar” is a popular open source natural language processing (NLP) library used for unsupervised topic modeling. It uses top academic models and modern statistical machine learning to perform various complex tasks such as − Building document or word vectors.\n",
        "\n",
        "NLTK is a toolkit build for working with NLP in Python. It provides us various text processing libraries with a lot of test datasets. A variety of tasks can be performed using NLTK such as tokenizing, parse tree visualization, etc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "vscode": {
          "languageId": "python"
        },
        "id": "8gyTAUomz7Fn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab76bcd7-50b4-40c7-af2c-866e74d695c4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['divergences', 'surrogate', 'loss', 'functions', 'experimental', 'design', 'xuanlong', 'nguyen', 'university', 'california', 'berkeley', 'ca', 'xuanlong', 'csberkeleyedu', 'martin', 'wainwright', 'university', 'california', 'berkeley', 'ca', 'wainwrig', 'eecsberkeleyedu', 'michael', 'jordan', 'university', 'california', 'berkeley', 'ca', 'jordan', 'csberkeleyedu']\n"
          ]
        }
      ],
      "source": [
        "import gensim\n",
        "from gensim.utils import simple_preprocess\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "stop_words = stopwords.words('english')\n",
        "stop_words.extend(['from', 'subject', 're', 'edu', 'use'])\n",
        "\n",
        "def sent_to_words(sentences):\n",
        "    for sentence in sentences:\n",
        "        # deacc=True removes punctuations\n",
        "        yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))\n",
        "\n",
        "def remove_stopwords(texts):\n",
        "    return [[word for word in simple_preprocess(str(doc))\n",
        "             if word not in stop_words] for doc in texts]\n",
        "\n",
        "\n",
        "data = papers.paper_text_processed.values.tolist()\n",
        "data_words = list(sent_to_words(data))\n",
        "\n",
        "# remove stop words\n",
        "data_words = remove_stopwords(data_words)\n",
        "\n",
        "print(data_words[:1][0][:30])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "vscode": {
          "languageId": "python"
        },
        "id": "l4g-suRYz7Fn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d956e1f2-1473-4994-a320-22546e9e0c9e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 2), (7, 2), (8, 1), (9, 2), (10, 1), (11, 1), (12, 2), (13, 3), (14, 2), (15, 3), (16, 12), (17, 3), (18, 1), (19, 4), (20, 2), (21, 1), (22, 2), (23, 1), (24, 1), (25, 1), (26, 1), (27, 2), (28, 4), (29, 3)]\n"
          ]
        }
      ],
      "source": [
        "import gensim.corpora as corpora\n",
        "\n",
        "# Create Dictionary\n",
        "id2word = corpora.Dictionary(data_words)\n",
        "\n",
        "# Create Corpus\n",
        "texts = data_words\n",
        "\n",
        "# Term Document Frequency\n",
        "corpus = [id2word.doc2bow(text) for text in texts]\n",
        "\n",
        "# View\n",
        "print(corpus[:1][0][:30])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vj8BMZxiz7Fo"
      },
      "source": [
        "** **\n",
        "#### Step 5: LDA model tranining <a class=\"anchor\\\" id=\"train_model\"></a>\n",
        "** **\n",
        "\n",
        "To keep things simple, we'll keep all the parameters to default except for inputting the number of topics. For this tutorial, we will build a model with 10 topics where each topic is a combination of keywords, and each keyword contributes a certain weightage to the topic."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "vscode": {
          "languageId": "python"
        },
        "id": "yib3S8v_z7Fo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e08b4166-f03b-4dc4-ddd1-82bdcb5144c2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:gensim.models.ldamulticore:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(0,\n",
            "  '0.009*\"learning\" + 0.006*\"model\" + 0.006*\"data\" + 0.005*\"function\" + '\n",
            "  '0.005*\"set\" + 0.004*\"neural\" + 0.004*\"algorithm\" + 0.004*\"time\" + '\n",
            "  '0.004*\"network\" + 0.004*\"input\"'),\n",
            " (1,\n",
            "  '0.007*\"data\" + 0.007*\"learning\" + 0.006*\"function\" + 0.006*\"model\" + '\n",
            "  '0.004*\"used\" + 0.004*\"given\" + 0.004*\"using\" + 0.004*\"set\" + '\n",
            "  '0.004*\"algorithm\" + 0.004*\"one\"'),\n",
            " (2,\n",
            "  '0.008*\"data\" + 0.007*\"learning\" + 0.007*\"model\" + 0.006*\"function\" + '\n",
            "  '0.005*\"set\" + 0.005*\"one\" + 0.005*\"algorithm\" + 0.004*\"time\" + '\n",
            "  '0.003*\"problem\" + 0.003*\"models\"'),\n",
            " (3,\n",
            "  '0.007*\"model\" + 0.006*\"data\" + 0.006*\"learning\" + 0.005*\"time\" + '\n",
            "  '0.004*\"algorithm\" + 0.004*\"function\" + 0.003*\"set\" + 0.003*\"problem\" + '\n",
            "  '0.003*\"functions\" + 0.003*\"using\"'),\n",
            " (4,\n",
            "  '0.012*\"model\" + 0.005*\"network\" + 0.005*\"set\" + 0.005*\"learning\" + '\n",
            "  '0.004*\"algorithm\" + 0.004*\"time\" + 0.004*\"function\" + 0.004*\"data\" + '\n",
            "  '0.003*\"input\" + 0.003*\"figure\"'),\n",
            " (5,\n",
            "  '0.009*\"learning\" + 0.008*\"model\" + 0.006*\"function\" + 0.004*\"data\" + '\n",
            "  '0.004*\"algorithm\" + 0.004*\"one\" + 0.004*\"set\" + 0.004*\"input\" + '\n",
            "  '0.003*\"network\" + 0.003*\"models\"'),\n",
            " (6,\n",
            "  '0.006*\"data\" + 0.005*\"learning\" + 0.005*\"function\" + 0.005*\"model\" + '\n",
            "  '0.004*\"set\" + 0.004*\"algorithm\" + 0.004*\"one\" + 0.004*\"log\" + 0.003*\"using\" '\n",
            "  '+ 0.003*\"given\"'),\n",
            " (7,\n",
            "  '0.007*\"data\" + 0.007*\"function\" + 0.005*\"learning\" + 0.005*\"set\" + '\n",
            "  '0.005*\"algorithm\" + 0.005*\"model\" + 0.004*\"one\" + 0.004*\"using\" + '\n",
            "  '0.003*\"functions\" + 0.003*\"neural\"'),\n",
            " (8,\n",
            "  '0.006*\"model\" + 0.006*\"learning\" + 0.005*\"function\" + 0.005*\"data\" + '\n",
            "  '0.004*\"set\" + 0.004*\"using\" + 0.004*\"algorithm\" + 0.004*\"two\" + '\n",
            "  '0.004*\"time\" + 0.003*\"neural\"'),\n",
            " (9,\n",
            "  '0.007*\"learning\" + 0.007*\"model\" + 0.005*\"data\" + 0.005*\"time\" + '\n",
            "  '0.005*\"algorithm\" + 0.005*\"function\" + 0.004*\"set\" + 0.004*\"one\" + '\n",
            "  '0.003*\"using\" + 0.003*\"functions\"')]\n"
          ]
        }
      ],
      "source": [
        "from pprint import pprint\n",
        "\n",
        "# number of topics\n",
        "num_topics = 10\n",
        "\n",
        "# Build LDA model\n",
        "lda_model = gensim.models.LdaMulticore(corpus=corpus,\n",
        "                                       id2word=id2word,\n",
        "                                       num_topics=num_topics)\n",
        "\n",
        "# Print the Keyword in the 10 topics\n",
        "pprint(lda_model.print_topics())\n",
        "doc_lda = lda_model[corpus]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IwNNPLWtz7Fo"
      },
      "source": [
        "** **\n",
        "#### Step 6: Analyzing our LDA model <a class=\"anchor\\\" id=\"results\"></a>\n",
        "** **\n",
        "\n",
        "Now that we have a trained model let’s visualize the topics for interpretability. To do so, we’ll use a popular visualization package, pyLDAvis which is designed to help interactively with:\n",
        "\n",
        "1. Better understanding and interpreting individual topics, and\n",
        "2. Better understanding the relationships between the topics.\n",
        "\n",
        "For (1), you can manually select each topic to view its top most frequent and/or “relevant” terms, using different values of the λ parameter. This can help when you’re trying to assign a human interpretable name or “meaning” to each topic.\n",
        "\n",
        "For (2), exploring the Intertopic Distance Plot can help you learn about how topics relate to each other, including potential higher-level structure between groups of topics."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "vscode": {
          "languageId": "python"
        },
        "id": "rIQe1c6Jz7Fo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 861
        },
        "outputId": "e9459896-8b52-4906-c441-ecfc3028d73e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PreparedData(topic_coordinates=              x         y  topics  cluster       Freq\n",
              "topic                                                \n",
              "1      0.007069  0.008164       1        1  27.098264\n",
              "9     -0.001563 -0.002226       2        1  15.026794\n",
              "4     -0.009264 -0.001543       3        1  12.325744\n",
              "0     -0.004544  0.000575       4        1  10.339546\n",
              "2      0.000010  0.002327       5        1   9.622216\n",
              "3     -0.000439 -0.003841       6        1   7.537013\n",
              "6      0.009888 -0.005797       7        1   6.238879\n",
              "5     -0.005250  0.003910       8        1   5.360262\n",
              "8      0.003859  0.001000       9        1   4.702741\n",
              "7      0.000234 -0.002569      10        1   1.748541, topic_info=          Term         Freq        Total Category  logprob  loglift\n",
              "245   function  1162.000000  1162.000000  Default  30.0000  30.0000\n",
              "134       data  1318.000000  1318.000000  Default  29.0000  29.0000\n",
              "323   learning  1466.000000  1466.000000  Default  28.0000  28.0000\n",
              "1092     model  1559.000000  1559.000000  Default  27.0000  27.0000\n",
              "547        set   923.000000   923.000000  Default  26.0000  26.0000\n",
              "...        ...          ...          ...      ...      ...      ...\n",
              "637       used     8.783043   661.312638  Topic10  -6.0920  -0.2750\n",
              "1645     input     8.306460   570.347047  Topic10  -6.1478  -0.1828\n",
              "1389  training     8.176375   611.688130  Topic10  -6.1636  -0.2686\n",
              "623        two     8.055869   654.232098  Topic10  -6.1785  -0.3507\n",
              "369     method     7.777886   478.878549  Topic10  -6.2136  -0.0738\n",
              "\n",
              "[855 rows x 6 columns], token_table=       Topic      Freq         Term\n",
              "term                               \n",
              "14285      4  0.291131         aaba\n",
              "14285      6  0.291131         aaba\n",
              "1444       1  0.240561  abstraction\n",
              "1444       2  0.160374  abstraction\n",
              "1444       3  0.080187  abstraction\n",
              "...      ...       ...          ...\n",
              "4659       6  0.053095           zk\n",
              "4659       7  0.026548           zk\n",
              "4659       8  0.079643           zk\n",
              "4659       9  0.026548           zk\n",
              "4659      10  0.026548           zk\n",
              "\n",
              "[3606 rows x 3 columns], R=30, lambda_step=0.01, plot_opts={'xlab': 'PC1', 'ylab': 'PC2'}, topic_order=[2, 10, 5, 1, 3, 4, 7, 6, 9, 8])"
            ],
            "text/html": [
              "\n",
              "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.4.0/pyLDAvis/js/ldavis.v1.0.0.css\">\n",
              "\n",
              "\n",
              "<div id=\"ldavis_el2491350606372124966694343950\" style=\"background-color:white;\"></div>\n",
              "<script type=\"text/javascript\">\n",
              "\n",
              "var ldavis_el2491350606372124966694343950_data = {\"mdsDat\": {\"x\": [0.007069009108074309, -0.001563193592058382, -0.009263635507525346, -0.004544316414253661, 1.0278725494066733e-05, -0.0004391891434156272, 0.009887676943483225, -0.00525024303659423, 0.003859220811463542, 0.00023439210533209015], \"y\": [0.008164345348804542, -0.002225753155552266, -0.0015432688025611816, 0.000575180180382966, 0.002327298885803798, -0.003841316720046019, -0.005796961849235365, 0.0039095031679186815, 0.0010001894546634897, -0.002569216510178657], \"topics\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"cluster\": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1], \"Freq\": [27.09826365912007, 15.026794229142487, 12.325744495341644, 10.339545987025952, 9.622215780745263, 7.537013499753723, 6.23887868177273, 5.360262163391023, 4.702740922117013, 1.748540581590103]}, \"tinfo\": {\"Term\": [\"function\", \"data\", \"learning\", \"model\", \"set\", \"algorithm\", \"one\", \"using\", \"time\", \"neural\", \"network\", \"functions\", \"number\", \"distribution\", \"models\", \"input\", \"problem\", \"results\", \"given\", \"also\", \"first\", \"log\", \"information\", \"linear\", \"two\", \"figure\", \"based\", \"used\", \"training\", \"probability\", \"shrinkage\", \"drsvm\", \"hog\", \"curvature\", \"cutting\", \"descriptor\", \"curvss\", \"paintings\", \"fiksvm\", \"ommer\", \"supergaussian\", \"maji\", \"linsvm\", \"cssps\", \"mcsps\", \"pascal\", \"deselaers\", \"qtk\", \"gss\", \"mcssps\", \"sofa\", \"curv\", \"lss\", \"eeg\", \"monroy\", \"csps\", \"dja\", \"discarding\", \"curvedness\", \"ethz\", \"similarities\", \"self\", \"nystrom\", \"object\", \"pc\", \"roc\", \"ht\", \"kernel\", \"covariance\", \"method\", \"detection\", \"used\", \"space\", \"latent\", \"deep\", \"optimal\", \"qi\", \"data\", \"samples\", \"vector\", \"given\", \"function\", \"matrix\", \"feature\", \"size\", \"prior\", \"view\", \"learning\", \"using\", \"two\", \"mean\", \"log\", \"one\", \"parameters\", \"number\", \"training\", \"functions\", \"model\", \"linear\", \"methods\", \"set\", \"error\", \"also\", \"based\", \"algorithm\", \"first\", \"models\", \"neural\", \"different\", \"problem\", \"network\", \"radio\", \"metaplasticity\", \"wireless\", \"calcium\", \"radios\", \"battery\", \"segregation\", \"shouval\", \"packet\", \"cooper\", \"packets\", \"bcm\", \"nmda\", \"hrin\", \"deprivation\", \"header\", \"vm\", \"ltp\", \"bpap\", \"voltage\", \"nack\", \"gm\", \"depressed\", \"mf\", \"brownedu\", \"errored\", \"routing\", \"vex\", \"toggle\", \"vrest\", \"mobile\", \"channel\", \"synapses\", \"holding\", \"cccp\", \"ltd\", \"time\", \"equilibrium\", \"label\", \"light\", \"minimax\", \"plasticity\", \"rate\", \"state\", \"synaptic\", \"algorithm\", \"view\", \"learning\", \"figure\", \"functions\", \"variables\", \"model\", \"log\", \"parameters\", \"training\", \"problem\", \"distribution\", \"also\", \"algorithms\", \"show\", \"data\", \"xi\", \"function\", \"first\", \"linear\", \"one\", \"given\", \"input\", \"using\", \"output\", \"set\", \"based\", \"neural\", \"models\", \"two\", \"results\", \"used\", \"number\", \"network\", \"rivalry\", \"rivalrous\", \"unsegmented\", \"tdnn\", \"vki\", \"binocular\", \"leopold\", \"hzk\", \"explanations\", \"percepts\", \"nessler\", \"percept\", \"lang\", \"waibel\", \"zk\", \"suppression\", \"excitabilities\", \"utterances\", \"recurrent\", \"spurious\", \"vertical\", \"wta\", \"zhaoping\", \"binocularly\", \"homeostatic\", \"azimuth\", \"zee\", \"homeostasis\", \"viterbi\", \"deweese\", \"format\", \"logothetis\", \"bk\", \"suppressed\", \"percent\", \"activated\", \"model\", \"eyes\", \"network\", \"bias\", \"spike\", \"modeling\", \"spiking\", \"neurons\", \"coreference\", \"relevant\", \"could\", \"patterns\", \"input\", \"time\", \"figure\", \"set\", \"feature\", \"units\", \"layer\", \"models\", \"algorithm\", \"neural\", \"form\", \"two\", \"noise\", \"number\", \"information\", \"different\", \"log\", \"using\", \"function\", \"parameters\", \"learning\", \"given\", \"one\", \"problem\", \"data\", \"results\", \"networks\", \"however\", \"first\", \"distribution\", \"also\", \"training\", \"functions\", \"holdout\", \"genesis\", \"dendrite\", \"composes\", \"thresholdout\", \"moritz\", \"adaptively\", \"analyst\", \"script\", \"dwork\", \"soukup\", \"xodus\", \"predictor\", \"pitch\", \"segev\", \"neuronl\", \"rohwer\", \"students\", \"privacy\", \"symbolic\", \"eid\", \"hertz\", \"ullman\", \"toolkits\", \"pomdp\", \"unix\", \"tourebky\", \"gating\", \"bower\", \"computers\", \"gpfa\", \"modules\", \"sparsevalidate\", \"adaptive\", \"ebnn\", \"mistakes\", \"simulator\", \"option\", \"processing\", \"neural\", \"networks\", \"simulation\", \"learning\", \"memory\", \"input\", \"machine\", \"generalization\", \"planar\", \"propagation\", \"network\", \"via\", \"set\", \"sequence\", \"prediction\", \"deep\", \"output\", \"also\", \"number\", \"time\", \"distribution\", \"problem\", \"error\", \"function\", \"data\", \"algorithm\", \"figure\", \"model\", \"training\", \"algorithms\", \"results\", \"two\", \"performance\", \"using\", \"case\", \"log\", \"based\", \"order\", \"used\", \"different\", \"xi\", \"one\", \"linear\", \"information\", \"given\", \"functions\", \"sanger\", \"shepard\", \"krr\", \"oli\", \"spm\", \"clst\", \"spec\", \"fjl\", \"decorrelated\", \"rayleigh\", \"llca\", \"med\", \"pil\", \"symptom\", \"illnesses\", \"umist\", \"renyi\", \"ixixj\", \"snowbird\", \"stdev\", \"ficients\", \"newsgroup\", \"ea\", \"bentley\", \"baseball\", \"hungarian\", \"hints\", \"topics\", \"fil\", \"footing\", \"xp\", \"lifelong\", \"retina\", \"lms\", \"clustering\", \"pv\", \"growing\", \"ai\", \"influenced\", \"xi\", \"lagrangian\", \"netrate\", \"one\", \"influence\", \"data\", \"location\", \"output\", \"dimensional\", \"diffusion\", \"set\", \"different\", \"well\", \"problem\", \"models\", \"function\", \"standard\", \"learning\", \"algorithm\", \"time\", \"input\", \"network\", \"used\", \"optimization\", \"based\", \"form\", \"model\", \"training\", \"neural\", \"large\", \"algorithms\", \"point\", \"ie\", \"results\", \"functions\", \"information\", \"parameters\", \"gaussian\", \"two\", \"distribution\", \"given\", \"using\", \"figure\", \"linear\", \"space\", \"first\", \"number\", \"syntactic\", \"phrase\", \"emit\", \"hmm\", \"enemy\", \"birl\", \"alonso\", \"concert\", \"mlirl\", \"syntax\", \"composite\", \"nwii\", \"bros\", \"proce\", \"aaba\", \"wait\", \"compositions\", \"distributional\", \"contingencies\", \"word\", \"evd\", \"punctuation\", \"tasa\", \"ftk\", \"schmidhuber\", \"tagging\", \"nouns\", \"landauer\", \"semantic\", \"blood\", \"reward\", \"dpm\", \"temporal\", \"conformal\", \"words\", \"documents\", \"isomap\", \"nash\", \"backward\", \"classes\", \"xt\", \"time\", \"lattice\", \"irl\", \"test\", \"approach\", \"regret\", \"state\", \"stochastic\", \"loss\", \"problem\", \"matrix\", \"distribution\", \"functions\", \"data\", \"probability\", \"model\", \"linear\", \"algorithm\", \"values\", \"information\", \"however\", \"learning\", \"algorithms\", \"models\", \"may\", \"input\", \"results\", \"figure\", \"using\", \"xi\", \"two\", \"one\", \"given\", \"function\", \"set\", \"also\", \"log\", \"number\", \"method\", \"used\", \"first\", \"neural\", \"network\", \"wald\", \"trw\", \"pdc\", \"lille\", \"ucb\", \"kasteleyn\", \"planar\", \"matchings\", \"atom\", \"snowberg\", \"bubeck\", \"anr\", \"vianney\", \"rucb\", \"regret\", \"gpm\", \"akq\", \"lattimore\", \"ije\", \"perchet\", \"gilles\", \"aurlien\", \"ties\", \"mnard\", \"gkm\", \"commit\", \"siegmund\", \"atoms\", \"favourable\", \"aes\", \"lai\", \"sprt\", \"arms\", \"strategies\", \"suboptimal\", \"robbins\", \"strategy\", \"thompson\", \"marginals\", \"stopping\", \"rank\", \"kq\", \"exploration\", \"etc\", \"graph\", \"xj\", \"sparse\", \"arm\", \"ij\", \"trace\", \"edges\", \"estimation\", \"log\", \"results\", \"non\", \"upper\", \"partition\", \"three\", \"ht\", \"one\", \"also\", \"error\", \"data\", \"sampling\", \"function\", \"set\", \"algorithm\", \"using\", \"given\", \"learning\", \"based\", \"used\", \"method\", \"model\", \"time\", \"information\", \"first\", \"probability\", \"problem\", \"two\", \"number\", \"linear\", \"neural\", \"models\", \"input\", \"figure\", \"parameters\", \"functions\", \"mossy\", \"cerebellum\", \"noradrenergic\", \"commands\", \"elemental\", \"command\", \"pgn\", \"option\", \"servos\", \"packets\", \"rubrospinal\", \"leaming\", \"fibers\", \"sensorimotor\", \"repetitive\", \"trigger\", \"climbing\", \"schema\", \"radio\", \"promote\", \"discharge\", \"onward\", \"options\", \"ncr\", \"esf\", \"reinforcement\", \"paragraphs\", \"rademacher\", \"hypothesized\", \"controller\", \"irl\", \"tsne\", \"wireless\", \"intra\", \"abstraction\", \"spinal\", \"syntactic\", \"power\", \"roc\", \"brown\", \"sne\", \"reward\", \"state\", \"mobile\", \"human\", \"learning\", \"motor\", \"input\", \"mixture\", \"curve\", \"model\", \"distribution\", \"function\", \"network\", \"probability\", \"models\", \"cell\", \"networks\", \"functions\", \"one\", \"information\", \"algorithm\", \"new\", \"regression\", \"since\", \"neural\", \"linear\", \"given\", \"set\", \"using\", \"training\", \"results\", \"data\", \"different\", \"number\", \"used\", \"problem\", \"also\", \"matrix\", \"based\", \"figure\", \"parameters\", \"time\", \"bhalla\", \"bower\", \"widgets\", \"axon\", \"compartment\", \"modules\", \"caltech\", \"neuronl\", \"students\", \"mimic\", \"koch\", \"bns\", \"knn\", \"olfactory\", \"liam\", \"shrinkage\", \"ryckebusch\", \"lc\", \"uhley\", \"genesis\", \"segev\", \"densities\", \"unix\", \"steve\", \"discrepancy\", \"bsp\", \"dangna\", \"netwoflks\", \"hd\", \"interrace\", \"sparse\", \"quasi\", \"prekopa\", \"kde\", \"dsp\", \"shallow\", \"density\", \"concavity\", \"snn\", \"av\", \"heavy\", \"cell\", \"know\", \"estimator\", \"using\", \"agent\", \"two\", \"without\", \"error\", \"distributions\", \"number\", \"based\", \"may\", \"models\", \"loss\", \"example\", \"function\", \"neural\", \"set\", \"methods\", \"results\", \"training\", \"time\", \"non\", \"noise\", \"given\", \"learning\", \"model\", \"algorithm\", \"linear\", \"different\", \"functions\", \"matrix\", \"features\", \"data\", \"used\", \"feature\", \"method\", \"figure\", \"distribution\", \"one\", \"also\", \"first\", \"problem\", \"birl\", \"cm\", \"irl\", \"gridworld\", \"mario\", \"killed\", \"highway\", \"dpm\", \"mlirl\", \"korea\", \"xnew\", \"babes\", \"killing\", \"enemy\", \"evd\", \"cj\", \"enemies\", \"nmcj\", \"lane\", \"hastings\", \"coins\", \"dimitrakakis\", \"amh\", \"collecting\", \"dpmbirl\", \"tbl\", \"lisa\", \"collector\", \"mh\", \"xm\", \"emmlirl\", \"behaviour\", \"reward\", \"trajectory\", \"trajectories\", \"coin\", \"function\", \"data\", \"node\", \"transmission\", \"set\", \"algorithm\", \"graph\", \"first\", \"functions\", \"one\", \"using\", \"new\", \"distribution\", \"number\", \"features\", \"work\", \"prior\", \"neural\", \"network\", \"learning\", \"problem\", \"information\", \"model\", \"also\", \"log\", \"results\", \"given\", \"time\", \"models\", \"figure\", \"probability\", \"linear\", \"different\", \"used\", \"input\", \"training\", \"two\", \"method\"], \"Freq\": [1162.0, 1318.0, 1466.0, 1559.0, 923.0, 960.0, 780.0, 761.0, 756.0, 680.0, 642.0, 628.0, 613.0, 564.0, 618.0, 570.0, 621.0, 526.0, 704.0, 568.0, 507.0, 618.0, 513.0, 512.0, 654.0, 604.0, 546.0, 661.0, 611.0, 417.0, 21.403259339303226, 8.227756676418394, 17.360935849740244, 40.890425944055565, 5.283552146890709, 12.832229684811965, 5.867871258420632, 3.4658987471058307, 7.565105412878138, 3.371167632427547, 2.055600442514155, 1.66201942460607, 6.714321885272081, 7.801280263715517, 7.721475337229702, 11.893316243768265, 2.6999984143101043, 5.570203035484587, 2.1423254815488044, 12.966385333835849, 1.5814355090628414, 8.413305233209837, 1.5550038726200264, 33.72725391509882, 1.5317411982699043, 8.605282831703292, 1.408949831055343, 1.9812389115168385, 1.477867090434193, 2.005808662262326, 12.249116128117416, 46.96279864079104, 5.435886178546672, 57.02975976193655, 12.22306703192169, 51.85262017058171, 33.72523531165355, 164.69105633153634, 89.80257170844651, 184.47470181279377, 56.816548277549124, 244.92654812861295, 156.60678784055636, 99.62878282806399, 95.23197715362308, 136.98945285426257, 39.50704125690511, 428.9654278503398, 72.74668328629414, 140.25032448507298, 231.66112737102668, 359.77283236336194, 159.99596695285717, 143.26988889569603, 85.8334085756953, 87.33520748474234, 88.21564801175057, 403.6714855962602, 229.73791695661927, 199.89819188841355, 100.27655127184516, 185.6844340358524, 223.09174922152428, 152.12240421455738, 182.5167826335912, 181.50247645657834, 183.61741214404853, 355.8071176781631, 153.88475716691934, 130.64656626874083, 227.44489558742134, 138.02852897771848, 160.8654803869099, 156.38685819157763, 225.32986177339478, 146.8917260731444, 160.07879978451092, 168.28484333194308, 142.66998518430302, 142.87457905432944, 142.15376940741209, 11.89276855156708, 5.688346307745171, 4.63474653590665, 6.561575491136919, 1.6094343159148676, 5.528161892089, 2.679617877220707, 2.603955074127559, 7.45585758616397, 2.9069451600114617, 7.9650729733472065, 1.5625709028815267, 7.805627034733605, 2.4902883962311844, 0.9222079444799228, 2.0665908368582, 1.8003512796258345, 1.8133357222708666, 1.7965673135429059, 5.874359929645525, 0.8629977540110053, 4.6145200383828024, 1.5126568994861505, 2.927805436023488, 0.874844298272269, 1.137239827431977, 1.4079939328872473, 0.8704618378427513, 0.8345921981305621, 0.8689957544311833, 12.516907970979698, 12.105893026052604, 14.07586507329419, 3.0154497862122445, 11.749372828465534, 2.044209395306513, 180.8999015838378, 12.999341419365805, 33.608611027983535, 15.12123471282934, 13.079043497545744, 19.844180185466914, 47.57752616358761, 69.41677204053869, 29.419193841635316, 172.8547616663508, 51.64646082044064, 240.9181384911364, 109.55833188577606, 110.38077765480686, 49.89148567565961, 232.50963677493507, 106.8776446743641, 87.26842845023639, 105.5444059951519, 106.11665574216019, 96.96996460076394, 97.30360075515424, 68.35570490544734, 52.4833302121292, 183.48370060726464, 72.16117038711799, 164.34722629201963, 86.02387697711549, 86.58077417508089, 118.74930055595625, 108.31960272112764, 91.62929085545964, 112.84279015375019, 53.76709092948925, 122.60744665781104, 82.79674007452985, 92.43794653740078, 82.82916310341993, 84.78221722462445, 74.7194258783145, 83.48018114382143, 77.63681441547632, 73.17065295742523, 17.00311580987702, 2.9009752249168494, 2.404179350848517, 2.28080754157077, 5.991492607192776, 12.753722878405977, 1.6213516623761914, 3.008893976044048, 5.465336639958066, 2.1956407754465426, 1.46325032335224, 2.7596072600187203, 3.2029636160255137, 0.8543190540560578, 11.742547632712082, 3.869841960459359, 5.524571702406314, 2.5112259608156853, 22.12603592237609, 1.934680478886258, 7.052078824004301, 8.217527213145937, 0.5562396566137093, 1.4386142783221587, 11.924867178060934, 4.098582847964203, 1.5641974247244228, 1.5960493070790003, 0.7924905323197907, 0.822643761855256, 1.3594203939464016, 1.7220290714796742, 21.434436151946418, 4.054432221060597, 2.8546901734973096, 5.472155161890034, 330.4545429733539, 3.6703736929727873, 142.515502612244, 20.65214167109215, 50.13709946867327, 24.372437226188808, 19.2821376239915, 59.06936160550653, 10.489944904206261, 24.90678299144946, 29.351627200280003, 29.455284674082915, 93.31959030651886, 116.94289713105728, 92.29301978675859, 128.42478115859296, 66.05608702882638, 38.039235509850066, 44.973373431466676, 90.37113230559648, 118.46466051468884, 90.68542033790375, 44.22933759348538, 85.9366876378727, 45.94581979139574, 80.3604932287133, 70.66005505608747, 69.58836672340787, 77.41982691340247, 88.13053172681249, 110.14659616828514, 63.03502352540083, 124.56767999092654, 78.07990765772793, 82.81664039677621, 71.10054671630772, 108.38040849968336, 63.83076376487489, 55.94217304862858, 52.54919045692186, 60.18526871045796, 60.67536701066015, 58.941927375856224, 59.3842936314691, 59.593993268451946, 16.300563008225748, 5.64077947436876, 2.334778941436208, 0.9548100977148818, 4.625450133824541, 1.3623125227757333, 6.0644155113499965, 5.800255080492521, 1.376641030841262, 1.3113343640931516, 1.0469577286117349, 0.7810553754593955, 1.5521078396549493, 1.6518334133702297, 0.9327838860168133, 1.1083208965638252, 0.8157599366224032, 0.7279827814924699, 5.186603677627493, 2.134226629674355, 1.2394696018501383, 0.6200747361039954, 1.6670740425280266, 0.7390748225047483, 3.9969423727181757, 0.8986588234477021, 0.5864672023844233, 8.217395029759174, 3.121362619821428, 0.7417705690644147, 9.423143897594754, 3.903619197082103, 1.9924032493950767, 19.469766103544114, 2.503947735462262, 12.442176793688525, 4.416459908011033, 9.813438791362339, 33.15092459703617, 100.79867072500167, 64.11877051535323, 15.816453192394851, 196.52878165266728, 31.137538885285277, 82.13722075071628, 32.516445342775626, 17.47212697487191, 9.045549500267503, 9.79842765501372, 84.98997850137285, 27.498275681032055, 111.05508780234604, 20.499795352752546, 36.7461759946104, 34.55601563246868, 38.79220216941757, 69.26830968354913, 73.6204373917294, 87.43123374891843, 68.01982601199312, 73.34170040668197, 56.979101798187074, 117.07741770886187, 128.85502745397486, 99.92522744485578, 69.51569791743344, 143.28742338741714, 69.34277433355642, 46.50954423541385, 59.39542673875923, 69.15470857009525, 42.05441654409967, 72.76433460830262, 46.07796269939614, 62.32776249996086, 56.56774371007035, 42.571925001706745, 57.559227527568, 50.56796393747426, 44.658785853319024, 57.26098382088743, 48.29213874021425, 48.15184759633827, 53.09068528789737, 50.76698919438932, 2.7830129723412593, 1.5115775261206084, 0.7327570604040149, 2.9210263270525765, 1.828099234362142, 1.0850070696435559, 1.0387780027600582, 2.290029336510367, 2.357414397080267, 4.03960249744444, 6.816420815888714, 0.3354957134903111, 0.6911324518874482, 0.8506734110766472, 0.5025664577301037, 1.3456512077894034, 5.285421064973221, 0.5057810310720989, 0.4948036965125201, 3.6291009022450154, 0.31731919759966226, 0.9321380718915916, 1.4281764915351582, 0.4908683008985624, 0.4490029775641576, 0.3020887938644263, 1.0595490082886898, 4.264310829864011, 1.7208360893304004, 0.46658173128640607, 1.6372975478635488, 2.611731040970852, 6.155664162975486, 2.599734343322422, 24.853548749664544, 3.5813838366878894, 5.321839233639798, 12.791838345470111, 6.993725050902042, 57.14159308102523, 4.302632006660754, 5.853920555715348, 102.87301696090302, 22.91793220031115, 161.92828273294106, 14.324959186696455, 37.47421653811615, 30.63272529339345, 7.363797134157081, 109.24819934927902, 64.05476709856471, 36.66771690158821, 74.03672636476128, 72.67438533701714, 125.4169179997403, 26.093382967938485, 148.0856678204532, 102.22404421218374, 80.98932814728109, 63.17720191467859, 69.90974788833394, 71.27203416220675, 32.16218260286553, 60.3194629742403, 32.74451989017947, 141.2529023517702, 64.71874240802767, 70.61838244630133, 35.37385056756355, 41.93525833876073, 30.97501414237146, 30.463321793131417, 53.411172006498276, 60.900854512867674, 52.37642339090544, 49.55610125508237, 41.880967386527374, 59.10264280361016, 53.21754738461091, 58.94964057662299, 60.311887029498465, 53.02896509651032, 46.00172383212205, 42.37587269658093, 43.83172338130277, 44.88263434418649, 6.241665354584817, 0.8728076460529773, 0.6255015318849619, 6.941781597116338, 1.0983041967222036, 4.432584365504968, 0.7702924385276315, 1.5600612915898773, 1.9205830663046097, 1.1793058554444869, 4.929558131948661, 0.7375714529003917, 0.8132610520613353, 0.612326227865611, 0.6002450633678167, 0.736560653182036, 0.6015861762535377, 0.721332558220682, 1.050427672935958, 6.169201639385203, 1.7950640627058045, 0.5575605240317197, 1.8280455461389562, 1.7053542474417422, 1.6128041775688817, 1.8358898441943394, 0.5647245792197476, 0.41785739662474314, 9.446069578215175, 0.41365105155762716, 29.547482925375267, 3.762157318654707, 16.28832395561874, 2.6920586498015147, 18.039905354162617, 4.369746641258701, 7.1794033581004015, 7.875242465468813, 4.155983457619086, 12.061474372711691, 26.13100327096193, 77.12930157174952, 7.729128783133962, 4.258133687979975, 25.82913968062621, 41.8045631267087, 14.09043695414101, 35.10917005303245, 19.335349002464007, 26.8147581068662, 56.39338380080604, 43.051794455174694, 50.66406182689735, 55.39026499062839, 101.81310477382105, 38.96668199651627, 114.93428714518566, 45.529402002434736, 75.15073861446417, 25.360208539541468, 44.57748404819323, 34.46918274745953, 99.12410069838539, 33.74523960645612, 49.4175440041149, 29.232817171586426, 45.42767480686436, 42.743446930676484, 46.01841852345818, 53.60361946646405, 34.689730083500066, 47.73441528813705, 52.80078521070188, 49.26968457221827, 65.07511821339973, 56.55977098684589, 42.278794874223934, 42.74113486034675, 42.191946026677655, 37.495051181106234, 41.61058315530028, 37.803398705604444, 38.93675374718899, 38.01578946301123, 0.9831575122331742, 3.275443663698927, 2.53482177483515, 1.13025773324313, 8.203601165857117, 1.0822950517808931, 8.765467528493982, 1.086867277440669, 0.7691319357026314, 0.32642629209409213, 1.2199810305055783, 0.8334130876180837, 0.6684641014547805, 0.3208098997546573, 20.26738316856674, 1.909331743387701, 2.296436696367521, 0.6698982799716114, 2.357257766540574, 1.341051819142975, 0.48647335290904564, 0.9950793480813116, 0.31584640155226223, 0.31473047551854383, 0.5865298962996172, 1.295643226060501, 0.825103878871467, 2.4158369998590477, 0.3122793867738242, 0.5824502030439864, 2.3124282911123646, 1.646246621227566, 2.8390866805818233, 12.055747375609425, 2.3500394714316015, 1.9938821140588514, 14.227909376944039, 7.376337143844056, 4.462255836455756, 2.93749533066814, 13.384456686710614, 6.74743554259982, 6.8002976279995115, 8.647839877717773, 20.01125300536175, 20.793451951312615, 17.942718167813727, 6.145553783927529, 18.751331817721837, 7.389592906911856, 9.927412740157084, 22.044699485475206, 50.844772721897826, 43.14993337440626, 26.02603068669294, 13.041829623623864, 13.943989634849206, 14.74448474510255, 9.267130667483398, 54.102642151661605, 42.3913735632999, 35.67608742159594, 79.16720278807705, 17.355565886448893, 71.50405011215396, 60.05136128810955, 57.3200915493696, 47.720024105149456, 44.99796538297668, 73.09740106278872, 36.23879855773892, 40.02103108620661, 32.43531678852902, 69.19272398017183, 43.141564710790746, 33.11938161561177, 32.54729163779248, 29.07551942420872, 36.09490466367893, 36.66402220062283, 35.30511324524234, 31.793253422415138, 35.016466967140985, 33.19918245500904, 30.736784678145135, 31.257226478625817, 28.187989244132286, 28.81262461814291, 1.2121518175183619, 3.299725485489851, 0.9240330014172575, 2.628327370485387, 1.8095139538810747, 1.0277947378240533, 0.3393031466231704, 7.262340117719173, 0.9181045565435582, 3.144097568546374, 0.6709802313894703, 0.7461439542110736, 3.064194235326117, 0.798312033454782, 0.7594476007932957, 1.5107517352579471, 1.2037238697157886, 1.0348341595412645, 4.01370795554213, 0.32245546138039166, 1.8846986900311666, 0.3114717295897551, 2.618399201008083, 0.32793237965029026, 0.32561733908438506, 7.635120204527746, 0.32092452125226256, 2.0338172410527497, 0.31156080877196635, 0.3121883707441154, 3.6816301227720056, 1.8953188695757262, 1.543641190437906, 1.6389919630107213, 3.0519591923188254, 0.9485371420219267, 3.675150912059654, 10.534883281393652, 13.223497501374611, 4.4676637867690046, 5.876433029636053, 18.152467018431924, 30.724864326940093, 4.4128270581337015, 15.51957754601555, 102.87071928714116, 8.616477479408845, 41.85831465328464, 10.73608854458492, 6.95047216773967, 92.29473410852971, 37.93984274187442, 66.62734624402894, 41.0708324993948, 28.347496928944388, 38.48716742052281, 9.108804601637708, 27.651026663569304, 37.100002825540614, 43.4248465939638, 31.107265658650686, 48.777181388531126, 21.94295051541963, 19.760762884492387, 20.56155908331257, 35.87702676089588, 28.94932004330264, 35.6438791587324, 42.786604305156914, 36.56160408891675, 31.230440331117755, 28.20598234328992, 50.15297435001143, 27.044104199293965, 29.44471953078878, 29.6685862606453, 28.408949779875595, 26.918603069741284, 24.101524190994002, 25.61438401802708, 25.982352442549832, 24.37224171813117, 25.14894841047789, 0.9202906585501308, 1.925436063614956, 0.5047763970945212, 0.6020757421413094, 0.48966945394018097, 2.0778553692620867, 0.44220628091762615, 0.5241912145498199, 0.34718475339144705, 8.851253738183221, 0.6873141414868478, 0.17552170227605932, 0.45011862164925975, 0.6092410374865781, 0.46534286913689876, 4.15470661951302, 0.2511656258732843, 4.559073738304483, 0.5058358612480226, 2.168599355882632, 0.4075752744706895, 4.01294186195608, 0.4046665755438065, 0.6139966524686538, 1.800673820337745, 1.1472886838631733, 0.26425053273150256, 0.15977283529521744, 0.24134568328992162, 0.2379632246228992, 14.434020422381597, 0.9377255187426718, 0.5212967320262596, 0.9613682337272957, 3.462332806867149, 5.9691828189354945, 15.618576761355007, 2.5263797011034335, 2.4849774293562623, 3.551664428028183, 2.1252884369599583, 7.7838721883842625, 5.061326647785683, 5.102195690372933, 45.57551564433425, 7.907917073470283, 38.92052136534547, 7.663709977899823, 27.7277460231464, 12.073114638399963, 35.59927032048739, 32.070979788181006, 19.525563085135282, 34.93440608452991, 16.188685248107248, 18.360173194688535, 56.63151915146098, 36.31878149853466, 46.43834033164161, 23.5785170522548, 28.756039305927253, 31.954358450430025, 37.347164793195375, 17.008766456248086, 16.953399419119407, 34.122143746169456, 58.30890269644202, 61.00304583981412, 41.65595563403877, 26.246756236254956, 26.133458039798313, 29.565221778344355, 23.864506689355423, 18.325967463964524, 48.71443424638916, 29.687754707124057, 21.68581292687822, 23.600115037914467, 26.74697901293226, 25.70543695453724, 30.393248359448076, 23.249540660636676, 22.042637047922593, 22.39500193178357, 2.034865681807749, 3.302631491539407, 2.3989426790722073, 0.2918507914152972, 0.8401754594605709, 0.22489704604561, 0.2795809890942992, 1.736965537942946, 0.7832435766911402, 0.31600622538783585, 0.728298662727451, 0.26317132451832514, 0.41983878623194754, 0.41012476048517676, 0.7280550050738036, 0.40468005778847543, 0.3003282687030819, 0.14874594504773606, 0.3867805482066088, 0.2419312458917131, 0.3399886963461438, 0.14455217848353663, 0.19139736932224202, 0.4268809446871442, 0.2711064797941749, 0.23354499889130045, 0.0921341456142091, 0.1807500103891854, 0.585719531774201, 1.4678556658477717, 0.3950315256360783, 1.6304077708290199, 7.440266342442658, 2.74182179966793, 2.614089786720355, 0.45684495664355396, 25.798627042745473, 27.4351254634523, 4.302138026172823, 2.4309376991179295, 18.642425046757324, 18.57379115183961, 4.676304824688413, 10.963546968888584, 12.805540940570406, 14.796127412337919, 14.029828048933672, 7.542280996711476, 11.24438802421076, 11.712850221621704, 7.300256471207578, 6.282739395987245, 5.7417303087270675, 11.865309585630708, 11.32309656950926, 19.540753164711887, 10.889960774560311, 9.34482979052199, 18.52325689367173, 9.896468004791025, 10.246365370341366, 8.91802660711155, 10.226196169929189, 10.545702246366213, 9.412391817896047, 9.196220104374417, 7.490312154641281, 8.205892283580026, 8.042318060181621, 8.783042754447205, 8.306459690532517, 8.176374770033942, 8.055868817710314, 7.777886075837887], \"Total\": [1162.0, 1318.0, 1466.0, 1559.0, 923.0, 960.0, 780.0, 761.0, 756.0, 680.0, 642.0, 628.0, 613.0, 564.0, 618.0, 570.0, 621.0, 526.0, 704.0, 568.0, 507.0, 618.0, 513.0, 512.0, 654.0, 604.0, 546.0, 661.0, 611.0, 417.0, 39.17165163784446, 15.394068905632421, 32.49870572859997, 76.73005212040185, 9.947449887495683, 24.167570134044016, 11.08080340464917, 6.623564405252394, 14.465270371368392, 6.635076178890147, 4.048772541507477, 3.277654896767071, 13.241909290770893, 15.409194234739068, 15.337154471700897, 23.756214201337816, 5.393703458902475, 11.167433456711887, 4.2975801285286, 26.065200404528092, 3.2031107633813316, 17.085874715110705, 3.174895789441146, 70.21974102362161, 3.2105502443031146, 18.064599344206727, 2.968651222437718, 4.174973122234139, 3.122103296727086, 4.239140402734659, 25.89580020627078, 101.18632045163699, 11.654513882772388, 131.6856409113791, 27.033387772155397, 120.64771970524609, 78.89702468061489, 419.47066825552076, 221.82979033450107, 478.8785488254787, 137.12275627443347, 661.3126380779028, 410.3905352553151, 253.00630071531182, 243.8183628886044, 367.4628031507385, 94.36411743348783, 1318.8956887659544, 186.66361805302202, 392.82476569625703, 704.3608326444285, 1162.397651296058, 464.6120973748052, 411.88296170696776, 231.84474819424574, 236.7202305091665, 244.0121069696653, 1466.7136304609128, 761.2780518287813, 654.2320979910959, 289.99171238673335, 618.945041287856, 780.3093406841605, 485.6681521674229, 613.2710613585145, 611.6881296146746, 628.933681927791, 1559.2596711330125, 512.6134593458777, 411.67983785937986, 923.2589125139617, 455.77246541808125, 568.5398278704057, 546.8013900790928, 960.2763139497172, 507.2702880577169, 618.917775167437, 680.8396019379418, 513.7660022566189, 621.652409234945, 642.9774430289742, 30.750685645492144, 14.852863466715073, 12.389330520158987, 18.07224828940514, 4.501707810228518, 15.57828362824088, 7.593694861659934, 7.379812749428157, 21.367502837979654, 8.348072528871096, 22.88585592606306, 4.555626942454277, 22.969182703466377, 7.407444111002494, 2.782163276230012, 6.236636582250888, 5.455707021140631, 5.50332735161188, 5.500652544036125, 18.05232564787274, 2.6545146510417905, 14.268588994319806, 4.678121700875621, 9.113708823190114, 2.74032071111562, 3.5720174349432656, 4.423863260504078, 2.744122828121891, 2.6332731533656846, 2.7610105223924215, 39.82871112875894, 39.165084100786956, 46.648200992820755, 9.713368630991708, 40.227439828228235, 6.545582087461359, 756.77106929359, 48.36178887546984, 141.10091499215156, 58.68830581816972, 50.425250192684835, 80.55991868246778, 217.6150614268349, 338.1628944744757, 127.80653665218465, 960.2763139497172, 244.0121069696653, 1466.7136304609128, 604.5650651498108, 628.933681927791, 247.83202399535668, 1559.2596711330125, 618.945041287856, 485.6681521674229, 611.6881296146746, 621.652409234945, 564.6744363971848, 568.5398278704057, 368.229712011902, 267.0422792087639, 1318.8956887659544, 403.20856389890395, 1162.397651296058, 507.2702880577169, 512.6134593458777, 780.3093406841605, 704.3608326444285, 570.347046585555, 761.2780518287813, 280.35075088438106, 923.2589125139617, 546.8013900790928, 680.8396019379418, 618.917775167437, 654.2320979910959, 526.5028438301028, 661.3126380779028, 613.2710613585145, 642.9774430289742, 44.388790439902095, 7.687725160601584, 6.501290778899508, 6.42450572923249, 17.31601101981015, 37.79467994551895, 4.83326605099491, 8.9871584162266, 16.3563461441334, 6.689390767363834, 4.538572026207825, 8.6609700862119, 10.124731575152582, 2.708791042943802, 37.668050833617514, 12.43671193985738, 17.78330972026574, 8.143012506709253, 72.05952984442706, 6.339084900000434, 23.130621807968605, 27.0144019587943, 1.829750707077512, 4.821872488436763, 40.14257225105492, 13.818199464750306, 5.286593358606384, 5.399898840747147, 2.68681420549052, 2.798888126545442, 4.625833530296791, 5.874819124708847, 75.92510090890622, 14.114616703921204, 9.850157681568845, 19.31113087022336, 1559.2596711330125, 13.004253900313225, 642.9774430289742, 84.59641163185547, 225.44501248209903, 104.34302289878968, 82.21835936472448, 294.801413421127, 41.720965894937294, 114.00082656416856, 138.24696021728013, 139.77635939042858, 570.347046585555, 756.77106929359, 604.5650651498108, 923.2589125139617, 411.88296170696776, 207.4598236277524, 256.8232152507536, 618.917775167437, 960.2763139497172, 680.8396019379418, 266.4187138140308, 654.2320979910959, 282.89830171057537, 613.2710613585145, 513.5688765267455, 513.7660022566189, 618.945041287856, 761.2780518287813, 1162.397651296058, 485.6681521674229, 1466.7136304609128, 704.3608326444285, 780.3093406841605, 621.652409234945, 1318.8956887659544, 526.5028438301028, 419.32594059100285, 371.94999292554235, 507.2702880577169, 564.6744363971848, 568.5398278704057, 611.6881296146746, 628.933681927791, 59.59519096855079, 21.129694915226302, 8.851411205235973, 3.6391701114351567, 18.14565205902167, 5.411620619789902, 24.26681772820496, 23.51468885798655, 5.661649264548262, 5.42506890201052, 4.372094676626216, 3.2851359468463444, 6.534004489889077, 7.0052666392519995, 4.0105345513198, 4.784558419647719, 3.5290170572642166, 3.171114184264095, 22.675331740045156, 9.357801208114116, 5.435044007568531, 2.719378483478771, 7.320499633568308, 3.2524930363073654, 17.612750042893612, 4.022194867435009, 2.629244926891102, 36.889811276816815, 14.014935567867132, 3.3342828614979694, 42.53545878871744, 17.816949650172788, 9.059240992613248, 93.14360786186056, 11.540093618255979, 64.75112720236628, 21.57847608889196, 51.13955423198138, 192.38587085337207, 680.8396019379418, 419.32594059100285, 89.08371291303952, 1466.7136304609128, 189.8466603424586, 570.347046585555, 204.24089151876964, 101.92359073028918, 48.69987411197162, 53.452172797000514, 642.9774430289742, 180.3070744788974, 923.2589125139617, 129.5814757174744, 258.29153819378547, 243.8183628886044, 280.35075088438106, 568.5398278704057, 613.2710613585145, 756.77106929359, 564.6744363971848, 621.652409234945, 455.77246541808125, 1162.397651296058, 1318.8956887659544, 960.2763139497172, 604.5650651498108, 1559.2596711330125, 611.6881296146746, 368.229712011902, 526.5028438301028, 654.2320979910959, 333.47246236571834, 761.2780518287813, 382.729506850082, 618.945041287856, 546.8013900790928, 347.3722224890434, 661.3126380779028, 513.7660022566189, 403.20856389890395, 780.3093406841605, 512.6134593458777, 513.5688765267455, 704.3608326444285, 628.933681927791, 12.744736684595443, 7.144951552878441, 3.5576707537737358, 14.328435321609687, 9.011797389395387, 5.428729136223723, 5.210145925845232, 11.486632845144033, 12.131763038338105, 20.80402015340978, 35.18483912052862, 1.7366945713276059, 3.614396990292179, 4.512019818452941, 2.697752706606949, 7.23836922315151, 28.432274176943135, 2.772053688014821, 2.7231641568343785, 20.158306279961657, 1.7638570693732274, 5.220547440393908, 8.147619104207129, 2.8033390675276193, 2.591094247490643, 1.7449368917139567, 6.152382952891327, 24.7927125511535, 10.006756252724998, 2.714760000406768, 9.536592552744432, 15.322058898917334, 36.51207336952494, 15.341163966916184, 156.3048145801126, 21.3382423652326, 32.446523169424154, 82.02135215632774, 43.45904527688171, 403.20856389890395, 26.31137836459029, 36.64483095103353, 780.3093406841605, 160.60687527626934, 1318.8956887659544, 97.30775321484153, 280.35075088438106, 226.8499745492597, 47.42463689665392, 923.2589125139617, 513.7660022566189, 281.50648295066816, 621.652409234945, 618.917775167437, 1162.397651296058, 198.677322015352, 1466.7136304609128, 960.2763139497172, 756.77106929359, 570.347046585555, 642.9774430289742, 661.3126380779028, 260.3903970844385, 546.8013900790928, 266.4187138140308, 1559.2596711330125, 611.6881296146746, 680.8396019379418, 293.8869799758379, 368.229712011902, 253.16636488442424, 248.92806868792897, 526.5028438301028, 628.933681927791, 513.5688765267455, 485.6681521674229, 387.5968675900636, 654.2320979910959, 564.6744363971848, 704.3608326444285, 761.2780518287813, 604.5650651498108, 512.6134593458777, 410.3905352553151, 507.2702880577169, 613.2710613585145, 30.451288440004607, 4.374572050775207, 3.3502245767200423, 37.227446905810346, 5.912021078927192, 24.18997740195193, 4.263363556972038, 8.679313026796937, 10.691893997932146, 6.64386996341135, 27.888573723487056, 4.188624246081402, 4.65240644566162, 3.5034656684290493, 3.43487457079693, 4.23855655333702, 3.4822008497213552, 4.181012734554803, 6.105069493218193, 36.13350726356446, 10.583403535560745, 3.2950515784791, 10.87536173601939, 10.170564173652558, 9.62347651732032, 10.957403679262478, 3.38960554448988, 2.5239775163567146, 57.40112798289011, 2.5200484630408964, 186.49653402016355, 23.33117627252639, 113.58183586418713, 17.263585905679136, 127.96514127701096, 28.802076076700512, 50.74274159778057, 56.11149094627592, 28.44734254082968, 92.96072232549241, 221.17580664219244, 756.77106929359, 57.17313148690445, 29.453347993427737, 228.60634485769324, 397.6782241606485, 116.62952719840158, 338.1628944744757, 171.03652736231024, 252.1631050586333, 621.652409234945, 464.6120973748052, 564.6744363971848, 628.933681927791, 1318.8956887659544, 417.428162269897, 1559.2596711330125, 512.6134593458777, 960.2763139497172, 252.06580054502, 513.5688765267455, 371.94999292554235, 1466.7136304609128, 368.229712011902, 618.917775167437, 308.43914118641214, 570.347046585555, 526.5028438301028, 604.5650651498108, 761.2780518287813, 403.20856389890395, 654.2320979910959, 780.3093406841605, 704.3608326444285, 1162.397651296058, 923.2589125139617, 568.5398278704057, 618.945041287856, 613.2710613585145, 478.8785488254787, 661.3126380779028, 507.2702880577169, 680.8396019379418, 642.9774430289742, 4.596142346378157, 15.605500606532404, 12.172058859465823, 5.918264352227295, 44.729502540740796, 5.975953317447308, 48.69987411197162, 6.043129799733063, 4.2825791886963644, 1.8312381913544773, 6.852405707135332, 4.714578176103202, 3.82404825475142, 1.8390167797042296, 116.62952719840158, 10.998314845116495, 13.316518285928536, 3.887428098154338, 13.726584393323552, 7.809127091244887, 2.835008797249737, 5.819814332277488, 1.852086040572027, 1.8466340688937761, 3.4421858863748636, 7.612668165941756, 4.906257145831952, 14.38091415308663, 1.8591267087808427, 3.4678169617259256, 13.849394651990574, 9.909494467486251, 17.36972033510707, 77.91158092144026, 14.743256969426591, 12.432838605829794, 99.76587988912479, 49.715405224513155, 29.142834454241243, 18.893292304608785, 96.66433832960293, 46.548383282727464, 47.38256489969362, 62.41921208919316, 160.38661138287392, 167.7314023195331, 149.34568665714713, 45.71667319567717, 176.44491225125006, 58.49244844661114, 83.68627615133981, 220.41337515909962, 618.945041287856, 526.5028438301028, 283.5656620539466, 121.42520914374373, 132.43246835648478, 142.8227357824255, 78.89702468061489, 780.3093406841605, 568.5398278704057, 455.77246541808125, 1318.8956887659544, 179.12104217773586, 1162.397651296058, 923.2589125139617, 960.2763139497172, 761.2780518287813, 704.3608326444285, 1466.7136304609128, 546.8013900790928, 661.3126380779028, 478.8785488254787, 1559.2596711330125, 756.77106929359, 513.5688765267455, 507.2702880577169, 417.428162269897, 621.652409234945, 654.2320979910959, 613.2710613585145, 512.6134593458777, 680.8396019379418, 618.917775167437, 570.347046585555, 604.5650651498108, 485.6681521674229, 628.933681927791, 7.244572415807617, 20.339261440356427, 5.715174164652139, 17.762965510237915, 12.422249575327609, 7.115004268853688, 2.3862624676566124, 51.13955423198138, 6.551178288811467, 22.88585592606306, 4.9198421736978295, 5.50104211058765, 22.85160575274482, 5.989196463091553, 5.753280882474576, 11.510772501103734, 9.187915056934012, 7.924151200583587, 30.750685645492144, 2.48403289774141, 14.542855284239156, 2.4473180408992814, 20.579285208098934, 2.5817563268610324, 2.573355510240051, 60.37073825386367, 2.5391785918463676, 16.133348804372826, 2.4747324532990156, 2.485265723068621, 29.453347993427737, 15.13203736962687, 12.389330520158987, 13.172633240753575, 24.941697914268556, 7.601001227033972, 30.451288440004607, 93.76727569647599, 120.64771970524609, 38.801784431185716, 52.80274846065958, 186.49653402016355, 338.1628944744757, 39.82871112875894, 168.70824304125344, 1466.7136304609128, 87.19162981844737, 570.347046585555, 115.47164036309218, 70.72138618987722, 1559.2596711330125, 564.6744363971848, 1162.397651296058, 642.9774430289742, 417.428162269897, 618.917775167437, 100.83760346559298, 419.32594059100285, 628.933681927791, 780.3093406841605, 513.5688765267455, 960.2763139497172, 326.43961205291833, 284.1448655466571, 309.4547681164603, 680.8396019379418, 512.6134593458777, 704.3608326444285, 923.2589125139617, 761.2780518287813, 611.6881296146746, 526.5028438301028, 1318.8956887659544, 513.7660022566189, 613.2710613585145, 661.3126380779028, 621.652409234945, 568.5398278704057, 464.6120973748052, 546.8013900790928, 604.5650651498108, 485.6681521674229, 756.77106929359, 6.15433604453752, 14.014935567867132, 3.8654990959739965, 4.777254168236267, 3.914630065190026, 17.816949650172788, 4.015421479752514, 4.784558419647719, 3.171114184264095, 80.93368584628446, 6.336331013927082, 1.6194594005140412, 4.190276372766117, 5.686378926453407, 4.383912955680833, 39.17165163784446, 2.387365221120725, 43.881951671863845, 4.8839914949692655, 21.129694915226302, 4.0105345513198, 39.68959035293915, 4.022194867435009, 6.1834962845621195, 18.135544150157582, 11.653365075271747, 2.6941812000332757, 1.6310566341742478, 2.470343465905089, 2.4422669811131255, 149.34568665714713, 9.802751035683423, 5.4149014447038635, 10.145579675310833, 38.34268515427472, 67.93225405693524, 193.08206269572398, 28.366620939441336, 27.890437342519416, 42.15604283848535, 24.126806303604926, 100.83760346559298, 63.38278355525403, 64.26685215745967, 761.2780518287813, 106.13809610371587, 654.2320979910959, 103.46378271050327, 455.77246541808125, 176.0135285208986, 613.2710613585145, 546.8013900790928, 308.43914118641214, 618.917775167437, 252.1631050586333, 296.66570860765273, 1162.397651296058, 680.8396019379418, 923.2589125139617, 411.67983785937986, 526.5028438301028, 611.6881296146746, 756.77106929359, 283.5656620539466, 282.89830171057537, 704.3608326444285, 1466.7136304609128, 1559.2596711330125, 960.2763139497172, 512.6134593458777, 513.7660022566189, 628.933681927791, 464.6120973748052, 318.67774982902483, 1318.8956887659544, 661.3126380779028, 411.88296170696776, 478.8785488254787, 604.5650651498108, 564.6744363971848, 780.3093406841605, 568.5398278704057, 507.2702880577169, 621.652409234945, 24.18997740195193, 39.90800799938005, 29.453347993427737, 3.6839160114324434, 10.71960783694793, 2.950403145142143, 3.6771708490902326, 23.33117627252639, 10.691893997932146, 4.4663560775637725, 10.327970009196815, 3.7322452969961626, 5.98031130502353, 5.912021078927192, 10.583403535560745, 5.977544188882994, 4.589628448575989, 2.284048357928843, 5.969177775558569, 3.745419985024066, 5.363332669870735, 2.2861079164868423, 3.0569819598660217, 6.885162173613325, 4.492223507393227, 3.9033556837444525, 1.5428472952393186, 3.028872523387931, 9.850701477289324, 24.87660877275532, 6.892811465610591, 33.54940674513468, 186.49653402016355, 69.31389919366276, 66.64692409153619, 8.706695864835872, 1162.397651296058, 1318.8956887659544, 140.8321574093131, 68.55391487052789, 923.2589125139617, 960.2763139497172, 160.38661138287392, 507.2702880577169, 628.933681927791, 780.3093406841605, 761.2780518287813, 326.43961205291833, 564.6744363971848, 613.2710613585145, 318.67774982902483, 266.7493378625839, 236.7202305091665, 680.8396019379418, 642.9774430289742, 1466.7136304609128, 621.652409234945, 513.5688765267455, 1559.2596711330125, 568.5398278704057, 618.945041287856, 526.5028438301028, 704.3608326444285, 756.77106929359, 618.917775167437, 604.5650651498108, 417.428162269897, 512.6134593458777, 513.7660022566189, 661.3126380779028, 570.347046585555, 611.6881296146746, 654.2320979910959, 478.8785488254787], \"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\"], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -7.942, -8.898, -8.1513, -7.2947, -9.3409, -8.4536, -9.2361, -9.7626, -8.982, -9.7903, -10.285, -10.4975, -9.1013, -8.9513, -8.9615, -8.5296, -10.0123, -9.2881, -10.2437, -8.4432, -10.5472, -8.8757, -10.5641, -7.4872, -10.5791, -8.8532, -10.6627, -10.3218, -10.6149, -10.3095, -8.5001, -7.1562, -9.3125, -6.962, -8.5022, -7.0571, -7.4873, -5.9015, -6.5079, -5.788, -6.9657, -5.5046, -5.9518, -6.4041, -6.4492, -6.0856, -7.3291, -4.9442, -6.7186, -6.0621, -5.5603, -5.1201, -5.9304, -6.0408, -6.5531, -6.5358, -6.5258, -5.0049, -5.5686, -5.7077, -6.3976, -5.7815, -5.598, -5.9809, -5.7987, -5.8043, -5.7927, -5.1312, -5.9693, -6.1331, -5.5786, -6.0781, -5.925, -5.9532, -5.588, -6.0159, -5.9299, -5.8799, -6.045, -6.0436, -6.0486, -7.94, -8.6775, -8.8823, -8.5347, -9.94, -8.7061, -9.4302, -9.4589, -8.4069, -9.3488, -8.3408, -9.9696, -8.3611, -9.5035, -10.4969, -9.69, -9.8279, -9.8207, -9.83, -8.6453, -10.5633, -8.8867, -10.002, -9.3417, -10.5496, -10.2873, -10.0737, -10.5546, -10.5967, -10.5563, -7.8888, -7.9222, -7.7715, -9.3122, -7.9521, -9.7009, -5.218, -7.851, -6.9011, -7.6998, -7.8449, -7.428, -6.5536, -6.1758, -7.0343, -5.2635, -6.4715, -4.9315, -5.7195, -5.712, -6.5061, -4.967, -5.7442, -5.9469, -5.7568, -5.7514, -5.8415, -5.8381, -6.1912, -6.4554, -5.2038, -6.137, -5.3139, -5.9613, -5.9548, -5.6389, -5.7308, -5.8982, -5.6899, -6.4313, -5.6069, -5.9995, -5.8894, -5.9991, -5.9758, -6.1022, -5.9913, -6.0639, -6.1231, -7.3844, -9.1527, -9.3406, -9.3932, -8.4274, -7.6719, -9.7345, -9.1162, -8.5193, -9.4313, -9.8371, -9.2027, -9.0537, -10.3752, -7.7545, -8.8646, -8.5086, -9.297, -7.121, -9.5578, -8.2644, -8.1115, -10.8043, -9.8541, -7.7391, -8.8071, -9.7704, -9.7502, -10.4503, -10.413, -9.9107, -9.6743, -7.1528, -8.818, -9.1688, -8.5181, -4.4173, -8.9175, -5.2583, -7.1899, -6.303, -7.0243, -7.2586, -6.1391, -7.8674, -7.0026, -6.8384, -6.8349, -5.6817, -5.4561, -5.6928, -5.3624, -6.0273, -6.5791, -6.4117, -5.7138, -5.4432, -5.7104, -6.4284, -5.7642, -6.3903, -5.8312, -5.9599, -5.9752, -5.8685, -5.7389, -5.516, -6.0741, -5.3929, -5.86, -5.8011, -5.9537, -5.5321, -6.0615, -6.1934, -6.256, -6.1203, -6.1122, -6.1412, -6.1337, -6.1302, -7.2509, -8.312, -9.1941, -10.0883, -8.5105, -9.7329, -8.2396, -8.2842, -9.7224, -9.771, -9.9962, -10.2892, -9.6024, -9.5402, -10.1116, -9.9392, -10.2457, -10.3595, -8.396, -9.2839, -9.8274, -10.52, -9.531, -10.3444, -8.6565, -10.1489, -10.5757, -7.9358, -8.9038, -10.3408, -7.7989, -8.6801, -9.3527, -7.0732, -9.1242, -7.521, -8.5567, -7.7583, -6.541, -5.4289, -5.8813, -7.281, -4.7612, -6.6036, -5.6337, -6.5603, -7.1814, -7.8398, -7.7598, -5.5995, -6.7279, -5.332, -7.0216, -6.438, -6.4995, -6.3838, -5.8041, -5.7431, -5.5712, -5.8223, -5.7469, -5.9994, -5.2792, -5.1834, -5.4376, -5.8005, -5.0772, -5.803, -6.2024, -5.9578, -5.8057, -6.3031, -5.7548, -6.2117, -5.9096, -6.0066, -6.2909, -5.9892, -6.1187, -6.243, -5.9944, -6.1648, -6.1677, -6.0701, -6.1148, -8.9466, -9.557, -10.2811, -8.8982, -9.3669, -9.8886, -9.9321, -9.1416, -9.1126, -8.574, -8.0508, -11.0623, -10.3396, -10.1319, -10.6582, -9.6733, -8.3052, -10.6518, -10.6737, -8.6812, -11.118, -10.0404, -9.6138, -10.6817, -10.7709, -11.1672, -9.9123, -8.5199, -9.4273, -10.7325, -9.4771, -9.0101, -8.1528, -9.0147, -6.7572, -8.6944, -8.2983, -7.4213, -8.0251, -5.9246, -8.5109, -8.203, -5.3367, -6.8382, -4.883, -7.3081, -6.3465, -6.5481, -7.9736, -5.2765, -5.8104, -6.3683, -5.6656, -5.6842, -5.1385, -6.7085, -4.9724, -5.343, -5.5758, -5.8242, -5.7229, -5.7036, -6.4994, -5.8705, -6.4814, -5.0196, -5.8001, -5.7129, -6.4042, -6.234, -6.537, -6.5536, -5.9921, -5.8609, -6.0117, -6.067, -6.2353, -5.8909, -5.9958, -5.8935, -5.8706, -5.9993, -6.1415, -6.2236, -6.1898, -6.1661, -7.8947, -9.8619, -10.1951, -7.7883, -9.6321, -8.2369, -9.9869, -9.2812, -9.0733, -9.561, -8.1307, -10.0303, -9.9326, -10.2164, -10.2363, -10.0317, -10.2341, -10.0526, -9.6767, -7.9063, -9.1409, -10.3101, -9.1227, -9.1921, -9.2479, -9.1184, -10.2973, -10.5985, -7.4803, -10.6086, -6.3399, -8.4009, -6.9355, -8.7356, -6.8333, -8.2512, -7.7547, -7.6622, -8.3014, -7.2359, -6.4628, -5.3804, -7.6809, -8.2771, -6.4744, -5.9929, -7.0804, -6.1674, -6.764, -6.437, -5.6936, -5.9635, -5.8007, -5.7115, -5.1028, -6.0632, -4.9815, -5.9075, -5.4064, -6.4927, -5.9287, -6.1858, -5.1295, -6.2071, -5.8256, -6.3506, -5.9098, -5.9707, -5.8969, -5.7443, -6.1795, -5.8603, -5.7594, -5.8286, -5.5504, -5.6906, -5.9816, -5.9707, -5.9837, -6.1017, -5.9975, -6.0935, -6.064, -6.0879, -9.5539, -8.3504, -8.6068, -9.4144, -7.4323, -9.4578, -7.3661, -9.4536, -9.7994, -10.6564, -9.338, -9.7191, -9.9397, -10.6738, -6.5279, -8.8901, -8.7055, -9.9375, -8.6794, -9.2434, -10.2575, -9.5418, -10.6894, -10.6929, -10.0704, -9.2779, -9.7291, -8.6548, -10.7007, -10.0774, -8.6986, -9.0384, -8.4934, -7.0473, -8.6824, -8.8468, -6.8817, -7.5386, -8.0412, -8.4593, -6.9428, -7.6277, -7.6199, -7.3796, -6.5406, -6.5022, -6.6497, -7.7211, -6.6056, -7.5368, -7.2416, -6.4438, -5.6081, -5.7722, -6.2778, -6.9687, -6.9018, -6.846, -7.3104, -5.546, -5.7899, -5.9624, -5.1653, -6.683, -5.2671, -5.4417, -5.4882, -5.6715, -5.7303, -5.2451, -5.9467, -5.8475, -6.0576, -5.3, -5.7724, -6.0368, -6.0542, -6.167, -5.9507, -5.9351, -5.9729, -6.0776, -5.9811, -6.0344, -6.1114, -6.0946, -6.198, -6.1761, -9.1927, -8.1913, -9.4641, -8.4187, -8.792, -9.3577, -10.466, -7.4024, -9.4705, -8.2396, -9.7841, -9.6779, -8.2653, -9.6103, -9.6603, -8.9725, -9.1997, -9.3508, -7.9954, -10.5169, -8.7513, -10.5515, -8.4225, -10.5, -10.5071, -7.3523, -10.5216, -8.6752, -10.5513, -10.5492, -8.0817, -8.7457, -8.9509, -8.891, -8.2693, -9.4379, -8.0835, -7.0304, -6.8031, -7.8882, -7.6141, -6.4863, -5.96, -7.9006, -6.643, -4.7516, -7.2314, -5.6508, -7.0115, -7.4463, -4.8601, -5.7491, -5.186, -5.6698, -6.0406, -5.7348, -7.1758, -6.0654, -5.7715, -5.6141, -5.9476, -5.4978, -6.2966, -6.4014, -6.3617, -5.805, -6.0195, -5.8115, -5.6289, -5.7861, -5.9437, -6.0456, -5.47, -6.0876, -6.0026, -5.995, -6.0384, -6.0923, -6.2028, -6.1419, -6.1277, -6.1916, -6.1603, -9.3373, -8.5991, -9.9379, -9.7616, -9.9682, -8.5229, -10.0702, -9.9001, -10.3121, -7.0737, -9.6292, -10.9942, -10.0525, -9.7498, -10.0192, -7.83, -10.6359, -7.7371, -9.9358, -8.4801, -10.1518, -7.8647, -10.1589, -9.742, -8.6661, -9.1168, -10.5851, -11.0882, -10.6757, -10.6899, -6.5846, -9.3185, -9.9057, -9.2936, -8.0123, -7.4676, -6.5058, -8.3274, -8.344, -7.9868, -8.5003, -7.2022, -7.6326, -7.6246, -5.4349, -7.1864, -5.5927, -7.2177, -5.9318, -6.7632, -5.6819, -5.7863, -6.2825, -5.7008, -6.4699, -6.344, -5.2177, -5.6619, -5.4161, -6.0939, -5.8954, -5.7899, -5.634, -6.4205, -6.4238, -5.7243, -5.1885, -5.1433, -5.5248, -5.9867, -5.991, -5.8676, -6.0818, -6.3459, -5.3682, -5.8635, -6.1776, -6.093, -5.9678, -6.0075, -5.84, -6.1079, -6.1612, -6.1454, -7.5544, -7.0701, -7.3898, -9.4964, -8.439, -9.757, -9.5393, -7.7127, -8.5092, -9.4169, -8.5819, -9.5998, -9.1327, -9.1562, -8.5822, -9.1695, -9.4677, -10.1704, -9.2148, -9.684, -9.3437, -10.199, -9.9183, -9.1161, -9.5701, -9.7192, -10.6494, -9.9755, -8.7998, -7.8811, -9.1936, -7.776, -6.258, -7.2562, -7.3039, -9.0483, -5.0145, -4.953, -6.8057, -7.3766, -5.3394, -5.3431, -6.7224, -5.8703, -5.715, -5.5705, -5.6237, -6.2443, -5.845, -5.8042, -6.2769, -6.4271, -6.5171, -5.7912, -5.838, -5.2924, -5.877, -6.03, -5.3458, -5.9727, -5.9379, -6.0768, -5.9399, -5.9091, -6.0228, -6.0461, -6.2512, -6.16, -6.1801, -6.092, -6.1478, -6.1636, -6.1785, -6.2136], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 0.7013, 0.6792, 0.6787, 0.6763, 0.673, 0.6726, 0.67, 0.658, 0.6575, 0.6286, 0.6279, 0.6266, 0.6266, 0.625, 0.6194, 0.6138, 0.6137, 0.6101, 0.6095, 0.6075, 0.5999, 0.5973, 0.5919, 0.5724, 0.5657, 0.5641, 0.5604, 0.5603, 0.5578, 0.5574, 0.5571, 0.5381, 0.543, 0.4689, 0.512, 0.4612, 0.4558, 0.3708, 0.4014, 0.3518, 0.4247, 0.3124, 0.3423, 0.3737, 0.3656, 0.319, 0.435, 0.1825, 0.3634, 0.2758, 0.1937, 0.1329, 0.2396, 0.2497, 0.312, 0.3086, 0.2883, 0.0155, 0.1076, 0.12, 0.2438, 0.1017, 0.0536, 0.1449, 0.0937, 0.0907, 0.0745, -0.1719, 0.1024, 0.158, -0.0953, 0.1112, 0.0432, 0.0539, -0.144, 0.0664, -0.0466, -0.092, 0.0245, -0.1647, -0.2035, 0.9454, 0.9356, 0.9121, 0.8822, 0.8668, 0.8593, 0.8537, 0.8536, 0.8425, 0.8404, 0.8399, 0.8253, 0.816, 0.8052, 0.7911, 0.7908, 0.7867, 0.7852, 0.7763, 0.7727, 0.7717, 0.7665, 0.7663, 0.7598, 0.7536, 0.7508, 0.7505, 0.7471, 0.7463, 0.7393, 0.7378, 0.7212, 0.6972, 0.7256, 0.6646, 0.7316, 0.4642, 0.5815, 0.4606, 0.5392, 0.5459, 0.4942, 0.375, 0.3119, 0.4265, 0.1806, 0.3425, 0.089, 0.1873, 0.1552, 0.2924, -0.0077, 0.139, 0.1788, 0.1382, 0.1275, 0.1335, 0.1301, 0.2114, 0.2684, -0.0771, 0.1748, -0.0609, 0.1209, 0.1169, 0.0127, 0.0231, 0.0668, -0.0137, 0.244, -0.1236, 0.0076, -0.1015, -0.1159, -0.148, -0.0572, -0.1743, -0.1714, -0.278, 1.1339, 1.1189, 1.0987, 1.0579, 1.0322, 1.0071, 1.0012, 0.9993, 0.9973, 0.9794, 0.9615, 0.9497, 0.9426, 0.9395, 0.9279, 0.926, 0.9244, 0.9171, 0.9127, 0.9067, 0.9056, 0.9034, 0.9027, 0.884, 0.8797, 0.8781, 0.8757, 0.8746, 0.8725, 0.869, 0.8689, 0.8663, 0.8287, 0.8461, 0.855, 0.8325, 0.542, 0.8285, 0.5868, 0.6834, 0.5902, 0.6392, 0.6433, 0.4859, 0.7129, 0.5724, 0.5438, 0.5363, 0.2833, 0.2261, 0.2139, 0.1209, 0.2632, 0.3972, 0.3512, 0.1694, 0.0009, 0.0775, 0.2978, 0.0636, 0.2759, 0.0612, 0.11, 0.0943, 0.0147, -0.0627, -0.2629, 0.0516, -0.3725, -0.1061, -0.1496, -0.0748, -0.4054, -0.0165, 0.0792, 0.1365, -0.0381, -0.1372, -0.173, -0.2387, -0.263, 0.9728, 0.9485, 0.9365, 0.9312, 0.9023, 0.8898, 0.8825, 0.8695, 0.8551, 0.8492, 0.8398, 0.8327, 0.8318, 0.8244, 0.8107, 0.8066, 0.8045, 0.7976, 0.794, 0.7911, 0.791, 0.7909, 0.7896, 0.7874, 0.7861, 0.7705, 0.7689, 0.7675, 0.7673, 0.7662, 0.762, 0.7509, 0.7548, 0.7039, 0.7412, 0.6197, 0.6828, 0.6184, 0.5108, 0.359, 0.3913, 0.5407, 0.2592, 0.4614, 0.3313, 0.4316, 0.5056, 0.5858, 0.5726, 0.2456, 0.3887, 0.1513, 0.4253, 0.3191, 0.3154, 0.2914, 0.1641, 0.1493, 0.111, 0.1527, 0.1319, 0.1899, -0.0262, -0.0567, 0.0064, 0.1062, -0.1179, 0.092, 0.2001, 0.0872, 0.0221, 0.1986, -0.0786, 0.1522, -0.0264, 0.0005, 0.17, -0.1722, -0.0493, 0.0688, -0.3429, -0.0931, -0.0978, -0.3161, -0.2476, 0.8195, 0.7878, 0.761, 0.7508, 0.7458, 0.731, 0.7285, 0.7285, 0.7028, 0.7021, 0.6998, 0.697, 0.6867, 0.6726, 0.6606, 0.6586, 0.6585, 0.6399, 0.6357, 0.6265, 0.6257, 0.6182, 0.5998, 0.5987, 0.5883, 0.5873, 0.5821, 0.5808, 0.5806, 0.5801, 0.579, 0.5718, 0.5608, 0.566, 0.5023, 0.5563, 0.5333, 0.4829, 0.5143, 0.3872, 0.5303, 0.5069, 0.3149, 0.3941, 0.2437, 0.4252, 0.3287, 0.3389, 0.4785, 0.2068, 0.2591, 0.3028, 0.2133, 0.1991, 0.1145, 0.3111, 0.0481, 0.101, 0.1064, 0.1408, 0.1222, 0.1134, 0.2497, 0.1367, 0.2448, -0.0603, 0.0949, 0.0751, 0.2239, 0.1685, 0.2402, 0.2405, 0.0529, 0.0063, 0.0582, 0.0587, 0.116, -0.0631, -0.0208, -0.1395, -0.1944, -0.0926, -0.0697, 0.0706, -0.1076, -0.2737, 1.0005, 0.9735, 0.9071, 0.9059, 0.9021, 0.8884, 0.8743, 0.8691, 0.8685, 0.8566, 0.8524, 0.8486, 0.8413, 0.8411, 0.8409, 0.8354, 0.8295, 0.8281, 0.8254, 0.8177, 0.8111, 0.8087, 0.8021, 0.7996, 0.7991, 0.7989, 0.7932, 0.7869, 0.7809, 0.7783, 0.7429, 0.7605, 0.6433, 0.7271, 0.6262, 0.6996, 0.6298, 0.6217, 0.6618, 0.5432, 0.4495, 0.3018, 0.5843, 0.6514, 0.4048, 0.3327, 0.4718, 0.3203, 0.4054, 0.3442, 0.1853, 0.2065, 0.1743, 0.1557, 0.0239, 0.2139, -0.0223, 0.1642, 0.0376, 0.2888, 0.1412, 0.2067, -0.1091, 0.1955, 0.0577, 0.2291, 0.0552, 0.0743, 0.0099, -0.068, 0.1323, -0.0325, -0.1078, -0.0746, -0.2974, -0.2073, -0.0134, -0.0875, -0.0912, 0.0381, -0.1805, -0.0113, -0.276, -0.2428, 1.2322, 1.2132, 1.2053, 1.1188, 1.0783, 1.0657, 1.0595, 1.0587, 1.0573, 1.0498, 1.0486, 1.0415, 1.0303, 1.0282, 1.0244, 1.0234, 1.0167, 1.016, 1.0125, 1.0125, 1.0118, 1.0082, 1.0056, 1.005, 1.0047, 1.0036, 0.9916, 0.9905, 0.9904, 0.9903, 0.9844, 0.9794, 0.9631, 0.9083, 0.938, 0.9441, 0.8267, 0.8663, 0.8978, 0.9131, 0.7972, 0.843, 0.8331, 0.7978, 0.6931, 0.6866, 0.6553, 0.7676, 0.5326, 0.7055, 0.6426, 0.4719, 0.2751, 0.2728, 0.386, 0.5432, 0.5233, 0.5036, 0.6327, 0.1056, 0.1782, 0.2269, -0.0386, 0.4402, -0.0141, 0.0417, -0.0442, 0.0047, 0.0237, -0.2246, 0.0604, -0.0305, 0.0822, -0.3407, -0.0902, 0.0331, 0.028, 0.1102, -0.0719, -0.1073, -0.0804, -0.0059, -0.1931, -0.1511, -0.1464, -0.1879, -0.0723, -0.3088, 1.1383, 1.1074, 1.104, 1.0154, 0.9997, 0.9914, 0.9756, 0.9743, 0.9611, 0.9412, 0.9339, 0.9284, 0.9169, 0.9109, 0.9012, 0.8955, 0.8937, 0.8905, 0.89, 0.8845, 0.8828, 0.8647, 0.8644, 0.8627, 0.8589, 0.8584, 0.8578, 0.8552, 0.8539, 0.8516, 0.8467, 0.8487, 0.8435, 0.8421, 0.8254, 0.845, 0.8116, 0.74, 0.7153, 0.7646, 0.7305, 0.5966, 0.5277, 0.7261, 0.5401, 0.2689, 0.6117, 0.3142, 0.5507, 0.6062, 0.0992, 0.2259, 0.067, 0.1753, 0.2366, 0.1485, 0.5219, 0.2072, 0.0957, 0.0375, 0.1222, -0.0538, 0.2264, 0.2604, 0.2148, -0.0171, 0.0522, -0.0576, -0.1455, -0.1098, -0.0487, -0.0006, -0.3433, -0.0181, -0.1101, -0.178, -0.1595, -0.1241, -0.0328, -0.1348, -0.2209, -0.0659, -0.4781, 1.1568, 1.0721, 1.0213, 0.9858, 0.9783, 0.9082, 0.8509, 0.8457, 0.845, 0.844, 0.8358, 0.8349, 0.826, 0.8234, 0.8141, 0.8133, 0.8052, 0.7926, 0.7895, 0.7804, 0.7706, 0.7655, 0.7605, 0.7474, 0.7473, 0.7388, 0.7351, 0.7338, 0.7311, 0.7285, 0.7203, 0.7101, 0.7164, 0.7006, 0.6524, 0.6251, 0.5424, 0.6386, 0.639, 0.5831, 0.6276, 0.4956, 0.5295, 0.5237, 0.2414, 0.4601, 0.2351, 0.4543, 0.2575, 0.3774, 0.2105, 0.2209, 0.2972, 0.1825, 0.3113, 0.2746, 0.0354, 0.126, 0.0672, 0.1971, 0.1496, 0.1051, 0.0482, 0.2433, 0.2424, 0.0297, -0.168, -0.184, -0.0808, 0.085, 0.0785, -0.0004, 0.0882, 0.2012, -0.2416, -0.0465, 0.1129, 0.0468, -0.0611, -0.0325, -0.1884, -0.1398, -0.079, -0.2665, 1.5709, 1.5545, 1.5386, 1.5109, 1.5002, 1.4723, 1.4698, 1.4487, 1.4326, 1.3978, 1.3945, 1.3944, 1.39, 1.3781, 1.3697, 1.3537, 1.3197, 1.3149, 1.3099, 1.3068, 1.288, 1.2854, 1.2756, 1.2658, 1.2388, 1.2302, 1.2282, 1.2276, 1.2239, 1.2163, 1.1871, 1.0222, 0.8249, 0.8164, 0.8079, 1.0989, 0.2385, 0.1737, 0.5579, 0.707, 0.1439, 0.1009, 0.5113, 0.2119, 0.1522, 0.0811, 0.0526, 0.2787, 0.13, 0.0883, 0.2701, 0.2979, 0.3273, -0.0033, 0.0071, -0.2719, 0.0018, 0.0398, -0.3866, -0.0045, -0.0547, -0.0318, -0.1859, -0.227, -0.1396, -0.1393, 0.0259, -0.0883, -0.1107, -0.275, -0.1828, -0.2686, -0.3507, -0.0738]}, \"token.table\": {\"Topic\": [4, 6, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 1, 7, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 4, 6, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 7, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 9, 1, 2, 3, 5, 7, 1, 2, 3, 4, 5, 6, 7, 8, 9, 1, 2, 3, 6, 7, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 4, 5, 9, 1, 2, 3, 4, 5, 7, 8, 9, 1, 2, 1, 2, 3, 4, 5, 6, 7, 8, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 1, 2, 3, 4, 5, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 1, 3, 4, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 8, 9, 1, 2, 3, 4, 1, 2, 6, 1, 2, 3, 4, 5, 6, 7, 8, 9, 2, 1, 2, 3, 4, 5, 6, 7, 9, 1, 2, 3, 6, 7, 1, 2, 3, 4, 5, 6, 7, 8, 9, 1, 2, 4, 5, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 6, 8, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 8, 1, 2, 4, 5, 6, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 8, 1, 2, 3, 6, 1, 2, 3, 4, 5, 6, 8, 1, 2, 3, 4, 5, 8, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 6, 7, 2, 4, 5, 1, 4, 1, 2, 3, 4, 5, 6, 7, 8, 9, 2, 4, 6, 2, 4, 1, 2, 3, 4, 5, 6, 7, 8, 9, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 7, 8, 9, 1, 2, 3, 4, 6, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 9, 1, 2, 3, 4, 5, 6, 7, 9, 1, 2, 3, 4, 5, 6, 7, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 1, 2, 3, 4, 5, 7, 9, 1, 2, 3, 4, 5, 6, 7, 1, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 7, 8, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 8, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 2, 1, 2, 3, 4, 5, 6, 7, 8, 9, 1, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 3, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 1, 2, 3, 4, 5, 6, 8, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 2, 3, 5, 6, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 1, 2, 3, 4, 5, 6, 7, 8, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 6, 1, 2, 3, 4, 5, 6, 7, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 8, 1, 2, 3, 4, 5, 6, 8, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 6, 1, 2, 3, 4, 5, 6, 8, 3, 6, 1, 2, 3, 4, 6, 7, 8, 1, 2, 6, 1, 2, 3, 4, 6, 8, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 2, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 1, 2, 3, 4, 5, 6, 7, 8, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 8, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 1, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 9, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 3, 5, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 8, 9, 10, 1, 2, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 7, 1, 2, 3, 4, 5, 6, 7, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 7, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 1, 2, 3, 4, 5, 6, 7, 8, 9, 1, 1, 2, 6, 1, 2, 6, 8, 1, 2, 3, 4, 5, 6, 7, 8, 9, 3, 4, 1, 2, 6, 1, 2, 4, 5, 1, 2, 3, 4, 5, 6, 7, 8, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 1, 2, 3, 4, 5, 6, 8, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 8, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 1, 2, 3, 4, 5, 8, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 7, 8, 10, 5, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 8, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 5, 1, 2, 3, 4, 5, 7, 1, 2, 3, 4, 5, 6, 7, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 1, 2, 3, 4, 6, 8, 1, 2, 4, 5, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 9, 1, 2, 3, 6, 1, 2, 3, 4, 5, 6, 7, 8, 9, 1, 2, 5, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 6, 8, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 7, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 4, 5, 8, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 3, 4, 1, 2, 1, 2, 3, 4, 5, 6, 8, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 6, 7, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 1, 2, 3, 4, 1, 2, 3, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 10, 1, 2, 3, 4, 5, 7, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 9, 1, 2, 3, 4, 5, 6, 7, 8, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 8, 9, 1, 1, 2, 4, 6, 1, 2, 3, 4, 5, 6, 8, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 2, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 2, 1, 2, 3, 4, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 4, 5, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 4, 5, 1, 2, 3, 4, 5, 6, 7, 8, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 3, 4, 5, 8, 3, 6, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 5, 6, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 9, 1, 2, 3, 4, 5, 6, 7, 1, 4, 7, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 1, 5, 6, 1, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 7, 1, 2, 3, 4, 5, 6, 8, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 1, 2, 3, 6, 7, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 6, 1, 2, 5, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 8, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 1, 2, 3, 5, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 3, 4, 6, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 3, 6, 1, 2, 3, 4, 5, 6, 7, 8, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 9, 1, 2, 3, 4, 5, 6, 7, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 1, 2, 6, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 1, 2, 3, 4, 5, 6, 8, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 1, 2, 3, 4, 5, 6, 7, 8, 9, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 3, 4, 1, 2, 8, 1, 3, 5, 6, 8, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 9, 1, 2, 3, 4, 5, 6, 8, 1, 2, 3, 4, 5, 6, 9, 1, 2, 3, 4, 5, 9, 2, 4, 5, 1, 2, 3, 4, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 8, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 8, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 5, 6, 7, 8, 9, 10, 1, 2, 7, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 1, 1, 2, 3, 4, 6, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 8, 1, 2, 4, 5, 6, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 8, 1, 2, 4, 5, 6, 7, 1, 2, 3, 4, 6, 7, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 5, 6, 7, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 2, 4, 1, 2, 3, 4, 5, 6, 7, 9, 1, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 7, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 1, 2, 3, 5, 6, 8, 1, 2, 3, 4, 5, 6, 8, 9, 1, 2, 3, 4, 5, 6, 8, 1, 2, 1, 2, 3, 5, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 2, 2, 4, 1, 2, 3, 4, 5, 6, 7, 8, 9, 4, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 8, 1, 2, 3, 4, 5, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 9, 1, 2, 3, 4, 5, 1, 2, 4, 5, 6, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 8, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 2, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 7, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 3, 1, 2, 3, 4, 5, 6, 8, 9, 1, 2, 3, 4, 1, 2, 3, 4, 5, 6, 7, 8, 9, 2, 3, 3, 1, 2, 6, 8, 1, 2, 6, 7, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 2, 4, 5, 9, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 10, 2, 4, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 3, 4, 5, 3, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"Freq\": [0.2911314458181187, 0.2911314458181187, 0.24056100834127825, 0.16037400556085216, 0.08018700278042608, 0.12028050417063912, 0.08018700278042608, 0.08018700278042608, 0.04009350139021304, 0.12028050417063912, 0.04009350139021304, 0.04009350139021304, 0.15535081918096394, 0.1035672127873093, 0.25891803196827323, 0.1035672127873093, 0.1035672127873093, 0.05178360639365465, 0.1035672127873093, 0.05178360639365465, 0.05178360639365465, 0.2576666348977369, 0.10736109787405704, 0.10736109787405704, 0.20398608596070836, 0.07515276851183993, 0.06441665872443422, 0.05368054893702852, 0.06441665872443422, 0.042944439149622815, 0.021472219574811408, 0.2472512080983033, 0.1648341387322022, 0.0824170693661011, 0.2472512080983033, 0.0824170693661011, 0.04120853468305055, 0.04120853468305055, 0.0824170693661011, 0.28836585409118654, 0.28836585409118654, 0.2732289447858743, 0.10363856526360749, 0.11306025301484453, 0.09421687751237044, 0.06595181425865931, 0.06595181425865931, 0.09421687751237044, 0.0847951897611334, 0.07537350200989636, 0.01884337550247409, 0.21945505074938398, 0.17068726169396534, 0.08534363084698267, 0.09753557811083734, 0.15849531443011067, 0.06095973631927333, 0.09753557811083734, 0.04876778905541867, 0.06095973631927333, 0.012191947263854667, 0.15018940815133222, 0.07509470407566611, 0.15018940815133222, 0.07509470407566611, 0.15018940815133222, 0.07509470407566611, 0.15018940815133222, 0.07509470407566611, 0.07509470407566611, 0.234307559950689, 0.180156479428752, 0.12288129810747245, 0.10413669331141732, 0.10621942717764568, 0.07810251998356299, 0.059357915187507874, 0.05102697972259449, 0.04373741119079528, 0.019785971729169294, 0.2199713856805284, 0.18466733612686337, 0.09504936418294438, 0.12763771761709675, 0.11405923701953326, 0.09233366806343168, 0.059745314629279324, 0.05159822627074123, 0.040735441792690445, 0.013578480597563482, 0.23455658581231303, 0.23455658581231303, 0.23455658581231303, 0.23455658581231303, 0.28318156812876566, 0.17061249756826255, 0.10377461192296382, 0.12136352919804243, 0.06507899391779087, 0.07387345255533018, 0.07387345255533018, 0.04749007664271226, 0.04045450973268081, 0.01758891727507861, 0.32712002004873686, 0.21263304950351472, 0.17010643960281177, 0.08505321980140589, 0.25515965940421764, 0.08505321980140589, 0.08505321980140589, 0.04252660990070294, 0.04252660990070294, 0.04252660990070294, 0.04252660990070294, 0.21210805349855122, 0.21210805349855122, 0.21210805349855122, 0.2967223067067711, 0.13327357843609208, 0.12070059933834756, 0.0980692369624074, 0.07543787458646722, 0.10561302442105411, 0.06035029966917378, 0.04526272475188033, 0.04777732057142924, 0.01760217073684235, 0.21873857612512299, 0.21873857612512299, 0.10936928806256149, 0.0656215728375369, 0.0656215728375369, 0.10936928806256149, 0.1312431456750738, 0.0437477152250246, 0.0437477152250246, 0.0218738576125123, 0.28785725409143037, 0.1727143524548582, 0.05757145081828607, 0.05757145081828607, 0.05757145081828607, 0.11514290163657213, 0.1727143524548582, 0.05757145081828607, 0.23350414690274632, 0.23350414690274632, 0.23350414690274632, 0.23350414690274632, 0.23350414690274632, 0.20860982605588385, 0.13907321737058922, 0.13907321737058922, 0.06953660868529461, 0.13907321737058922, 0.06953660868529461, 0.13907321737058922, 0.06953660868529461, 0.06953660868529461, 0.34365357480697034, 0.17182678740348517, 0.17182678740348517, 0.17182678740348517, 0.17182678740348517, 0.16604974112061385, 0.23721391588659124, 0.09488556635463649, 0.09488556635463649, 0.09488556635463649, 0.09488556635463649, 0.07116417476597738, 0.023721391588659123, 0.09488556635463649, 0.023721391588659123, 0.2093252661013835, 0.2093252661013835, 0.2093252661013835, 0.2093252661013835, 0.2093252661013835, 0.14473665726869286, 0.14473665726869286, 0.28947331453738573, 0.07236832863434643, 0.14473665726869286, 0.07236832863434643, 0.07236832863434643, 0.07236832863434643, 0.26793522944615505, 0.26793522944615505, 0.17576334214078657, 0.14061067371262925, 0.10545800528447194, 0.17576334214078657, 0.07030533685631463, 0.14061067371262925, 0.07030533685631463, 0.07030533685631463, 0.07030533685631463, 0.28529554392214546, 0.15179185990729532, 0.09509851464071514, 0.10424260258693775, 0.10972905535467133, 0.06949506839129184, 0.06583743321280279, 0.04754925732035757, 0.058522162855824705, 0.012801723124711653, 0.12838384816503964, 0.3851515444951189, 0.06419192408251982, 0.06419192408251982, 0.06419192408251982, 0.12838384816503964, 0.06419192408251982, 0.12838384816503964, 0.21950875535503458, 0.43901751071006917, 0.21950875535503458, 0.1788407182749995, 0.1788407182749995, 0.14903393189583292, 0.05961357275833317, 0.05961357275833317, 0.08942035913749975, 0.08942035913749975, 0.08942035913749975, 0.05961357275833317, 0.05961357275833317, 0.3567174629653135, 0.16248706485366238, 0.16248706485366238, 0.16248706485366238, 0.16248706485366238, 0.16248706485366238, 0.16248706485366238, 0.24823747952084857, 0.1300291559394921, 0.24823747952084857, 0.09456665886508517, 0.08274582650694953, 0.03546249707440694, 0.047283329432542584, 0.047283329432542584, 0.059104161790678234, 0.011820832358135646, 0.21167000253824095, 0.07937625095184035, 0.34396375412464153, 0.13229375158640058, 0.05291750063456024, 0.05291750063456024, 0.02645875031728012, 0.02645875031728012, 0.02645875031728012, 0.2073883128179105, 0.2073883128179105, 0.2073883128179105, 0.12401830519105508, 0.16535774025474012, 0.12401830519105508, 0.08267887012737006, 0.04133943506368503, 0.16535774025474012, 0.08267887012737006, 0.08267887012737006, 0.04133943506368503, 0.08267887012737006, 0.22390487199215373, 0.1185378734076108, 0.27658837128442515, 0.1185378734076108, 0.05268349929227146, 0.05268349929227146, 0.02634174964613573, 0.06585437411533933, 0.039512624469203596, 0.013170874823067865, 0.14270490151845705, 0.21405735227768558, 0.07135245075922853, 0.21405735227768558, 0.14270490151845705, 0.07135245075922853, 0.14270490151845705, 0.18179661267356584, 0.3635932253471317, 0.18179661267356584, 0.18179661267356584, 0.2149425274166453, 0.2149425274166453, 0.2149425274166453, 0.10308804243510836, 0.2061760848702167, 0.12886005304388545, 0.07731603182633127, 0.12886005304388545, 0.10308804243510836, 0.05154402121755418, 0.10308804243510836, 0.05154402121755418, 0.36492079045481035, 0.3432484929600237, 0.08581212324000592, 0.08581212324000592, 0.08581212324000592, 0.08581212324000592, 0.08581212324000592, 0.08581212324000592, 0.08581212324000592, 0.2918682993211308, 0.1459341496605654, 0.1459341496605654, 0.1459341496605654, 0.1459341496605654, 0.16600037537989948, 0.38733420921976547, 0.16600037537989948, 0.0553334584599665, 0.0553334584599665, 0.0553334584599665, 0.0553334584599665, 0.0553334584599665, 0.0553334584599665, 0.24903985921339292, 0.24903985921339292, 0.24903985921339292, 0.24903985921339292, 0.3056989281096369, 0.13586619027094973, 0.09144839729775463, 0.12018932216276323, 0.09406120864911906, 0.0862227745950258, 0.06009466108138162, 0.044417792973195105, 0.044417792973195105, 0.01567686810818651, 0.1740105766086558, 0.29830384561483847, 0.09943461520494616, 0.1242932690061827, 0.07457596140370962, 0.07457596140370962, 0.07457596140370962, 0.02485865380123654, 0.02485865380123654, 0.02485865380123654, 0.19833870810728108, 0.11900322486436865, 0.10908628945900459, 0.13883709567509675, 0.10908628945900459, 0.08925241864827649, 0.03966774162145621, 0.08925241864827649, 0.07933548324291242, 0.019833870810728106, 0.24582996853952527, 0.04916599370790505, 0.1966639748316202, 0.0983319874158101, 0.0983319874158101, 0.0983319874158101, 0.04916599370790505, 0.14749798112371515, 0.04916599370790505, 0.04916599370790505, 0.12766473288128427, 0.30639535891508224, 0.07659883972877056, 0.07659883972877056, 0.07659883972877056, 0.12766473288128427, 0.051065893152513704, 0.10213178630502741, 0.051065893152513704, 0.025532946576256852, 0.16729278252092136, 0.16729278252092136, 0.16729278252092136, 0.16729278252092136, 0.16729278252092136, 0.20438739636158865, 0.1506012394243285, 0.11832954526197237, 0.10757231387452033, 0.11832954526197237, 0.12908677664942442, 0.05378615693726017, 0.06454338832471221, 0.05378615693726017, 0.021514462774904066, 0.21767724098522476, 0.10883862049261238, 0.21767724098522476, 0.10883862049261238, 0.10883862049261238, 0.10883862049261238, 0.10883862049261238, 0.18420517489579705, 0.18420517489579705, 0.18420517489579705, 0.18420517489579705, 0.18420517489579705, 0.22392144537595846, 0.185534911882937, 0.07037531140387265, 0.08956857815038338, 0.15994388955425604, 0.09596633373255363, 0.06397755582170242, 0.05118204465736193, 0.03838653349302145, 0.019193266746510725, 0.2004610202574951, 0.15034576519312132, 0.15034576519312132, 0.07517288259656066, 0.050115255064373775, 0.12528813766093444, 0.07517288259656066, 0.07517288259656066, 0.050115255064373775, 0.07517288259656066, 0.2297082648858209, 0.11485413244291046, 0.11485413244291046, 0.11485413244291046, 0.11485413244291046, 0.11485413244291046, 0.11485413244291046, 0.1864512349975303, 0.1864512349975303, 0.1864512349975303, 0.1864512349975303, 0.14523986142728737, 0.14523986142728737, 0.14523986142728737, 0.14523986142728737, 0.14523986142728737, 0.14523986142728737, 0.14523986142728737, 0.14054805341123316, 0.14054805341123316, 0.14054805341123316, 0.14054805341123316, 0.14054805341123316, 0.14054805341123316, 0.1688907180656806, 0.11259381204378706, 0.1688907180656806, 0.11259381204378706, 0.11259381204378706, 0.11259381204378706, 0.05629690602189353, 0.1688907180656806, 0.05629690602189353, 0.05629690602189353, 0.26271997628213734, 0.13135998814106867, 0.13135998814106867, 0.13135998814106867, 0.13135998814106867, 0.13135998814106867, 0.2554519797138117, 0.2554519797138117, 0.2554519797138117, 0.27478792399886914, 0.27478792399886914, 0.10757093674795837, 0.1434279156639445, 0.17928489457993063, 0.07171395783197225, 0.1434279156639445, 0.17928489457993063, 0.035856978915986125, 0.07171395783197225, 0.035856978915986125, 0.28717470449185023, 0.28717470449185023, 0.28717470449185023, 0.2999145668015512, 0.2999145668015512, 0.3525270077584695, 0.10575810232754086, 0.14101080310338782, 0.035252700775846954, 0.10575810232754086, 0.035252700775846954, 0.07050540155169391, 0.035252700775846954, 0.10575810232754086, 0.11521649200951169, 0.11521649200951169, 0.11521649200951169, 0.23043298401902337, 0.11521649200951169, 0.23043298401902337, 0.28962696552835926, 0.17377617931701556, 0.1158507862113437, 0.05792539310567185, 0.05792539310567185, 0.17377617931701556, 0.05792539310567185, 0.05792539310567185, 0.05792539310567185, 0.16379829928403739, 0.16379829928403739, 0.16379829928403739, 0.16379829928403739, 0.16379829928403739, 0.11978813031889521, 0.35936439095668565, 0.11978813031889521, 0.11978813031889521, 0.11978813031889521, 0.1917501148018909, 0.14381258610141814, 0.2396876435023636, 0.04793752870047272, 0.04793752870047272, 0.07190629305070907, 0.07190629305070907, 0.07190629305070907, 0.07190629305070907, 0.02396876435023636, 0.23146982725483586, 0.15190207413598605, 0.209769530949695, 0.09403461732227708, 0.07956775311884984, 0.057867456813708966, 0.05063402471199535, 0.057867456813708966, 0.04340059261028173, 0.014466864203427241, 0.40571647236508407, 0.08114329447301681, 0.0856512552770733, 0.08114329447301681, 0.10819105929735576, 0.07663533366896033, 0.08114329447301681, 0.040571647236508405, 0.031555725628395426, 0.01352388241216947, 0.4982119906736973, 0.055356887852633034, 0.055356887852633034, 0.11071377570526607, 0.055356887852633034, 0.055356887852633034, 0.11071377570526607, 0.055356887852633034, 0.5191705600001133, 0.06489632000001416, 0.06489632000001416, 0.06489632000001416, 0.06489632000001416, 0.06489632000001416, 0.06489632000001416, 0.06489632000001416, 0.4682230282845759, 0.05852787853557199, 0.05852787853557199, 0.05852787853557199, 0.05852787853557199, 0.05852787853557199, 0.05852787853557199, 0.05852787853557199, 0.5343408334411708, 0.07819621952797622, 0.06516351627331352, 0.06516351627331352, 0.07819621952797622, 0.05213081301865081, 0.05213081301865081, 0.026065406509325404, 0.06516351627331352, 0.013032703254662702, 0.31107987534255926, 0.11311995467002156, 0.12725994900377424, 0.12725994900377424, 0.09897996033626887, 0.02827998866750539, 0.02827998866750539, 0.09897996033626887, 0.05655997733501078, 0.014139994333752695, 0.3202968976229275, 0.5414769832918958, 0.09024616388198262, 0.09024616388198262, 0.09024616388198262, 0.09024616388198262, 0.09024616388198262, 0.09024616388198262, 0.5026413861390935, 0.10052827722781871, 0.10052827722781871, 0.10052827722781871, 0.10052827722781871, 0.10052827722781871, 0.10052827722781871, 0.37117028356802767, 0.3252721224689123, 0.1387524438503752, 0.08188668817399192, 0.09780909976337923, 0.12283003226098786, 0.07733742771988125, 0.05989859597912371, 0.03791050378425551, 0.03715229370857041, 0.02047167204349798, 0.24728475082472112, 0.08242825027490704, 0.16485650054981407, 0.08242825027490704, 0.16485650054981407, 0.08242825027490704, 0.08242825027490704, 0.08242825027490704, 0.38963431168391344, 0.10663675898717631, 0.09023110375837995, 0.1435494832519681, 0.06152120710798633, 0.053318379493588156, 0.049216965686389065, 0.049216965686389065, 0.045115551879189975, 0.012304241421597266, 0.11297633527730121, 0.22595267055460241, 0.11297633527730121, 0.22595267055460241, 0.11297633527730121, 0.11297633527730121, 0.11297633527730121, 0.4031283734027037, 0.05039104667533796, 0.1259776166883449, 0.05039104667533796, 0.07558657001300695, 0.07558657001300695, 0.07558657001300695, 0.05039104667533796, 0.10078209335067592, 0.02519552333766898, 0.35218186014078634, 0.1191203350476189, 0.08286632003312619, 0.07768717503105581, 0.08804546503519659, 0.06732888502691503, 0.07768717503105581, 0.041433160016563095, 0.08286632003312619, 0.015537435006211162, 0.21376100579273652, 0.42752201158547304, 0.21376100579273652, 0.3594325353021899, 0.5379109247597611, 0.08275552688611709, 0.041377763443058546, 0.041377763443058546, 0.08275552688611709, 0.041377763443058546, 0.08275552688611709, 0.041377763443058546, 0.041377763443058546, 0.5562041040740583, 0.41568592660084713, 0.17502565330561984, 0.08751282665280992, 0.051049148880805785, 0.0802200910984091, 0.04375641332640496, 0.04375641332640496, 0.051049148880805785, 0.04375641332640496, 0.007292735554400826, 0.35728473407554906, 0.2783368291632764, 0.13040956331426237, 0.13624879749251292, 0.09926698103025941, 0.1245703291360118, 0.0622851645680059, 0.05255310760425498, 0.05255310760425498, 0.0506066962115048, 0.015571291142001476, 0.2319469524663058, 0.1265165195270759, 0.16868869270276787, 0.10543043293922992, 0.14760260611492187, 0.10543043293922992, 0.021086086587845984, 0.04217217317569197, 0.021086086587845984, 0.021086086587845984, 0.2600837849650644, 0.1322459923551175, 0.11461319337443517, 0.12342959286477634, 0.1366541921002881, 0.05730659668721758, 0.07493939566789992, 0.035265597961364664, 0.052898396942047, 0.01322459923551175, 0.47904500015792845, 0.20628686329920748, 0.06876228776640249, 0.20628686329920748, 0.06876228776640249, 0.13752457553280498, 0.13752457553280498, 0.13752457553280498, 0.06876228776640249, 0.2757016805562217, 0.11028067222248866, 0.05514033611124433, 0.11028067222248866, 0.11028067222248866, 0.05514033611124433, 0.05514033611124433, 0.05514033611124433, 0.11028067222248866, 0.23553394917004797, 0.1717803990187568, 0.10802684886746561, 0.12042337250799445, 0.0938593932782898, 0.09031752938099584, 0.04781516261346838, 0.06729541404858513, 0.046044230664821405, 0.01948025143511675, 0.23917650184016498, 0.23917650184016498, 0.23917650184016498, 0.23917650184016498, 0.23293664040791018, 0.15907868125418256, 0.10794624799390959, 0.0909021035738186, 0.0909021035738186, 0.08522072210045495, 0.07953934062709128, 0.05681381473363663, 0.06817657768036395, 0.017044144420090987, 0.33685331319549444, 0.24303803591653803, 0.13887887766659315, 0.13887887766659315, 0.06943943883329658, 0.13887887766659315, 0.13887887766659315, 0.03471971941664829, 0.06943943883329658, 0.03471971941664829, 0.1714444206874472, 0.12858331551558538, 0.12858331551558538, 0.0857222103437236, 0.0428611051718618, 0.1714444206874472, 0.0857222103437236, 0.0857222103437236, 0.0428611051718618, 0.0857222103437236, 0.2226069113333779, 0.2226069113333779, 0.2226069113333779, 0.5196806672128731, 0.06496008340160914, 0.06496008340160914, 0.06496008340160914, 0.06496008340160914, 0.06496008340160914, 0.06496008340160914, 0.06496008340160914, 0.365128314401298, 0.104322375543228, 0.07824178165742099, 0.07824178165742099, 0.07824178165742099, 0.07824178165742099, 0.07824178165742099, 0.026080593885807, 0.07824178165742099, 0.026080593885807, 0.18432945609767315, 0.18432945609767315, 0.18432945609767315, 0.18432945609767315, 0.18432945609767315, 0.24547048339155594, 0.12273524169577797, 0.12273524169577797, 0.12273524169577797, 0.12273524169577797, 0.12273524169577797, 0.12273524169577797, 0.17330881933540626, 0.17330881933540626, 0.08665440966770313, 0.25996322900310936, 0.17330881933540626, 0.08665440966770313, 0.08665440966770313, 0.08665440966770313, 0.2031396398766374, 0.17924085871468007, 0.11949390580978672, 0.09559512464782938, 0.13144329639076538, 0.04779756232391469, 0.11949390580978672, 0.035848171742936016, 0.035848171742936016, 0.023898781161957344, 0.4841943234818048, 0.07120504757085365, 0.05696403805668292, 0.08544605708502438, 0.05696403805668292, 0.05696403805668292, 0.11392807611336583, 0.01424100951417073, 0.04272302854251219, 0.01424100951417073, 0.18399115050539744, 0.18399115050539744, 0.18399115050539744, 0.18399115050539744, 0.18399115050539744, 0.2415021515876187, 0.0805007171958729, 0.1610014343917458, 0.0805007171958729, 0.0805007171958729, 0.0805007171958729, 0.1610014343917458, 0.2984874527363853, 0.2984874527363853, 0.14507868160752257, 0.14507868160752257, 0.14507868160752257, 0.14507868160752257, 0.14507868160752257, 0.14507868160752257, 0.14507868160752257, 0.2178825609097545, 0.2178825609097545, 0.2178825609097545, 0.1691468935326364, 0.1691468935326364, 0.1691468935326364, 0.1691468935326364, 0.1691468935326364, 0.1691468935326364, 0.16541985286358535, 0.2688072609033262, 0.12406488964768901, 0.08270992643179267, 0.08270992643179267, 0.12406488964768901, 0.062032444823844506, 0.02067748160794817, 0.062032444823844506, 0.02067748160794817, 0.30278266124174974, 0.09215124472574993, 0.1184801717902499, 0.1250624035563749, 0.09215124472574993, 0.07021047217199994, 0.07898678119349993, 0.04607562236287496, 0.06143416315049995, 0.013164463532249988, 0.2799538407112738, 0.2799538407112738, 0.3885976873466336, 0.3357328018165188, 0.14971868189115028, 0.0952755248398229, 0.05444315705132737, 0.07712780582271378, 0.06805394631415922, 0.09981245459410018, 0.04536929754277281, 0.05444315705132737, 0.013610789262831843, 0.37344290554635856, 0.10892084745102125, 0.07780060532215803, 0.09336072638658964, 0.07780060532215803, 0.06224048425772643, 0.06224048425772643, 0.04668036319329482, 0.07780060532215803, 0.015560121064431607, 0.2563313355691994, 0.24031062709612444, 0.09612425083844978, 0.06408283389229985, 0.06408283389229985, 0.08010354236537481, 0.14418637625767466, 0.032041416946149925, 0.016020708473074963, 0.016020708473074963, 0.4717937624122582, 0.18897512442759118, 0.18897512442759118, 0.09448756221379559, 0.09448756221379559, 0.09448756221379559, 0.18897512442759118, 0.09448756221379559, 0.09448756221379559, 0.09448756221379559, 0.3000009688268507, 0.13820269350450426, 0.12471950389430872, 0.08764073246627099, 0.11123631428411318, 0.06741594805097768, 0.04719116363568438, 0.04044956883058661, 0.060674353245879914, 0.020224784415293306, 0.16869750609928477, 0.11246500406618984, 0.33739501219856954, 0.11246500406618984, 0.11246500406618984, 0.05623250203309492, 0.05623250203309492, 0.05623250203309492, 0.18341504719720197, 0.06113834906573399, 0.30569174532866994, 0.12227669813146798, 0.06113834906573399, 0.06113834906573399, 0.06113834906573399, 0.06113834906573399, 0.06113834906573399, 0.2743625219006255, 0.18994328439274075, 0.06331442813091358, 0.08441923750788477, 0.06331442813091358, 0.08441923750788477, 0.14773366563879836, 0.042209618753942385, 0.042209618753942385, 0.021104809376971193, 0.15379582829829455, 0.07689791414914728, 0.3075916565965891, 0.15379582829829455, 0.07689791414914728, 0.07689791414914728, 0.07689791414914728, 0.07689791414914728, 0.5378869526627202, 0.347186004993663, 0.1213937080397423, 0.16023969461245982, 0.08254772146702476, 0.06798047650225568, 0.06069685401987115, 0.055841105698281455, 0.04127386073351238, 0.05341323153748661, 0.014567244964769075, 0.31379661759771876, 0.12238068086311032, 0.14434644409495065, 0.08786305292736125, 0.09727695145529283, 0.05648339116758938, 0.06275932351954376, 0.037655594111726254, 0.05648339116758938, 0.021965763231840314, 0.17504240372777918, 0.13128180279583437, 0.17504240372777918, 0.08752120186388959, 0.13128180279583437, 0.08752120186388959, 0.043760600931944796, 0.13128180279583437, 0.043760600931944796, 0.043760600931944796, 0.23322551719898055, 0.18194898504885007, 0.15217551476812916, 0.11578571775835914, 0.08766632915990048, 0.07608775738406458, 0.05127653215013048, 0.04300612373881911, 0.04466020542108138, 0.014886735140360461, 0.5530487709261678, 0.06913109636577097, 0.06913109636577097, 0.06913109636577097, 0.06913109636577097, 0.06913109636577097, 0.06913109636577097, 0.06913109636577097, 0.199864966177763, 0.0999324830888815, 0.0999324830888815, 0.0999324830888815, 0.199864966177763, 0.0999324830888815, 0.0999324830888815, 0.2897863396708037, 0.16953486538564028, 0.11828013864114437, 0.08476743269282014, 0.0867387683368392, 0.07491075447272477, 0.0650540762526294, 0.047312055456457745, 0.0433693841684196, 0.0216846920842098, 0.1741154285126732, 0.1741154285126732, 0.0870577142563366, 0.0870577142563366, 0.1741154285126732, 0.0870577142563366, 0.0870577142563366, 0.2852652462433647, 0.1276186627930842, 0.16515356361457956, 0.07882329172514024, 0.12386517271093465, 0.0638093313965421, 0.05630235123224303, 0.03378141073934582, 0.04879537106794396, 0.011260470246448606, 0.21617725615297717, 0.21617725615297717, 0.21617725615297717, 0.09832296251475986, 0.19664592502951972, 0.09832296251475986, 0.19664592502951972, 0.09832296251475986, 0.19664592502951972, 0.09832296251475986, 0.09832296251475986, 0.3097046863425823, 0.14108769044495414, 0.09463198749356681, 0.10065402306133925, 0.10753634942450774, 0.055918901700744025, 0.06194093726851646, 0.05763948329153615, 0.04903657533757553, 0.02236756068029761, 0.29255866761024474, 0.1748992034626463, 0.0953995655250798, 0.08108963069631783, 0.09698955828383114, 0.08744960173132316, 0.04610979000378858, 0.05882973207379922, 0.0476997827625399, 0.020669905863767293, 0.10843102367709255, 0.1355387795963657, 0.18975429143491196, 0.2168620473541851, 0.054215511838546275, 0.10843102367709255, 0.027107755919273138, 0.054215511838546275, 0.027107755919273138, 0.027107755919273138, 0.31218002547939566, 0.11352000926523478, 0.11094000905466127, 0.10578000863351424, 0.10836000884408775, 0.06450000526433795, 0.06966000568548499, 0.05160000421147036, 0.05160000421147036, 0.01290000105286759, 0.294338138845463, 0.13735779812788274, 0.09811271294848767, 0.16679161201242904, 0.0883014416536389, 0.058867627769092594, 0.03924508517939507, 0.049056356474243834, 0.049056356474243834, 0.019622542589697534, 0.09465351998806082, 0.18930703997612164, 0.09465351998806082, 0.28396055996418246, 0.09465351998806082, 0.04732675999403041, 0.04732675999403041, 0.09465351998806082, 0.04732675999403041, 0.3527325915073376, 0.3527325915073376, 0.32937663374748855, 0.15333050191693434, 0.11073869582889702, 0.07524552408886592, 0.08376388530647338, 0.06956661661046094, 0.06388770913205598, 0.05111016730564478, 0.04827071356644229, 0.014197268696012438, 0.29051307309064284, 0.29051307309064284, 0.14016802928419772, 0.35042007321049434, 0.14016802928419772, 0.07008401464209886, 0.07008401464209886, 0.07008401464209886, 0.07008401464209886, 0.07008401464209886, 0.16456857876555347, 0.07052939089952291, 0.14105878179904582, 0.21158817269856875, 0.1175489848325382, 0.047019593933015275, 0.09403918786603055, 0.047019593933015275, 0.07052939089952291, 0.023509796966507637, 0.18184603988565085, 0.09092301994282542, 0.09092301994282542, 0.18184603988565085, 0.09092301994282542, 0.18184603988565085, 0.20575283507438538, 0.14340349111245043, 0.11222881913148294, 0.12469868792386993, 0.10599388473528944, 0.062349343961934964, 0.12469868792386993, 0.03740960637716098, 0.04987947516954797, 0.031174671980967482, 0.27145027109647996, 0.27145027109647996, 0.21573960215855795, 0.09245982949652484, 0.1540997158275414, 0.12327977266203312, 0.1540997158275414, 0.06163988633101656, 0.03081994316550828, 0.06163988633101656, 0.06163988633101656, 0.46537817566760703, 0.26699275488422286, 0.26699275488422286, 0.26699275488422286, 0.1603428365292188, 0.3206856730584376, 0.1603428365292188, 0.1603428365292188, 0.24868604341982492, 0.12434302170991246, 0.0828953478066083, 0.0828953478066083, 0.12434302170991246, 0.0828953478066083, 0.0828953478066083, 0.0828953478066083, 0.0828953478066083, 0.3677310849061171, 0.3677310849061171, 0.271948201766967, 0.271948201766967, 0.271948201766967, 0.16253864683927838, 0.16253864683927838, 0.16253864683927838, 0.16253864683927838, 0.1611714070852261, 0.1343095059043551, 0.1611714070852261, 0.05372380236174203, 0.1343095059043551, 0.18803330826609713, 0.026861901180871017, 0.05372380236174203, 0.05372380236174203, 0.5230977547834903, 0.06154091232746945, 0.06154091232746945, 0.06154091232746945, 0.06154091232746945, 0.030770456163734725, 0.06154091232746945, 0.030770456163734725, 0.030770456163734725, 0.10295089561507796, 0.30885268684523387, 0.10295089561507796, 0.10295089561507796, 0.10295089561507796, 0.10295089561507796, 0.10295089561507796, 0.21813840661841793, 0.13423901945748795, 0.08389938716092997, 0.2684780389149759, 0.08389938716092997, 0.06711950972874398, 0.03355975486437199, 0.05033963229655798, 0.016779877432185994, 0.016779877432185994, 0.18518865436035406, 0.18518865436035406, 0.3703773087207081, 0.18518865436035406, 0.19928967057634842, 0.1494672529322613, 0.2989345058645226, 0.09964483528817421, 0.07473362646613065, 0.024911208822043552, 0.024911208822043552, 0.07473362646613065, 0.024911208822043552, 0.024911208822043552, 0.29573868017795607, 0.13173813935199863, 0.14249227317665158, 0.0940986709657133, 0.07527893677257064, 0.09141013750955007, 0.0645248029479177, 0.04839360221093827, 0.04032800184244856, 0.016131200736979424, 0.13499933108029402, 0.26999866216058804, 0.13499933108029402, 0.13499933108029402, 0.13499933108029402, 0.4309414726047819, 0.13942224113684118, 0.07604849516554973, 0.06337374597129145, 0.03802424758277487, 0.06337374597129145, 0.11407274274832462, 0.02534949838851658, 0.03802424758277487, 0.01267474919425829, 0.3022970252113242, 0.14225742362885843, 0.09483828241923896, 0.09483828241923896, 0.08298349711683409, 0.08298349711683409, 0.053346533860821915, 0.09483828241923896, 0.029636963256012176, 0.017782177953607304, 0.4040840853995834, 0.1112698757144937, 0.1112698757144937, 0.3338096271434811, 0.1112698757144937, 0.1112698757144937, 0.1112698757144937, 0.28924018243303645, 0.1647062149965902, 0.10846506841238866, 0.08034449512028789, 0.12051674268043185, 0.08034449512028789, 0.04418947231615834, 0.056241146584201526, 0.040172247560143946, 0.020086123780071973, 0.34004947626125115, 0.11334982542041705, 0.0963473516073545, 0.1076823341493962, 0.09067986033633364, 0.039672438897145966, 0.1076823341493962, 0.04533993016816682, 0.039672438897145966, 0.02266996508408341, 0.21855400542753844, 0.07285133514251281, 0.14570267028502562, 0.14570267028502562, 0.14570267028502562, 0.14570267028502562, 0.07285133514251281, 0.07285133514251281, 0.3706788978659695, 0.18056512182380358, 0.1681123548014723, 0.17433873831263794, 0.09339575266748461, 0.14320682075680974, 0.06226383511165641, 0.05603745160049076, 0.05603745160049076, 0.043584684578159484, 0.024905534044662562, 0.20709152588742216, 0.18408135634437525, 0.13806101725828143, 0.06903050862914072, 0.16107118680132834, 0.04602033908609381, 0.06903050862914072, 0.06903050862914072, 0.04602033908609381, 0.023010169543046907, 0.2628663966418719, 0.13824825304868818, 0.13824825304868818, 0.09346360769488778, 0.10125224166946176, 0.08762213221395729, 0.06425623029023535, 0.06036191330294836, 0.03504885288558292, 0.01752442644279146, 0.1665652528030572, 0.1613052974513817, 0.1630586159019402, 0.14377211294579673, 0.1104590623851853, 0.07889933027513235, 0.0543528719673134, 0.07363937492345686, 0.033313050560611436, 0.014026547604467974, 0.2277448969518548, 0.15182993130123654, 0.07591496565061827, 0.2277448969518548, 0.07591496565061827, 0.07591496565061827, 0.15182993130123654, 0.07591496565061827, 0.1697599879346724, 0.1358079903477379, 0.10185599276080344, 0.06790399517386896, 0.06790399517386896, 0.1358079903477379, 0.06790399517386896, 0.1358079903477379, 0.03395199758693448, 0.06790399517386896, 0.29560878123022194, 0.15765801665611837, 0.11824351249208878, 0.07882900832805918, 0.07882900832805918, 0.13795076457410357, 0.03941450416402959, 0.03941450416402959, 0.03941450416402959, 0.03941450416402959, 0.36074337388325983, 0.36074337388325983, 0.16733731789376838, 0.16733731789376838, 0.16733731789376838, 0.16733731789376838, 0.16733731789376838, 0.16733731789376838, 0.3942603703299438, 0.09856509258248596, 0.09856509258248596, 0.09856509258248596, 0.09856509258248596, 0.09856509258248596, 0.09856509258248596, 0.09856509258248596, 0.3933528908855438, 0.13588554412409695, 0.07151870743373524, 0.07390266434819308, 0.10012619040722934, 0.0691347505192774, 0.05721496594698819, 0.05006309520361467, 0.03337539680240978, 0.01668769840120489, 0.33893673196712326, 0.16721537542033782, 0.16721537542033782, 0.16721537542033782, 0.16721537542033782, 0.16721537542033782, 0.16721537542033782, 0.23864774326087526, 0.23864774326087526, 0.23864774326087526, 0.23864774326087526, 0.23665732488576696, 0.15777154992384465, 0.11044008494669125, 0.12621723993907571, 0.07888577496192233, 0.09466292995430678, 0.03155430998476893, 0.04733146497715339, 0.07888577496192233, 0.03155430998476893, 0.1578200377792807, 0.1578200377792807, 0.1578200377792807, 0.1578200377792807, 0.1578200377792807, 0.1578200377792807, 0.22389616560654116, 0.22389616560654116, 0.22389616560654116, 0.22389616560654116, 0.19334720918953155, 0.1288981394596877, 0.15038116270296897, 0.04296604648656256, 0.1288981394596877, 0.08593209297312512, 0.15038116270296897, 0.06444906972984385, 0.06444906972984385, 0.2810827839926637, 0.2810827839926637, 0.2810827839926637, 0.24096229285183005, 0.24096229285183005, 0.09213264138452325, 0.10630689390521914, 0.0992197676448712, 0.07795838886382736, 0.042522757562087656, 0.042522757562087656, 0.0496098838224356, 0.021261378781043828, 0.2280382242564216, 0.1140191121282108, 0.1140191121282108, 0.0760127414188072, 0.1520254828376144, 0.0760127414188072, 0.0760127414188072, 0.0380063707094036, 0.0760127414188072, 0.21661596592373877, 0.21661596592373877, 0.07220532197457959, 0.07220532197457959, 0.07220532197457959, 0.07220532197457959, 0.14441064394915917, 0.16752726047037936, 0.16752726047037936, 0.16752726047037936, 0.16752726047037936, 0.16752726047037936, 0.16752726047037936, 0.19753610109607864, 0.09876805054803932, 0.29630415164411794, 0.09876805054803932, 0.09876805054803932, 0.09876805054803932, 0.2620054825373026, 0.14291208138398323, 0.10888539534017772, 0.0952747209226555, 0.11909340115331937, 0.08506671510951383, 0.06805337208761107, 0.04763736046132775, 0.05444269767008886, 0.013610674417522214, 0.3952470737577487, 0.14624141729036702, 0.08300188548912722, 0.0632395318012398, 0.08300188548912722, 0.055334590326084815, 0.035572236638197384, 0.05928706106366231, 0.05928706106366231, 0.011857412212732461, 0.19239806730753514, 0.13992586713275285, 0.10494440034956462, 0.13992586713275285, 0.05247220017478231, 0.13992586713275285, 0.08745366695797052, 0.05247220017478231, 0.05247220017478231, 0.017490733391594106, 0.2572394844999904, 0.2572394844999904, 0.2572394844999904, 0.27645475869725394, 0.14406797284223094, 0.17521780480811872, 0.1090244118806072, 0.11291814087634316, 0.0545122059403036, 0.046724747948831656, 0.03893728995735971, 0.0272561029701518, 0.011681186987207914, 0.3190377698942797, 0.13673047281183415, 0.09115364854122278, 0.04557682427061139, 0.09115364854122278, 0.04557682427061139, 0.09115364854122278, 0.06836523640591707, 0.11394206067652847, 0.022788412135305695, 0.18178373840755324, 0.18178373840755324, 0.18178373840755324, 0.18178373840755324, 0.18178373840755324, 0.27544572547065205, 0.1643129203921464, 0.08522454377186017, 0.13431388098445163, 0.10090585982588243, 0.06749783866731325, 0.049771133562766336, 0.07022502406801277, 0.03954418831014312, 0.013635927003497627, 0.20689943186432988, 0.41379886372865976, 0.20689943186432988, 0.22810671883988112, 0.22810671883988112, 0.19579614070090684, 0.13053076046727122, 0.06526538023363561, 0.19579614070090684, 0.19579614070090684, 0.06526538023363561, 0.06526538023363561, 0.06526538023363561, 0.22150920560353338, 0.2555875449271539, 0.0851958483090513, 0.11927418763267182, 0.0851958483090513, 0.05111750898543078, 0.0851958483090513, 0.03407833932362052, 0.06815667864724104, 0.01703916966181026, 0.3379369154484143, 0.16896845772420716, 0.16896845772420716, 0.16896845772420716, 0.3004212963828774, 0.16971852457993725, 0.07217914263744457, 0.09363780666479296, 0.08973623138709325, 0.08973623138709325, 0.062425204443195305, 0.05657284152664575, 0.05072047861009619, 0.015606301110798826, 0.5286246753614854, 0.07551781076592648, 0.07551781076592648, 0.07551781076592648, 0.07551781076592648, 0.07551781076592648, 0.07551781076592648, 0.07551781076592648, 0.22737065736169285, 0.19894932519148126, 0.05684266434042321, 0.11368532868084642, 0.19894932519148126, 0.14210666085105803, 0.05684266434042321, 0.028421332170211606, 0.028421332170211606, 0.028421332170211606, 0.3259205110370174, 0.13036820441480695, 0.06518410220740348, 0.06518410220740348, 0.19555230662221043, 0.06518410220740348, 0.06518410220740348, 0.06518410220740348, 0.06518410220740348, 0.15415010114232272, 0.17470344796129908, 0.18498012137078726, 0.08221338727590545, 0.14387342773283454, 0.030830020228464546, 0.10276673409488181, 0.051383367047440905, 0.051383367047440905, 0.020553346818976363, 0.300511333951371, 0.1728747996386919, 0.12440522964653529, 0.10017044465045699, 0.06624174565594737, 0.06947305032209114, 0.08239826898666623, 0.03554435132758151, 0.032313046661437736, 0.016156523330718868, 0.17021800650748706, 0.17021800650748706, 0.3404360130149741, 0.17021800650748706, 0.29742654058198126, 0.17052454993366925, 0.0872451185707145, 0.063450995324156, 0.095176492986234, 0.10707355460951325, 0.063450995324156, 0.0396568720775975, 0.063450995324156, 0.01982843603879875, 0.6299419359373826, 0.15277480087150513, 0.30554960174301027, 0.15277480087150513, 0.15277480087150513, 0.1817082532274058, 0.3634165064548116, 0.1817082532274058, 0.2692898546956525, 0.12730065858339937, 0.12240447940711477, 0.1615739128173915, 0.09302740434940722, 0.07344268764426887, 0.04406561258656132, 0.04896179176284591, 0.04406561258656132, 0.014688537528853771, 0.6101923671014629, 0.24019626543159633, 0.10294125661354128, 0.10294125661354128, 0.13725500881805505, 0.13725500881805505, 0.03431375220451376, 0.13725500881805505, 0.03431375220451376, 0.03431375220451376, 0.03431375220451376, 0.18657398949861556, 0.09328699474930778, 0.09328699474930778, 0.09328699474930778, 0.09328699474930778, 0.18657398949861556, 0.09328699474930778, 0.09328699474930778, 0.09328699474930778, 0.16547716715338, 0.16547716715338, 0.16547716715338, 0.16547716715338, 0.16547716715338, 0.16547716715338, 0.3443732974325184, 0.1334446527551009, 0.10976898855661524, 0.06672232637755045, 0.08394099124917637, 0.09255032368498932, 0.051655994614877764, 0.051655994614877764, 0.051655994614877764, 0.012913998653719441, 0.26585471508118824, 0.15238014157092497, 0.11347457351026329, 0.0810532667930452, 0.09077965880821062, 0.09402178947993244, 0.061600482762714355, 0.061600482762714355, 0.06484261343443616, 0.01621065335860904, 0.5216091429972275, 0.06520114287465344, 0.06520114287465344, 0.06520114287465344, 0.06520114287465344, 0.06520114287465344, 0.13040228574930687, 0.06520114287465344, 0.49874928250087874, 0.038365329423144516, 0.07673065884628903, 0.07673065884628903, 0.038365329423144516, 0.07673065884628903, 0.11509598826943356, 0.038365329423144516, 0.07673065884628903, 0.3448374409632778, 0.12414147874678001, 0.11379635551788167, 0.08620936024081945, 0.08965773465045222, 0.07586423701192112, 0.062070739373390006, 0.041380492915593335, 0.04482886732522611, 0.01724187204816389, 0.2212311763832847, 0.13695263299917626, 0.16855708676821693, 0.16328967780671014, 0.07374372546109491, 0.09481336130712202, 0.031604453769040676, 0.05794149857657457, 0.04213927169205423, 0.015802226884520338, 0.13465416984960202, 0.403962509548806, 0.13465416984960202, 0.06732708492480101, 0.06732708492480101, 0.06732708492480101, 0.06732708492480101, 0.06732708492480101, 0.38423103405088316, 0.11067524350378699, 0.08144027352165457, 0.0793520613800737, 0.08979312208797813, 0.0772638492384928, 0.06682278853058837, 0.04176424283161773, 0.05011709139794128, 0.016705697132647093, 0.3182084424662704, 0.15303154103339722, 0.10930824359528372, 0.10202102735559815, 0.09230473903601737, 0.07287216239685582, 0.04372329743811349, 0.0388651532783231, 0.05829772991748465, 0.012145360399475969, 0.1097248133992902, 0.3291744401978706, 0.2194496267985804, 0.1097248133992902, 0.1097248133992902, 0.1097248133992902, 0.20303122621378553, 0.20303122621378553, 0.10151561310689276, 0.10151561310689276, 0.10151561310689276, 0.10151561310689276, 0.10151561310689276, 0.10151561310689276, 0.10151561310689276, 0.22240430312524007, 0.09884635694455113, 0.08649056232648224, 0.12355794618068892, 0.12355794618068892, 0.08649056232648224, 0.06177897309034446, 0.06177897309034446, 0.11120215156262003, 0.012355794618068891, 0.17848200981867662, 0.25780734751586626, 0.09915667212148702, 0.059494003272892206, 0.059494003272892206, 0.11898800654578441, 0.09915667212148702, 0.039662668848594804, 0.059494003272892206, 0.019831334424297402, 0.20076870568401356, 0.16988121250185764, 0.06177498636431187, 0.18532495909293561, 0.07721873295538983, 0.10810622613754577, 0.046331239773233904, 0.046331239773233904, 0.046331239773233904, 0.030887493182155935, 0.28578445665302665, 0.12990202575137574, 0.12124189070128404, 0.09526148555100888, 0.08660135050091718, 0.06928108040073373, 0.0519608103005503, 0.09526148555100888, 0.04330067525045859, 0.02598040515027515, 0.0935287985639779, 0.1870575971279558, 0.0935287985639779, 0.0935287985639779, 0.0935287985639779, 0.1870575971279558, 0.0935287985639779, 0.0935287985639779, 0.0935287985639779, 0.17575261166173015, 0.3263977073717846, 0.05021503190335147, 0.05021503190335147, 0.0753225478550272, 0.12553757975837868, 0.05021503190335147, 0.10043006380670294, 0.025107515951675735, 0.22831347888406425, 0.1494298892696263, 0.21163889896556518, 0.09171018955174491, 0.09042752955801421, 0.07375294963951513, 0.04425176978370908, 0.05900235971161211, 0.039121129808786285, 0.012185269940441631, 0.24917813647415024, 0.1054215192775251, 0.23001058751460024, 0.11500529375730012, 0.07667019583820008, 0.05750264687865006, 0.047918872398875045, 0.05750264687865006, 0.047918872398875045, 0.00958377447977501, 0.25851576157546113, 0.13410505131727046, 0.1454151158861969, 0.07755472847263835, 0.11794781621880415, 0.07917045198248497, 0.05331887582493886, 0.061397493374172024, 0.05655032284463213, 0.01454151158861969, 0.11225266048729077, 0.16837899073093615, 0.11225266048729077, 0.22450532097458153, 0.16837899073093615, 0.056126330243645384, 0.11225266048729077, 0.622946176764825, 0.1847875285904324, 0.1847875285904324, 0.1847875285904324, 0.1847875285904324, 0.13803437147208378, 0.13803437147208378, 0.13803437147208378, 0.13803437147208378, 0.13803437147208378, 0.13803437147208378, 0.13803437147208378, 0.27525577913812843, 0.10322091717679815, 0.1261588987716422, 0.10322091717679815, 0.08028293558195412, 0.10322091717679815, 0.034406972392266054, 0.10322091717679815, 0.034406972392266054, 0.034406972392266054, 0.3767167002101646, 0.1782166153733916, 0.2495032615227482, 0.10692996922403494, 0.07128664614935663, 0.0891083076866958, 0.14257329229871327, 0.07128664614935663, 0.01782166153733916, 0.07128664614935663, 0.01782166153733916, 0.38733322335490367, 0.22033361908228738, 0.22033361908228738, 0.22033361908228738, 0.22033361908228738, 0.19102284874376182, 0.10915591356786389, 0.19102284874376182, 0.10915591356786389, 0.16373387035179585, 0.08186693517589792, 0.027288978391965972, 0.027288978391965972, 0.027288978391965972, 0.027288978391965972, 0.22084756088963, 0.11353430947142952, 0.22240282540293727, 0.13219748363111655, 0.10886851593150776, 0.05910005150567564, 0.03421581929275958, 0.0637658450455974, 0.027994761239530565, 0.01710790964637979, 0.26232576941213015, 0.15739546164727808, 0.13354766442799354, 0.15262590220342118, 0.09539118887713824, 0.05484993360435449, 0.026232576941213014, 0.06677383221399677, 0.038156475550855294, 0.016693458053499192, 0.24675415402071915, 0.13512727482087, 0.1336585000945562, 0.14834624735769425, 0.10428300556828012, 0.057282214326238375, 0.051407115420983154, 0.05287589014729696, 0.05287589014729696, 0.017625296715765654, 0.2090057038270271, 0.2090057038270271, 0.2090057038270271, 0.2090057038270271, 0.2090057038270271, 0.26119277755973536, 0.12890033178272653, 0.20013472566265436, 0.10515553382275059, 0.07801862186849237, 0.06105805189708099, 0.04748959591995188, 0.06105805189708099, 0.04070536793138733, 0.016960569971411387, 0.2542583587758494, 0.15623103972973879, 0.1194707950874473, 0.09496396532591965, 0.1133440876470654, 0.05207701324324626, 0.07352048928458296, 0.06739378184420104, 0.042886952082673395, 0.02450682976152765, 0.19155079259744198, 0.19155079259744198, 0.19155079259744198, 0.19155079259744198, 0.13060978436761084, 0.3482927583136289, 0.17414637915681444, 0.08707318957840722, 0.08707318957840722, 0.08707318957840722, 0.04353659478920361, 0.04353659478920361, 0.04353659478920361, 0.2272208321498302, 0.1420130200936439, 0.15621432210300826, 0.1278117180842795, 0.12071106707959729, 0.049704557032775355, 0.05680520803745755, 0.049704557032775355, 0.03550325502341097, 0.028402604018728773, 0.29692649086998707, 0.1272542103728516, 0.16260260214308814, 0.08130130107154407, 0.09190581860261504, 0.056557426832378487, 0.056557426832378487, 0.05302258765535483, 0.060092266009402144, 0.014139356708094622, 0.25743596552290665, 0.13753428295059397, 0.11637516249665644, 0.0881630018914064, 0.09168952196706265, 0.08463648181575013, 0.09168952196706265, 0.05642432121050009, 0.059950841286156346, 0.01763260037828128, 0.17497279543726138, 0.17497279543726138, 0.17497279543726138, 0.17497279543726138, 0.17497279543726138, 0.2950195787901024, 0.2950195787901024, 0.2983998618728551, 0.1271868263720366, 0.13044802704824268, 0.12066442501962447, 0.0733770152146365, 0.06848521420032741, 0.05707101183360617, 0.04728740980498797, 0.0587016121717092, 0.0195672040572364, 0.23874187352459064, 0.23874187352459064, 0.23874187352459064, 0.23874187352459064, 0.23874187352459064, 0.42901832288268676, 0.08580366457653736, 0.08580366457653736, 0.08580366457653736, 0.08580366457653736, 0.08580366457653736, 0.08580366457653736, 0.4328490153179227, 0.09871995086198238, 0.07593842373998644, 0.07593842373998644, 0.08353226611398508, 0.04556305424399187, 0.07593842373998644, 0.05315689661799051, 0.05315689661799051, 0.007593842373998644, 0.17585883968230373, 0.17585883968230373, 0.17585883968230373, 0.17585883968230373, 0.17585883968230373, 0.17585883968230373, 0.20937387318736025, 0.13958258212490685, 0.06979129106245342, 0.06979129106245342, 0.20937387318736025, 0.13958258212490685, 0.06979129106245342, 0.4521425103670493, 0.15071417012234975, 0.15071417012234975, 0.28578409660517173, 0.1525036210583652, 0.10636807183062447, 0.07304795294392283, 0.13199893251270264, 0.06792178080750719, 0.0692033238416111, 0.0551063504664681, 0.03844629102311728, 0.01922314551155864, 0.3728268516576918, 0.11157591910923624, 0.10613319134781007, 0.0898050080635316, 0.07075546089854005, 0.08436228030210545, 0.06259136925640081, 0.0517059137335485, 0.03265636656855695, 0.013606819403565396, 0.2803482801876438, 0.1420943337937373, 0.1344135589940758, 0.07680774799661474, 0.1228923967945836, 0.06528658579712253, 0.06912697319695327, 0.04608464879796884, 0.04608464879796884, 0.019201936999153686, 0.1955433548489215, 0.1173260129093529, 0.0391086709697843, 0.1955433548489215, 0.09777167742446075, 0.0782173419395686, 0.0391086709697843, 0.13688034839424504, 0.05866300645467645, 0.0391086709697843, 0.242962763256338, 0.1457776579538028, 0.0485925526512676, 0.1457776579538028, 0.0971851053025352, 0.0971851053025352, 0.0485925526512676, 0.1457776579538028, 0.0485925526512676, 0.0485925526512676, 0.25620931737800995, 0.15257408787679244, 0.12666528050148806, 0.12378652412645424, 0.09787771675114987, 0.06333264025074403, 0.06621139662577785, 0.051817614750608754, 0.051817614750608754, 0.011515025500135279, 0.2247184992416222, 0.19261585649281904, 0.11057576946809981, 0.13911145191148042, 0.13197753130063528, 0.06777224580302892, 0.03923656335964832, 0.04637048397049347, 0.03210264274880317, 0.017834801527112875, 0.1404001217525359, 0.32760028408925046, 0.04680004058417864, 0.04680004058417864, 0.04680004058417864, 0.1404001217525359, 0.04680004058417864, 0.09360008116835727, 0.04680004058417864, 0.13108533103118575, 0.34956088274982866, 0.04369511034372858, 0.04369511034372858, 0.04369511034372858, 0.13108533103118575, 0.04369511034372858, 0.13108533103118575, 0.04369511034372858, 0.45292833532667726, 0.15097611177555909, 0.15097611177555909, 0.39382814710675723, 0.3129709027072492, 0.179134661417965, 0.12971820309576776, 0.061770572902746554, 0.10295095483791092, 0.05147547741895546, 0.05765253470923012, 0.04941645832219724, 0.041180381935164365, 0.01235411458054931, 0.3322448078333765, 0.09061222031819359, 0.09061222031819359, 0.12836731211744093, 0.08306120195834413, 0.06795916523864519, 0.10571425703789253, 0.03775509179924733, 0.045306110159096795, 0.022653055079548397, 0.5051309900768712, 0.08418849834614521, 0.042094249173072605, 0.08418849834614521, 0.08418849834614521, 0.042094249173072605, 0.08418849834614521, 0.042094249173072605, 0.042094249173072605, 0.23609142593149932, 0.10731428451431788, 0.2074742833943479, 0.0858514276114543, 0.11446857014860573, 0.07154285634287859, 0.06438857070859072, 0.06438857070859072, 0.035771428171439294, 0.014308571268575716, 0.4438955302657292, 0.07398258837762153, 0.07398258837762153, 0.07398258837762153, 0.07398258837762153, 0.07398258837762153, 0.07398258837762153, 0.03699129418881077, 0.07398258837762153, 0.03699129418881077, 0.164310740121394, 0.082155370060697, 0.082155370060697, 0.164310740121394, 0.082155370060697, 0.24646611018209097, 0.10152121745940709, 0.10152121745940709, 0.3045636523782213, 0.10152121745940709, 0.10152121745940709, 0.10152121745940709, 0.10152121745940709, 0.11546050731568522, 0.11546050731568522, 0.3463815219470557, 0.11546050731568522, 0.11546050731568522, 0.11546050731568522, 0.14949044461250416, 0.14949044461250416, 0.2989808892250083, 0.14949044461250416, 0.2561105712112532, 0.2561105712112532, 0.1280552856056266, 0.1280552856056266, 0.1280552856056266, 0.2758848492236335, 0.1469386696951961, 0.12594743116731094, 0.12594743116731094, 0.09895869591717288, 0.06597246394478193, 0.04498122541689677, 0.05697621886140257, 0.04797997377802322, 0.011994993444505804, 0.22859378892223126, 0.22859378892223126, 0.22859378892223126, 0.22859378892223126, 0.22859378892223126, 0.2766713237881383, 0.2766713237881383, 0.2766713237881383, 0.14274974122994652, 0.14274974122994652, 0.14274974122994652, 0.28549948245989304, 0.14274974122994652, 0.14274974122994652, 0.1848054058478065, 0.08213573593235844, 0.10266966991544806, 0.1848054058478065, 0.14373753788162727, 0.02053393398308961, 0.1848054058478065, 0.04106786796617922, 0.02053393398308961, 0.04106786796617922, 0.1365443284936424, 0.2482624154429862, 0.22343617389868756, 0.08689184540504516, 0.08689184540504516, 0.04965248308859724, 0.03723936231644793, 0.07447872463289586, 0.04965248308859724, 0.02482624154429862, 0.24489825110971714, 0.18564867422833395, 0.08689937942602866, 0.1263990973469508, 0.12244912555485857, 0.07504946404975202, 0.05134963329719875, 0.05134963329719875, 0.03949971792092212, 0.01579988716836885, 0.11355410115565454, 0.1703311517334818, 0.1703311517334818, 0.22710820231130907, 0.05677705057782727, 0.11355410115565454, 0.05677705057782727, 0.05677705057782727, 0.17063522301524348, 0.1919646258921489, 0.11731171582297989, 0.08531761150762174, 0.08531761150762174, 0.10664701438452717, 0.08531761150762174, 0.11731171582297989, 0.03199410431535815, 0.021329402876905434, 0.23229564707994607, 0.16260695295596225, 0.09678985294997752, 0.14324898236596675, 0.10840463530397483, 0.08517507059598023, 0.054202317651987415, 0.05033072353398831, 0.054202317651987415, 0.015486376471996405, 0.15304550242465112, 0.15304550242465112, 0.15304550242465112, 0.30609100484930224, 0.15304550242465112, 0.36935113601303565, 0.18467556800651783, 0.18467556800651783, 0.18467556800651783, 0.18467556800651783, 0.3675224538809796, 0.14785386075671592, 0.0844879204324091, 0.08026352441078864, 0.08871231645402955, 0.05491714828106591, 0.05491714828106591, 0.046468356237825005, 0.046468356237825005, 0.02534637612972273, 0.22050394046363103, 0.13230236427817862, 0.08820157618545241, 0.22050394046363103, 0.08820157618545241, 0.08820157618545241, 0.044100788092726204, 0.044100788092726204, 0.044100788092726204, 0.25154028762465247, 0.13655044185338278, 0.11019860219746681, 0.1054073586236639, 0.100616115049861, 0.09342924968915664, 0.06947303182014211, 0.06707741003324066, 0.047912435738029044, 0.016769352508310166, 0.23003208525482463, 0.17051329396511475, 0.11421173463701083, 0.11742896659861676, 0.11903758257941974, 0.09008249492496628, 0.0579101753089069, 0.04504124746248314, 0.035389551577665324, 0.017694775788832662, 0.28543165386529934, 0.28543165386529934, 0.28543165386529934, 0.23390491100199864, 0.12994717277888815, 0.12994717277888815, 0.17153026806813235, 0.09356196440079946, 0.07277041675617736, 0.041583095289244205, 0.062374642933866305, 0.041583095289244205, 0.020791547644622103, 0.14966650711061313, 0.16837482049943978, 0.14966650711061313, 0.18708313388826642, 0.1309581937217865, 0.07483325355530657, 0.05612494016647993, 0.05612494016647993, 0.037416626777653283, 0.018708313388826642, 0.30348538594396474, 0.30348538594396474, 0.23432108017231704, 0.14059264810339023, 0.14059264810339023, 0.04686421603446341, 0.18745686413785365, 0.04686421603446341, 0.14059264810339023, 0.04686421603446341, 0.04686421603446341, 0.42388993918365037, 0.07418073935713881, 0.052986242397956296, 0.08477798783673007, 0.08477798783673007, 0.07418073935713881, 0.08477798783673007, 0.03179174543877378, 0.06358349087754755, 0.02119449695918252, 0.5372765392565523, 0.08954608987609206, 0.08954608987609206, 0.08954608987609206, 0.08954608987609206, 0.08954608987609206, 0.08954608987609206, 0.08954608987609206, 0.30603653903680395, 0.10201217967893464, 0.10201217967893464, 0.10201217967893464, 0.10201217967893464, 0.10201217967893464, 0.10201217967893464, 0.10201217967893464, 0.24793364654186548, 0.1859502349063991, 0.06198341163546637, 0.1859502349063991, 0.06198341163546637, 0.06198341163546637, 0.06198341163546637, 0.12396682327093274, 0.06198341163546637, 0.13007840040101268, 0.390235201203038, 0.06503920020050634, 0.03251960010025317, 0.06503920020050634, 0.13007840040101268, 0.06503920020050634, 0.13007840040101268, 0.03251960010025317, 0.22213791790925622, 0.44427583581851243, 0.22213791790925622, 0.23793676548610249, 0.12414092112318391, 0.10345076760265326, 0.05172538380132663, 0.12414092112318391, 0.07241553732185728, 0.13448599788344923, 0.07241553732185728, 0.062070460561591954, 0.010345076760265326, 0.25733512943830844, 0.22057296808997867, 0.11947702438207178, 0.09190540337082444, 0.06892905252811833, 0.07811959286520077, 0.041357431516871, 0.05054797185395344, 0.05514324202249467, 0.018381080674164888, 0.24033816363999722, 0.09613526545599889, 0.14420289818399834, 0.09613526545599889, 0.19227053091199778, 0.09613526545599889, 0.048067632727999444, 0.048067632727999444, 0.048067632727999444, 0.16652897994071572, 0.09714190496541751, 0.30530312989131214, 0.1248967349555368, 0.11101931996047715, 0.055509659980238574, 0.027754829990119287, 0.055509659980238574, 0.027754829990119287, 0.027754829990119287, 0.2780271952055669, 0.1689279160742685, 0.09502195279177603, 0.09502195279177603, 0.09502195279177603, 0.08446395803713425, 0.049270642188328315, 0.07038663169761188, 0.049270642188328315, 0.014077326339522375, 0.20577979330374002, 0.222928109412385, 0.06859326443458, 0.051444948325935005, 0.0600191063802575, 0.120038212760515, 0.17148316108645, 0.025722474162967503, 0.0600191063802575, 0.0085741580543225, 0.21533611110293177, 0.18220747862555764, 0.1159502136708094, 0.08282158119343529, 0.06625726495474824, 0.1159502136708094, 0.03312863247737412, 0.13251452990949647, 0.049692948716061176, 0.03312863247737412, 0.2192966555898439, 0.11403426090671882, 0.2192966555898439, 0.06140306356515629, 0.13157799335390633, 0.05263119734156253, 0.08771866223593756, 0.05263119734156253, 0.035087464894375024, 0.017543732447187512, 0.24619908898024692, 0.10551389527724868, 0.21102779055449736, 0.035171298425749564, 0.1758564921287478, 0.035171298425749564, 0.07034259685149913, 0.07034259685149913, 0.035171298425749564, 0.1738138673267564, 0.1738138673267564, 0.1738138673267564, 0.1738138673267564, 0.1738138673267564, 0.1738138673267564, 0.1738138673267564, 0.2336169717626271, 0.14244937302599214, 0.12155679831551329, 0.1120601734471138, 0.10066422360503444, 0.08167097386823549, 0.08167097386823549, 0.05318109926303706, 0.055080424236716954, 0.017093924763119054, 0.16432920528166833, 0.21910560704222445, 0.1369410044013903, 0.10955280352111223, 0.16432920528166833, 0.08216460264083417, 0.027388200880278057, 0.027388200880278057, 0.08216460264083417, 0.027388200880278057, 0.1662229282858863, 0.1662229282858863, 0.11796465878353221, 0.08579247911529615, 0.053620299447060094, 0.16086089834118028, 0.058982329391766106, 0.09651653900470818, 0.053620299447060094, 0.037534209612942064, 0.13007749094944848, 0.13007749094944848, 0.3902324728483455, 0.13007749094944848, 0.18022568131995365, 0.06758463049498262, 0.38297957280490147, 0.13516926098996523, 0.04505642032998841, 0.04505642032998841, 0.04505642032998841, 0.022528210164994206, 0.022528210164994206, 0.24129646455744155, 0.16086430970496104, 0.08043215485248052, 0.08043215485248052, 0.08043215485248052, 0.16086430970496104, 0.16086430970496104, 0.4310069027996631, 0.06630875427687125, 0.10775172569991577, 0.09117453713069797, 0.09946313141530687, 0.01657718856921781, 0.01657718856921781, 0.10775172569991577, 0.04144297142304453, 0.01657718856921781, 0.2833650231136104, 0.2833650231136104, 0.2260467697833081, 0.2260467697833081, 0.2260467697833081, 0.2032585527532044, 0.2032585527532044, 0.2032585527532044, 0.2032585527532044, 0.2032585527532044, 0.3910778155990969, 0.08571568561076097, 0.11250183736412377, 0.11250183736412377, 0.0803584552600884, 0.07500122490941584, 0.04821507315605304, 0.03750061245470792, 0.03750061245470792, 0.021428921402690242, 0.2456439481651757, 0.18981577812763578, 0.12282197408258785, 0.08932507206006389, 0.07257662104880191, 0.07257662104880191, 0.09490788906381789, 0.05024535303378594, 0.044662536030031945, 0.016748451011261982, 0.39231881550314784, 0.07846376310062957, 0.07846376310062957, 0.07846376310062957, 0.2353912893018887, 0.07846376310062957, 0.07846376310062957, 0.07846376310062957, 0.25239296290216, 0.12619648145108, 0.12619648145108, 0.12619648145108, 0.12619648145108, 0.12619648145108, 0.12619648145108, 0.10391255158156217, 0.10391255158156217, 0.20782510316312433, 0.20782510316312433, 0.10391255158156217, 0.20782510316312433, 0.10391255158156217, 0.1766269779835592, 0.1766269779835592, 0.1766269779835592, 0.1766269779835592, 0.1766269779835592, 0.1766269779835592, 0.24934331999980316, 0.24934331999980316, 0.24934331999980316, 0.1316881989884706, 0.39506459696541174, 0.1316881989884706, 0.1316881989884706, 0.4644896641188185, 0.07906207048830953, 0.07906207048830953, 0.07906207048830953, 0.07906207048830953, 0.04941379405519346, 0.07906207048830953, 0.039531035244154765, 0.039531035244154765, 0.009882758811038691, 0.1742126043756624, 0.10452756262539745, 0.15679134393809618, 0.0871063021878312, 0.12194882306296369, 0.15679134393809618, 0.03484252087513248, 0.0871063021878312, 0.05226378131269872, 0.01742126043756624, 0.3339346124851652, 0.1669673062425826, 0.1669673062425826, 0.1669673062425826, 0.1669673062425826, 0.1669673062425826, 0.20836311556497406, 0.15434304856664746, 0.1466258961383151, 0.15434304856664746, 0.0848886767116561, 0.09260582913998848, 0.05402006699832661, 0.04630291456999424, 0.038585762141661865, 0.015434304856664745, 0.15264429632572596, 0.15264429632572596, 0.15264429632572596, 0.15264429632572596, 0.15264429632572596, 0.15264429632572596, 0.15264429632572596, 0.24586819246823924, 0.13322373424490497, 0.13863933319794988, 0.12022629675759716, 0.1180600571763792, 0.06173782806471206, 0.064987187436539, 0.04657415099618629, 0.04982351036801324, 0.020579276021570687, 0.2944109580588573, 0.10304383532060006, 0.0883232874176572, 0.10304383532060006, 0.11776438322354293, 0.0883232874176572, 0.0441616437088286, 0.07360273951471433, 0.0883232874176572, 0.014720547902942867, 0.27991792319351316, 0.13995896159675658, 0.13995896159675658, 0.27991792319351316, 0.13550479313685668, 0.40651437941057006, 0.13550479313685668, 0.13550479313685668, 0.13550479313685668, 0.26587550185075676, 0.19472571966534297, 0.09736285983267148, 0.08612868369813247, 0.08987340907631214, 0.07114978218541378, 0.0823839583199528, 0.04493670453815607, 0.05617088067269509, 0.01497890151271869, 0.5361019799254906, 0.025528665710737645, 0.07658599713221294, 0.05105733142147529, 0.05105733142147529, 0.07658599713221294, 0.025528665710737645, 0.10211466284295058, 0.025528665710737645, 0.20382135919017966, 0.20382135919017966, 0.20382135919017966, 0.46339560486314485, 0.07723260081052415, 0.07723260081052415, 0.07723260081052415, 0.07723260081052415, 0.07723260081052415, 0.03861630040526207, 0.03861630040526207, 0.03861630040526207, 0.03861630040526207, 0.1908317406639171, 0.1908317406639171, 0.10102856858677964, 0.1796063441542749, 0.10102856858677964, 0.06735237905785309, 0.033676189528926544, 0.06735237905785309, 0.05612698254821091, 0.022450793019284362, 0.13902742657273756, 0.1853699020969834, 0.13902742657273756, 0.1853699020969834, 0.0926849510484917, 0.04634247552424585, 0.04634247552424585, 0.04634247552424585, 0.0926849510484917, 0.04634247552424585, 0.2940655933462723, 0.14218556161797782, 0.09048172102962225, 0.08725023099285002, 0.10340768117671113, 0.09048172102962225, 0.058166820661900015, 0.06786129077221668, 0.05170384058835557, 0.016157450183861114, 0.3709378826556248, 0.10783077984175139, 0.11214401103542145, 0.09057785506707117, 0.077638161486061, 0.06469846790505084, 0.060385236711380776, 0.05607200551771072, 0.04313231193670056, 0.012939693581010167, 0.3030145298576781, 0.1136304486966293, 0.09469204058052441, 0.07575363246441953, 0.09469204058052441, 0.07575363246441953, 0.05681522434831465, 0.1136304486966293, 0.07575363246441953, 0.018938408116104883, 0.28683666382684764, 0.10756374893506787, 0.07170916595671191, 0.10756374893506787, 0.10756374893506787, 0.07170916595671191, 0.035854582978355955, 0.07170916595671191, 0.07170916595671191, 0.6243930190814632, 0.2287233177602785, 0.2287233177602785, 0.2287233177602785, 0.2287233177602785, 0.2287233177602785, 0.38256242898566367, 0.12670857520544276, 0.07310110108006312, 0.10477824488142382, 0.10234154151208838, 0.05604417749471506, 0.05117077075604419, 0.04629736401737331, 0.043860660648037876, 0.012183516846677187, 0.28122673603837917, 0.07365462134338502, 0.13391749335160913, 0.05356699734064365, 0.11382986934886775, 0.07365462134338502, 0.12052574401644821, 0.040175248005482736, 0.0937422453461264, 0.013391749335160913, 0.22076904694673277, 0.11038452347336639, 0.11038452347336639, 0.22076904694673277, 0.11038452347336639, 0.11038452347336639, 0.11038452347336639, 0.1919332038358929, 0.1919332038358929, 0.1919332038358929, 0.1919332038358929, 0.1919332038358929, 0.15524849990983544, 0.18629819989180252, 0.22178357129976492, 0.08427775709391067, 0.11089178564988246, 0.053228057111943575, 0.053228057111943575, 0.062099399963934175, 0.053228057111943575, 0.013307014277985894, 0.17027827006247287, 0.14595280291069104, 0.23109193794192748, 0.08513913503123643, 0.10946460218301828, 0.048650934303563674, 0.060813667879454594, 0.07297640145534552, 0.048650934303563674, 0.024325467151781837, 0.26312323077737887, 0.13156161538868943, 0.13156161538868943, 0.13156161538868943, 0.13156161538868943, 0.13156161538868943, 0.13156161538868943, 0.22193130999077895, 0.22193130999077895, 0.11096565499538948, 0.22193130999077895, 0.11096565499538948, 0.11096565499538948, 0.3027399641670129, 0.20182664277800857, 0.10091332138900429, 0.10091332138900429, 0.10091332138900429, 0.20182664277800857, 0.15775147608449472, 0.15775147608449472, 0.31550295216898944, 0.15775147608449472, 0.15775147608449472, 0.2717975028666199, 0.14093203852343256, 0.110732315982697, 0.10066574180245182, 0.13086546434318735, 0.08556588053208404, 0.05033287090122591, 0.04529958381110332, 0.04529958381110332, 0.020133148360490363, 0.22178660410555762, 0.204043675777113, 0.1094147246920751, 0.09462895108503791, 0.0591430944281487, 0.10350041524926022, 0.05618593970674126, 0.09167179636363049, 0.044357320821111525, 0.01774292832844461, 0.19842936923605511, 0.14882202692704133, 0.09921468461802756, 0.09921468461802756, 0.19842936923605511, 0.14882202692704133, 0.04960734230901378, 0.04960734230901378, 0.32344161101758123, 0.16172080550879062, 0.16172080550879062, 0.16172080550879062, 0.16172080550879062, 0.16172080550879062, 0.2455615806033674, 0.16955442470232512, 0.14616760750200442, 0.09354726880128282, 0.06431374730088193, 0.11108738170152335, 0.05262033870072159, 0.05262033870072159, 0.035080225800481056, 0.023386817200320705, 0.2646441879682511, 0.2117153503746009, 0.052928837593650226, 0.052928837593650226, 0.052928837593650226, 0.10585767518730045, 0.15878651278095068, 0.052928837593650226, 0.052928837593650226, 0.3080414967346082, 0.1540207483673041, 0.10268049891153605, 0.051340249455768025, 0.06417531181971003, 0.08984543654759405, 0.1540207483673041, 0.03850518709182602, 0.03850518709182602, 0.012835062363942006, 0.2706336077024185, 0.21049280599076994, 0.09021120256747282, 0.07016426866358998, 0.06014080171164855, 0.06014080171164855, 0.14032853732717995, 0.0400938678077657, 0.030070400855824277, 0.010023466951941425, 0.3153465759644556, 0.3153465759644556, 0.2713104715121554, 0.20348285363411656, 0.06782761787803886, 0.06782761787803886, 0.06782761787803886, 0.06782761787803886, 0.1356552357560777, 0.06782761787803886, 0.4939768731130896, 0.2125456229474914, 0.07084854098249713, 0.2833941639299885, 0.14169708196499425, 0.07084854098249713, 0.07084854098249713, 0.07084854098249713, 0.07084854098249713, 0.16081420954925932, 0.08040710477462966, 0.32162841909851864, 0.16081420954925932, 0.08040710477462966, 0.08040710477462966, 0.08040710477462966, 0.2137254206966704, 0.1068627103483352, 0.1068627103483352, 0.2137254206966704, 0.1068627103483352, 0.1068627103483352, 0.22163023218787078, 0.22163023218787078, 0.22163023218787078, 0.22163023218787078, 0.22163023218787078, 0.12862232352590428, 0.30011875489377665, 0.17149643136787238, 0.10718526960492022, 0.08574821568393619, 0.06431116176295214, 0.06431116176295214, 0.042874107841968094, 0.042874107841968094, 0.021437053920984047, 0.1721351706749652, 0.22690545225336323, 0.1721351706749652, 0.09389191127725374, 0.0860675853374826, 0.07041893345794031, 0.03912162969885573, 0.07041893345794031, 0.03912162969885573, 0.023472977819313436, 0.1313573318213065, 0.09851799886597988, 0.16419666477663314, 0.06567866591065324, 0.1313573318213065, 0.19703599773195976, 0.03283933295532662, 0.1313573318213065, 0.03283933295532662, 0.15051468579414243, 0.15051468579414243, 0.15051468579414243, 0.15051468579414243, 0.15051468579414243, 0.15051468579414243, 0.18252499027530728, 0.09126249513765364, 0.09126249513765364, 0.09126249513765364, 0.18252499027530728, 0.18252499027530728, 0.09126249513765364, 0.09126249513765364, 0.09195096441601408, 0.09195096441601408, 0.18390192883202816, 0.09195096441601408, 0.18390192883202816, 0.18390192883202816, 0.09195096441601408, 0.2561898225581916, 0.2561898225581916, 0.15565399769975238, 0.15565399769975238, 0.31130799539950477, 0.15565399769975238, 0.17608449315711486, 0.19369294247282634, 0.10565069589426891, 0.13206336986783612, 0.0616295726049902, 0.1408675945256919, 0.052825347947134456, 0.0616295726049902, 0.044021123289278714, 0.017608449315711486, 0.24933691160445406, 0.1618502759537684, 0.10498396278082275, 0.09186096743321992, 0.12248128991095988, 0.11373262634589132, 0.0481176496078771, 0.0481176496078771, 0.0481176496078771, 0.017497327130137127, 0.24137387487456635, 0.18103040615592475, 0.06034346871864159, 0.08045795829152211, 0.08045795829152211, 0.10057244786440264, 0.1408014270101637, 0.040228979145761054, 0.040228979145761054, 0.020114489572880527, 0.2170522769373711, 0.14003372705636846, 0.13303204070355004, 0.11202698164509477, 0.09102192258663949, 0.07701854988100265, 0.10502529529227633, 0.056013490822547383, 0.056013490822547383, 0.021005059058455268, 0.22043848228707089, 0.11021924114353544, 0.11021924114353544, 0.27554810285883863, 0.11021924114353544, 0.05510962057176772, 0.05510962057176772, 0.05510962057176772, 0.12817614723372672, 0.2391740479309746, 0.15460421882830955, 0.11496211143643531, 0.10703368995806045, 0.1017480756391439, 0.05682035392835308, 0.03303508949322854, 0.048891932449978234, 0.014535439377020556, 0.3797555140536267, 0.30745646150109035, 0.30745646150109035, 0.12100329860277523, 0.12100329860277523, 0.16133773147036695, 0.08066886573518348, 0.16133773147036695, 0.12100329860277523, 0.04033443286759174, 0.08066886573518348, 0.04033443286759174, 0.3803373317458218, 0.17096223983729247, 0.13676979186983398, 0.15386601585356324, 0.08548111991864624, 0.11967356788610474, 0.06838489593491699, 0.11967356788610474, 0.06838489593491699, 0.06838489593491699, 0.017096223983729248, 0.29753724355358774, 0.173290922069672, 0.09645438115198725, 0.11280258134723932, 0.1062633012691385, 0.05885352070290747, 0.03923568046860498, 0.05067942060528143, 0.05231424062480664, 0.01307856015620166, 0.1500444339526533, 0.1500444339526533, 0.12003554716212264, 0.1500444339526533, 0.06001777358106132, 0.09002666037159197, 0.12003554716212264, 0.06001777358106132, 0.04501333018579599, 0.04501333018579599, 0.259688175234639, 0.1298440876173195, 0.11541696677095067, 0.10098984592458184, 0.07213560423184417, 0.08656272507821301, 0.08656272507821301, 0.07213560423184417, 0.043281362539106506, 0.043281362539106506, 0.17504470784292053, 0.1604576488560105, 0.14587058986910045, 0.1312835308821904, 0.1312835308821904, 0.1021094129083703, 0.04376117696073013, 0.04376117696073013, 0.04376117696073013, 0.02917411797382009, 0.17375028477091575, 0.17375028477091575, 0.17375028477091575, 0.17375028477091575, 0.08687514238545788, 0.08687514238545788, 0.17375028477091575, 0.19223990794272958, 0.06407996931424319, 0.12815993862848638, 0.12815993862848638, 0.12815993862848638, 0.19223990794272958, 0.06407996931424319, 0.06407996931424319, 0.06407996931424319, 0.2643398177187183, 0.13216990885935914, 0.06608495442967957, 0.06608495442967957, 0.13216990885935914, 0.06608495442967957, 0.06608495442967957, 0.13216990885935914, 0.06608495442967957, 0.30570190703593697, 0.12992331049027322, 0.1314518200254529, 0.10546715792739826, 0.09018206257560141, 0.07336845768862488, 0.05655485280164834, 0.03668422884431244, 0.059611871872007706, 0.012228076281437478, 0.22356609020839746, 0.15649626314587822, 0.11178304510419873, 0.06706982706251924, 0.04471321804167949, 0.08942643608335898, 0.17885287216671797, 0.04471321804167949, 0.06706982706251924, 0.022356609020839746, 0.20475056130422128, 0.20475056130422128, 0.20475056130422128, 0.20475056130422128, 0.20475056130422128, 0.20475056130422128, 0.27320539582147607, 0.13660269791073804, 0.13660269791073804, 0.27320539582147607, 0.13660269791073804, 0.13815266521657352, 0.27630533043314703, 0.13815266521657352, 0.13815266521657352, 0.13815266521657352, 0.2217296785257966, 0.13978610167930655, 0.18316799530391892, 0.13978610167930655, 0.08194357684649005, 0.08194357684649005, 0.0530223144300818, 0.03856168322187767, 0.04338189362461238, 0.014460631208204126, 0.2486204753768455, 0.2486204753768455, 0.2486204753768455, 0.2486204753768455, 0.15381560893193474, 0.15381560893193474, 0.3076312178638695, 0.15381560893193474, 0.15381560893193474, 0.30471431971098545, 0.13176835446961532, 0.12353283231526437, 0.11529731016091341, 0.06588417723480766, 0.06588417723480766, 0.10706178800656245, 0.049413132926105746, 0.024706566463052873, 0.016471044308701915, 0.37047530304590814, 0.1255079598073893, 0.08165578107950629, 0.087704357455766, 0.10736223067861012, 0.0635100519507271, 0.06048576376259725, 0.04536432282194794, 0.04536432282194794, 0.01360929684658438, 0.3021235138035074, 0.14843459591215796, 0.11559508354221151, 0.09589137612024365, 0.07881482968787148, 0.07093334671908434, 0.06305186375029719, 0.04860247830752075, 0.06042470276070148, 0.018390126927170014, 0.12280467445875497, 0.12280467445875497, 0.3684140233762649, 0.12280467445875497, 0.12280467445875497, 0.12280467445875497, 0.22613143027238858, 0.13091819647348812, 0.13091819647348812, 0.1348854145484423, 0.09521323379890045, 0.09918045187385464, 0.06744270727422115, 0.05157383497440441, 0.043639398824496044, 0.015868872299816743, 0.27841438280507597, 0.20174955275730141, 0.10894475848894276, 0.10490976743379674, 0.0847348121580666, 0.060524865827190424, 0.056489874772044396, 0.04438490160660631, 0.04438490160660631, 0.012104973165438085, 0.3563930083477778, 0.14764853202979367, 0.08909825208694445, 0.094189580777627, 0.1018265738136508, 0.061095944288190485, 0.053458951252166674, 0.048367622561484136, 0.03563930083477778, 0.01272832172670635, 0.2161636657029893, 0.08646546628119572, 0.30262913198418506, 0.1296981994217936, 0.04323273314059786, 0.04323273314059786, 0.04323273314059786, 0.04323273314059786, 0.04323273314059786, 0.36441517476985946, 0.29948908081429715, 0.12756016405053397, 0.11646797587222668, 0.14974454040714857, 0.08319141133730477, 0.07209922315899747, 0.04436875271322921, 0.04991484680238286, 0.03882265862407556, 0.022184376356614605, 0.26150297626539876, 0.26150297626539876, 0.26150297626539876, 0.36063784331381493, 0.21310418013998156, 0.07376683158691669, 0.08606130351806947, 0.09015946082845373, 0.03688341579345834, 0.028687101172689824, 0.045079730414226866, 0.049177887724611125, 0.016392629241537043, 0.3721879979480882, 0.17325006299475612, 0.11550004199650409, 0.34650012598951224, 0.05775002099825204, 0.05775002099825204, 0.05775002099825204, 0.05775002099825204, 0.05775002099825204, 0.18329430010171785, 0.3665886002034357, 0.18329430010171785, 0.18329430010171785, 0.11078904951150587, 0.3323671485345176, 0.11078904951150587, 0.05539452475575293, 0.11078904951150587, 0.11078904951150587, 0.05539452475575293, 0.05539452475575293, 0.05539452475575293, 0.36218623286284973, 0.36218623286284973, 0.36916837960053256, 0.23592937534659034, 0.23592937534659034, 0.23592937534659034, 0.23592937534659034, 0.21757376613629428, 0.21757376613629428, 0.21757376613629428, 0.21757376613629428, 0.25576675622286626, 0.13143569417008405, 0.12077874599413128, 0.11722642993548037, 0.13143569417008405, 0.07815095329032025, 0.046180108762461966, 0.04973242482111288, 0.056837056938414725, 0.0177615802932546, 0.2586988058130766, 0.2586988058130766, 0.2586988058130766, 0.2586988058130766, 0.08071461152585083, 0.4035730576292541, 0.08071461152585083, 0.08071461152585083, 0.08071461152585083, 0.08071461152585083, 0.08071461152585083, 0.16142922305170165, 0.23196522852014, 0.1449782678250875, 0.11598261426007, 0.11598261426007, 0.10631739640506417, 0.06765652498504084, 0.06765652498504084, 0.06765652498504084, 0.07732174284004667, 0.019330435710011667, 0.11070057414640828, 0.13837571768301035, 0.19372600475621451, 0.05535028707320414, 0.13837571768301035, 0.16605086121961243, 0.05535028707320414, 0.08302543060980622, 0.05535028707320414, 0.2031803328667205, 0.14066330736926802, 0.15629256374363115, 0.07814628187181558, 0.1094047946205418, 0.14066330736926802, 0.03907314093590779, 0.07814628187181558, 0.03907314093590779, 0.015629256374363115, 0.2624186457627143, 0.1574511874576286, 0.14995351186440817, 0.10871629610169593, 0.05998140474576327, 0.08997210711864491, 0.044986053559322454, 0.05998140474576327, 0.044986053559322454, 0.022493026779661227, 0.22210375077530647, 0.11105187538765324, 0.2961383343670753, 0.11105187538765324, 0.07403458359176883, 0.037017291795884415, 0.037017291795884415, 0.11105187538765324, 0.037017291795884415, 0.2529708174193799, 0.17856763582544463, 0.07936339370019761, 0.1116047723909029, 0.141366045028477, 0.08680371185959114, 0.06200265132827938, 0.039681696850098806, 0.034721484743836455, 0.012400530265655877, 0.31001946732036806, 0.11923825666168003, 0.08346677966317602, 0.09539060532934403, 0.10135251816242803, 0.08346677966317602, 0.12520016949476404, 0.03577147699850401, 0.029809564165420008, 0.017885738499252006, 0.20099202611072792, 0.20099202611072792, 0.08039681044429116, 0.08039681044429116, 0.08039681044429116, 0.12059521566643674, 0.08039681044429116, 0.08039681044429116, 0.04019840522214558, 0.04019840522214558, 0.19364889694867887, 0.19364889694867887, 0.09682444847433944, 0.09682444847433944, 0.09682444847433944, 0.09682444847433944, 0.09682444847433944, 0.09682444847433944, 0.09682444847433944, 0.30440140565871476, 0.30440140565871476, 0.3145777680453238, 0.10485925601510793, 0.10485925601510793, 0.10485925601510793, 0.20971851203021585, 0.10485925601510793, 0.2757987002560495, 0.15824515588461857, 0.13563870504395878, 0.10851096403516702, 0.06781935252197939, 0.11755354437143094, 0.05425548201758351, 0.027127741008791756, 0.040691611513187634, 0.013563870504395878, 0.1891577301613403, 0.3783154603226806, 0.1891577301613403, 0.1891577301613403, 0.5465225378145668, 0.21238157597632473, 0.13273848498520296, 0.31857236396448707, 0.07964309099112177, 0.07964309099112177, 0.05309539399408118, 0.02654769699704059, 0.07964309099112177, 0.02654769699704059, 0.02654769699704059], \"Term\": [\"aaba\", \"aaba\", \"abstraction\", \"abstraction\", \"abstraction\", \"abstraction\", \"abstraction\", \"abstraction\", \"abstraction\", \"abstraction\", \"abstraction\", \"abstraction\", \"activated\", \"activated\", \"activated\", \"activated\", \"activated\", \"activated\", \"activated\", \"activated\", \"activated\", \"adaptive\", \"adaptive\", \"adaptive\", \"adaptive\", \"adaptive\", \"adaptive\", \"adaptive\", \"adaptive\", \"adaptive\", \"adaptive\", \"adaptively\", \"adaptively\", \"adaptively\", \"adaptively\", \"adaptively\", \"adaptively\", \"adaptively\", \"adaptively\", \"aes\", \"aes\", \"agent\", \"agent\", \"agent\", \"agent\", \"agent\", \"agent\", \"agent\", \"agent\", \"agent\", \"agent\", \"ai\", \"ai\", \"ai\", \"ai\", \"ai\", \"ai\", \"ai\", \"ai\", \"ai\", \"ai\", \"akq\", \"akq\", \"akq\", \"akq\", \"akq\", \"akq\", \"akq\", \"akq\", \"akq\", \"algorithm\", \"algorithm\", \"algorithm\", \"algorithm\", \"algorithm\", \"algorithm\", \"algorithm\", \"algorithm\", \"algorithm\", \"algorithm\", \"algorithms\", \"algorithms\", \"algorithms\", \"algorithms\", \"algorithms\", \"algorithms\", \"algorithms\", \"algorithms\", \"algorithms\", \"algorithms\", \"alonso\", \"alonso\", \"alonso\", \"alonso\", \"also\", \"also\", \"also\", \"also\", \"also\", \"also\", \"also\", \"also\", \"also\", \"also\", \"amh\", \"analyst\", \"analyst\", \"analyst\", \"analyst\", \"analyst\", \"analyst\", \"analyst\", \"analyst\", \"analyst\", \"analyst\", \"anr\", \"anr\", \"anr\", \"approach\", \"approach\", \"approach\", \"approach\", \"approach\", \"approach\", \"approach\", \"approach\", \"approach\", \"approach\", \"arm\", \"arm\", \"arm\", \"arm\", \"arm\", \"arm\", \"arm\", \"arm\", \"arm\", \"arm\", \"arms\", \"arms\", \"arms\", \"arms\", \"arms\", \"arms\", \"arms\", \"arms\", \"atom\", \"atom\", \"atom\", \"atom\", \"atom\", \"atoms\", \"atoms\", \"atoms\", \"atoms\", \"atoms\", \"atoms\", \"atoms\", \"atoms\", \"atoms\", \"aurlien\", \"aurlien\", \"aurlien\", \"aurlien\", \"aurlien\", \"av\", \"av\", \"av\", \"av\", \"av\", \"av\", \"av\", \"av\", \"av\", \"av\", \"axon\", \"axon\", \"axon\", \"axon\", \"axon\", \"azimuth\", \"azimuth\", \"azimuth\", \"azimuth\", \"azimuth\", \"azimuth\", \"azimuth\", \"azimuth\", \"babes\", \"babes\", \"backward\", \"backward\", \"backward\", \"backward\", \"backward\", \"backward\", \"backward\", \"backward\", \"backward\", \"based\", \"based\", \"based\", \"based\", \"based\", \"based\", \"based\", \"based\", \"based\", \"based\", \"battery\", \"battery\", \"battery\", \"battery\", \"battery\", \"battery\", \"battery\", \"battery\", \"bcm\", \"bcm\", \"bcm\", \"behaviour\", \"behaviour\", \"behaviour\", \"behaviour\", \"behaviour\", \"behaviour\", \"behaviour\", \"behaviour\", \"behaviour\", \"behaviour\", \"bentley\", \"bhalla\", \"bhalla\", \"bhalla\", \"bhalla\", \"bhalla\", \"bhalla\", \"bias\", \"bias\", \"bias\", \"bias\", \"bias\", \"bias\", \"bias\", \"bias\", \"bias\", \"bias\", \"binocular\", \"binocular\", \"binocular\", \"binocular\", \"binocular\", \"binocular\", \"binocular\", \"binocular\", \"binocular\", \"binocularly\", \"binocularly\", \"binocularly\", \"birl\", \"birl\", \"birl\", \"birl\", \"birl\", \"birl\", \"birl\", \"birl\", \"birl\", \"birl\", \"bk\", \"bk\", \"bk\", \"bk\", \"bk\", \"bk\", \"bk\", \"bk\", \"bk\", \"bk\", \"bower\", \"bower\", \"bower\", \"bower\", \"bower\", \"bower\", \"bower\", \"bpap\", \"bpap\", \"bpap\", \"bpap\", \"bros\", \"bros\", \"bros\", \"brown\", \"brown\", \"brown\", \"brown\", \"brown\", \"brown\", \"brown\", \"brown\", \"brown\", \"brownedu\", \"bsp\", \"bsp\", \"bsp\", \"bsp\", \"bsp\", \"bsp\", \"bsp\", \"bsp\", \"bubeck\", \"bubeck\", \"bubeck\", \"bubeck\", \"bubeck\", \"calcium\", \"calcium\", \"calcium\", \"calcium\", \"calcium\", \"calcium\", \"calcium\", \"calcium\", \"calcium\", \"caltech\", \"caltech\", \"caltech\", \"caltech\", \"case\", \"case\", \"case\", \"case\", \"case\", \"case\", \"case\", \"case\", \"case\", \"case\", \"cccp\", \"cccp\", \"cccp\", \"cccp\", \"cccp\", \"cccp\", \"cccp\", \"cccp\", \"cccp\", \"cccp\", \"cell\", \"cell\", \"cell\", \"cell\", \"cell\", \"cell\", \"cell\", \"cell\", \"cell\", \"cell\", \"cerebellum\", \"cerebellum\", \"cerebellum\", \"cerebellum\", \"cerebellum\", \"cerebellum\", \"cerebellum\", \"cerebellum\", \"cerebellum\", \"cerebellum\", \"channel\", \"channel\", \"channel\", \"channel\", \"channel\", \"channel\", \"channel\", \"channel\", \"channel\", \"channel\", \"cj\", \"cj\", \"cj\", \"cj\", \"cj\", \"classes\", \"classes\", \"classes\", \"classes\", \"classes\", \"classes\", \"classes\", \"classes\", \"classes\", \"classes\", \"climbing\", \"climbing\", \"climbing\", \"climbing\", \"climbing\", \"climbing\", \"climbing\", \"clst\", \"clst\", \"clst\", \"clst\", \"clst\", \"clustering\", \"clustering\", \"clustering\", \"clustering\", \"clustering\", \"clustering\", \"clustering\", \"clustering\", \"clustering\", \"clustering\", \"cm\", \"cm\", \"cm\", \"cm\", \"cm\", \"cm\", \"cm\", \"cm\", \"cm\", \"cm\", \"coin\", \"coin\", \"coin\", \"coin\", \"coin\", \"coin\", \"coin\", \"coins\", \"coins\", \"coins\", \"coins\", \"collecting\", \"collecting\", \"collecting\", \"collecting\", \"collecting\", \"collecting\", \"collecting\", \"command\", \"command\", \"command\", \"command\", \"command\", \"command\", \"commands\", \"commands\", \"commands\", \"commands\", \"commands\", \"commands\", \"commands\", \"commands\", \"commands\", \"commands\", \"commit\", \"commit\", \"commit\", \"commit\", \"commit\", \"commit\", \"compartment\", \"compartment\", \"compartment\", \"composes\", \"composes\", \"composite\", \"composite\", \"composite\", \"composite\", \"composite\", \"composite\", \"composite\", \"composite\", \"composite\", \"compositions\", \"compositions\", \"compositions\", \"computers\", \"computers\", \"concavity\", \"concavity\", \"concavity\", \"concavity\", \"concavity\", \"concavity\", \"concavity\", \"concavity\", \"concavity\", \"concert\", \"concert\", \"concert\", \"concert\", \"concert\", \"concert\", \"conformal\", \"conformal\", \"conformal\", \"conformal\", \"conformal\", \"conformal\", \"conformal\", \"conformal\", \"conformal\", \"contingencies\", \"contingencies\", \"contingencies\", \"contingencies\", \"contingencies\", \"cooper\", \"cooper\", \"cooper\", \"cooper\", \"cooper\", \"coreference\", \"coreference\", \"coreference\", \"coreference\", \"coreference\", \"coreference\", \"coreference\", \"coreference\", \"coreference\", \"coreference\", \"could\", \"could\", \"could\", \"could\", \"could\", \"could\", \"could\", \"could\", \"could\", \"could\", \"covariance\", \"covariance\", \"covariance\", \"covariance\", \"covariance\", \"covariance\", \"covariance\", \"covariance\", \"covariance\", \"covariance\", \"csps\", \"csps\", \"csps\", \"csps\", \"csps\", \"csps\", \"csps\", \"csps\", \"cssps\", \"cssps\", \"cssps\", \"cssps\", \"cssps\", \"cssps\", \"cssps\", \"cssps\", \"curv\", \"curv\", \"curv\", \"curv\", \"curv\", \"curv\", \"curv\", \"curv\", \"curvature\", \"curvature\", \"curvature\", \"curvature\", \"curvature\", \"curvature\", \"curvature\", \"curvature\", \"curvature\", \"curvature\", \"curve\", \"curve\", \"curve\", \"curve\", \"curve\", \"curve\", \"curve\", \"curve\", \"curve\", \"curve\", \"curvedness\", \"curvss\", \"curvss\", \"curvss\", \"curvss\", \"curvss\", \"curvss\", \"curvss\", \"cutting\", \"cutting\", \"cutting\", \"cutting\", \"cutting\", \"cutting\", \"cutting\", \"dangna\", \"data\", \"data\", \"data\", \"data\", \"data\", \"data\", \"data\", \"data\", \"data\", \"data\", \"decorrelated\", \"decorrelated\", \"decorrelated\", \"decorrelated\", \"decorrelated\", \"decorrelated\", \"decorrelated\", \"decorrelated\", \"deep\", \"deep\", \"deep\", \"deep\", \"deep\", \"deep\", \"deep\", \"deep\", \"deep\", \"deep\", \"dendrite\", \"dendrite\", \"dendrite\", \"dendrite\", \"dendrite\", \"dendrite\", \"dendrite\", \"densities\", \"densities\", \"densities\", \"densities\", \"densities\", \"densities\", \"densities\", \"densities\", \"densities\", \"densities\", \"density\", \"density\", \"density\", \"density\", \"density\", \"density\", \"density\", \"density\", \"density\", \"density\", \"depressed\", \"depressed\", \"depressed\", \"deprivation\", \"descriptor\", \"descriptor\", \"descriptor\", \"descriptor\", \"descriptor\", \"descriptor\", \"descriptor\", \"descriptor\", \"descriptor\", \"deselaers\", \"detection\", \"detection\", \"detection\", \"detection\", \"detection\", \"detection\", \"detection\", \"detection\", \"detection\", \"detection\", \"deweese\", \"different\", \"different\", \"different\", \"different\", \"different\", \"different\", \"different\", \"different\", \"different\", \"different\", \"diffusion\", \"diffusion\", \"diffusion\", \"diffusion\", \"diffusion\", \"diffusion\", \"diffusion\", \"diffusion\", \"diffusion\", \"diffusion\", \"dimensional\", \"dimensional\", \"dimensional\", \"dimensional\", \"dimensional\", \"dimensional\", \"dimensional\", \"dimensional\", \"dimensional\", \"dimensional\", \"discarding\", \"discharge\", \"discharge\", \"discharge\", \"discharge\", \"discharge\", \"discharge\", \"discharge\", \"discharge\", \"discrepancy\", \"discrepancy\", \"discrepancy\", \"discrepancy\", \"discrepancy\", \"discrepancy\", \"discrepancy\", \"discrepancy\", \"discrepancy\", \"distribution\", \"distribution\", \"distribution\", \"distribution\", \"distribution\", \"distribution\", \"distribution\", \"distribution\", \"distribution\", \"distribution\", \"distributional\", \"distributional\", \"distributional\", \"distributional\", \"distributions\", \"distributions\", \"distributions\", \"distributions\", \"distributions\", \"distributions\", \"distributions\", \"distributions\", \"distributions\", \"distributions\", \"dja\", \"documents\", \"documents\", \"documents\", \"documents\", \"documents\", \"documents\", \"documents\", \"documents\", \"documents\", \"dpm\", \"dpm\", \"dpm\", \"dpm\", \"dpm\", \"dpm\", \"dpm\", \"dpm\", \"dpm\", \"dpm\", \"dpmbirl\", \"dpmbirl\", \"dpmbirl\", \"drsvm\", \"drsvm\", \"drsvm\", \"drsvm\", \"drsvm\", \"drsvm\", \"drsvm\", \"drsvm\", \"dsp\", \"dsp\", \"dsp\", \"dsp\", \"dsp\", \"dsp\", \"dsp\", \"dsp\", \"dsp\", \"dsp\", \"dwork\", \"dwork\", \"dwork\", \"dwork\", \"dwork\", \"ea\", \"ea\", \"ea\", \"ea\", \"ea\", \"ea\", \"ea\", \"ebnn\", \"ebnn\", \"ebnn\", \"ebnn\", \"ebnn\", \"ebnn\", \"ebnn\", \"ebnn\", \"edges\", \"edges\", \"edges\", \"edges\", \"edges\", \"edges\", \"edges\", \"edges\", \"edges\", \"edges\", \"eeg\", \"eeg\", \"eeg\", \"eeg\", \"eeg\", \"eeg\", \"eeg\", \"eeg\", \"eeg\", \"eeg\", \"eid\", \"eid\", \"eid\", \"eid\", \"eid\", \"elemental\", \"elemental\", \"elemental\", \"elemental\", \"elemental\", \"elemental\", \"elemental\", \"emit\", \"emit\", \"emmlirl\", \"emmlirl\", \"emmlirl\", \"emmlirl\", \"emmlirl\", \"emmlirl\", \"emmlirl\", \"enemies\", \"enemies\", \"enemies\", \"enemy\", \"enemy\", \"enemy\", \"enemy\", \"enemy\", \"enemy\", \"equilibrium\", \"equilibrium\", \"equilibrium\", \"equilibrium\", \"equilibrium\", \"equilibrium\", \"equilibrium\", \"equilibrium\", \"equilibrium\", \"equilibrium\", \"error\", \"error\", \"error\", \"error\", \"error\", \"error\", \"error\", \"error\", \"error\", \"error\", \"errored\", \"errored\", \"esf\", \"estimation\", \"estimation\", \"estimation\", \"estimation\", \"estimation\", \"estimation\", \"estimation\", \"estimation\", \"estimation\", \"estimation\", \"estimator\", \"estimator\", \"estimator\", \"estimator\", \"estimator\", \"estimator\", \"estimator\", \"estimator\", \"estimator\", \"estimator\", \"etc\", \"etc\", \"etc\", \"etc\", \"etc\", \"etc\", \"etc\", \"etc\", \"etc\", \"etc\", \"ethz\", \"evd\", \"evd\", \"evd\", \"evd\", \"evd\", \"evd\", \"evd\", \"evd\", \"evd\", \"example\", \"example\", \"example\", \"example\", \"example\", \"example\", \"example\", \"example\", \"example\", \"example\", \"excitabilities\", \"excitabilities\", \"excitabilities\", \"excitabilities\", \"excitabilities\", \"excitabilities\", \"excitabilities\", \"excitabilities\", \"explanations\", \"explanations\", \"explanations\", \"explanations\", \"explanations\", \"explanations\", \"explanations\", \"explanations\", \"explanations\", \"exploration\", \"exploration\", \"exploration\", \"exploration\", \"exploration\", \"exploration\", \"exploration\", \"exploration\", \"exploration\", \"exploration\", \"eyes\", \"eyes\", \"eyes\", \"eyes\", \"eyes\", \"eyes\", \"eyes\", \"eyes\", \"favourable\", \"feature\", \"feature\", \"feature\", \"feature\", \"feature\", \"feature\", \"feature\", \"feature\", \"feature\", \"feature\", \"features\", \"features\", \"features\", \"features\", \"features\", \"features\", \"features\", \"features\", \"features\", \"features\", \"fibers\", \"fibers\", \"fibers\", \"fibers\", \"fibers\", \"fibers\", \"fibers\", \"fibers\", \"fibers\", \"fibers\", \"figure\", \"figure\", \"figure\", \"figure\", \"figure\", \"figure\", \"figure\", \"figure\", \"figure\", \"figure\", \"fiksvm\", \"fiksvm\", \"fiksvm\", \"fiksvm\", \"fiksvm\", \"fiksvm\", \"fiksvm\", \"fiksvm\", \"fil\", \"fil\", \"fil\", \"fil\", \"fil\", \"fil\", \"fil\", \"first\", \"first\", \"first\", \"first\", \"first\", \"first\", \"first\", \"first\", \"first\", \"first\", \"fjl\", \"fjl\", \"fjl\", \"fjl\", \"fjl\", \"fjl\", \"fjl\", \"form\", \"form\", \"form\", \"form\", \"form\", \"form\", \"form\", \"form\", \"form\", \"form\", \"format\", \"format\", \"format\", \"ftk\", \"ftk\", \"ftk\", \"ftk\", \"ftk\", \"ftk\", \"ftk\", \"ftk\", \"function\", \"function\", \"function\", \"function\", \"function\", \"function\", \"function\", \"function\", \"function\", \"function\", \"functions\", \"functions\", \"functions\", \"functions\", \"functions\", \"functions\", \"functions\", \"functions\", \"functions\", \"functions\", \"gating\", \"gating\", \"gating\", \"gating\", \"gating\", \"gating\", \"gating\", \"gating\", \"gating\", \"gating\", \"gaussian\", \"gaussian\", \"gaussian\", \"gaussian\", \"gaussian\", \"gaussian\", \"gaussian\", \"gaussian\", \"gaussian\", \"gaussian\", \"generalization\", \"generalization\", \"generalization\", \"generalization\", \"generalization\", \"generalization\", \"generalization\", \"generalization\", \"generalization\", \"generalization\", \"genesis\", \"genesis\", \"genesis\", \"genesis\", \"genesis\", \"genesis\", \"genesis\", \"genesis\", \"genesis\", \"gilles\", \"gilles\", \"given\", \"given\", \"given\", \"given\", \"given\", \"given\", \"given\", \"given\", \"given\", \"given\", \"gkm\", \"gkm\", \"gm\", \"gm\", \"gm\", \"gm\", \"gm\", \"gm\", \"gm\", \"gm\", \"gpfa\", \"gpfa\", \"gpfa\", \"gpfa\", \"gpfa\", \"gpfa\", \"gpfa\", \"gpfa\", \"gpfa\", \"gpfa\", \"gpm\", \"gpm\", \"gpm\", \"gpm\", \"gpm\", \"gpm\", \"graph\", \"graph\", \"graph\", \"graph\", \"graph\", \"graph\", \"graph\", \"graph\", \"graph\", \"graph\", \"gridworld\", \"gridworld\", \"growing\", \"growing\", \"growing\", \"growing\", \"growing\", \"growing\", \"growing\", \"growing\", \"growing\", \"gss\", \"hastings\", \"hastings\", \"hastings\", \"header\", \"header\", \"header\", \"header\", \"heavy\", \"heavy\", \"heavy\", \"heavy\", \"heavy\", \"heavy\", \"heavy\", \"heavy\", \"heavy\", \"hertz\", \"hertz\", \"highway\", \"highway\", \"highway\", \"hints\", \"hints\", \"hints\", \"hints\", \"hmm\", \"hmm\", \"hmm\", \"hmm\", \"hmm\", \"hmm\", \"hmm\", \"hmm\", \"hmm\", \"hog\", \"hog\", \"hog\", \"hog\", \"hog\", \"hog\", \"hog\", \"hog\", \"hog\", \"holding\", \"holding\", \"holding\", \"holding\", \"holding\", \"holding\", \"holding\", \"holdout\", \"holdout\", \"holdout\", \"holdout\", \"holdout\", \"holdout\", \"holdout\", \"holdout\", \"holdout\", \"holdout\", \"homeostasis\", \"homeostasis\", \"homeostasis\", \"homeostasis\", \"homeostatic\", \"homeostatic\", \"homeostatic\", \"homeostatic\", \"homeostatic\", \"homeostatic\", \"homeostatic\", \"homeostatic\", \"homeostatic\", \"homeostatic\", \"however\", \"however\", \"however\", \"however\", \"however\", \"however\", \"however\", \"however\", \"however\", \"however\", \"hrin\", \"hrin\", \"hrin\", \"hrin\", \"hrin\", \"ht\", \"ht\", \"ht\", \"ht\", \"ht\", \"ht\", \"ht\", \"ht\", \"ht\", \"ht\", \"human\", \"human\", \"human\", \"human\", \"human\", \"human\", \"human\", \"human\", \"human\", \"human\", \"hypothesized\", \"hzk\", \"hzk\", \"hzk\", \"hzk\", \"hzk\", \"hzk\", \"ie\", \"ie\", \"ie\", \"ie\", \"ie\", \"ie\", \"ie\", \"ie\", \"ie\", \"ie\", \"ij\", \"ij\", \"ij\", \"ij\", \"ij\", \"ij\", \"ij\", \"ij\", \"ij\", \"ij\", \"ije\", \"ije\", \"ije\", \"ije\", \"ije\", \"ije\", \"ije\", \"ije\", \"illnesses\", \"influence\", \"influence\", \"influence\", \"influence\", \"influence\", \"influence\", \"influence\", \"influence\", \"influence\", \"influence\", \"influenced\", \"influenced\", \"influenced\", \"influenced\", \"influenced\", \"influenced\", \"influenced\", \"influenced\", \"influenced\", \"influenced\", \"information\", \"information\", \"information\", \"information\", \"information\", \"information\", \"information\", \"information\", \"information\", \"information\", \"input\", \"input\", \"input\", \"input\", \"input\", \"input\", \"input\", \"input\", \"input\", \"input\", \"intra\", \"intra\", \"intra\", \"intra\", \"intra\", \"intra\", \"intra\", \"intra\", \"irl\", \"irl\", \"irl\", \"irl\", \"irl\", \"irl\", \"irl\", \"irl\", \"irl\", \"irl\", \"isomap\", \"isomap\", \"isomap\", \"isomap\", \"isomap\", \"isomap\", \"isomap\", \"isomap\", \"isomap\", \"isomap\", \"ixixj\", \"ixixj\", \"kasteleyn\", \"kasteleyn\", \"kasteleyn\", \"kasteleyn\", \"kasteleyn\", \"kasteleyn\", \"kde\", \"kde\", \"kde\", \"kde\", \"kde\", \"kde\", \"kde\", \"kde\", \"kernel\", \"kernel\", \"kernel\", \"kernel\", \"kernel\", \"kernel\", \"kernel\", \"kernel\", \"kernel\", \"kernel\", \"killed\", \"killing\", \"killing\", \"killing\", \"killing\", \"killing\", \"killing\", \"knn\", \"knn\", \"knn\", \"knn\", \"know\", \"know\", \"know\", \"know\", \"know\", \"know\", \"know\", \"know\", \"know\", \"know\", \"koch\", \"koch\", \"koch\", \"koch\", \"koch\", \"koch\", \"korea\", \"korea\", \"korea\", \"korea\", \"kq\", \"kq\", \"kq\", \"kq\", \"kq\", \"kq\", \"kq\", \"kq\", \"kq\", \"krr\", \"krr\", \"krr\", \"label\", \"label\", \"label\", \"label\", \"label\", \"label\", \"label\", \"label\", \"label\", \"label\", \"lagrangian\", \"lagrangian\", \"lagrangian\", \"lagrangian\", \"lagrangian\", \"lagrangian\", \"lagrangian\", \"lagrangian\", \"lagrangian\", \"lai\", \"lai\", \"lai\", \"lai\", \"lai\", \"lai\", \"lai\", \"lane\", \"lane\", \"lane\", \"lane\", \"lane\", \"lane\", \"lang\", \"lang\", \"lang\", \"lang\", \"lang\", \"lang\", \"large\", \"large\", \"large\", \"large\", \"large\", \"large\", \"large\", \"large\", \"large\", \"large\", \"latent\", \"latent\", \"latent\", \"latent\", \"latent\", \"latent\", \"latent\", \"latent\", \"latent\", \"latent\", \"lattice\", \"lattice\", \"lattice\", \"lattice\", \"lattice\", \"lattice\", \"lattice\", \"lattice\", \"lattice\", \"lattice\", \"lattimore\", \"lattimore\", \"lattimore\", \"layer\", \"layer\", \"layer\", \"layer\", \"layer\", \"layer\", \"layer\", \"layer\", \"layer\", \"layer\", \"lc\", \"lc\", \"lc\", \"lc\", \"lc\", \"lc\", \"lc\", \"lc\", \"lc\", \"lc\", \"leaming\", \"leaming\", \"leaming\", \"leaming\", \"leaming\", \"learning\", \"learning\", \"learning\", \"learning\", \"learning\", \"learning\", \"learning\", \"learning\", \"learning\", \"learning\", \"leopold\", \"leopold\", \"leopold\", \"liam\", \"liam\", \"lifelong\", \"lifelong\", \"lifelong\", \"lifelong\", \"lifelong\", \"lifelong\", \"lifelong\", \"lifelong\", \"light\", \"light\", \"light\", \"light\", \"light\", \"light\", \"light\", \"light\", \"light\", \"light\", \"lille\", \"lille\", \"lille\", \"lille\", \"linear\", \"linear\", \"linear\", \"linear\", \"linear\", \"linear\", \"linear\", \"linear\", \"linear\", \"linear\", \"linsvm\", \"linsvm\", \"linsvm\", \"linsvm\", \"linsvm\", \"linsvm\", \"linsvm\", \"linsvm\", \"llca\", \"llca\", \"llca\", \"llca\", \"llca\", \"llca\", \"llca\", \"llca\", \"llca\", \"llca\", \"lms\", \"lms\", \"lms\", \"lms\", \"lms\", \"lms\", \"lms\", \"lms\", \"lms\", \"location\", \"location\", \"location\", \"location\", \"location\", \"location\", \"location\", \"location\", \"location\", \"location\", \"log\", \"log\", \"log\", \"log\", \"log\", \"log\", \"log\", \"log\", \"log\", \"log\", \"logothetis\", \"logothetis\", \"logothetis\", \"logothetis\", \"loss\", \"loss\", \"loss\", \"loss\", \"loss\", \"loss\", \"loss\", \"loss\", \"loss\", \"loss\", \"lss\", \"ltd\", \"ltd\", \"ltd\", \"ltd\", \"ltp\", \"ltp\", \"ltp\", \"machine\", \"machine\", \"machine\", \"machine\", \"machine\", \"machine\", \"machine\", \"machine\", \"machine\", \"machine\", \"maji\", \"marginals\", \"marginals\", \"marginals\", \"marginals\", \"marginals\", \"marginals\", \"marginals\", \"marginals\", \"marginals\", \"marginals\", \"mario\", \"mario\", \"mario\", \"mario\", \"mario\", \"mario\", \"mario\", \"mario\", \"mario\", \"matchings\", \"matchings\", \"matchings\", \"matchings\", \"matchings\", \"matchings\", \"matrix\", \"matrix\", \"matrix\", \"matrix\", \"matrix\", \"matrix\", \"matrix\", \"matrix\", \"matrix\", \"matrix\", \"may\", \"may\", \"may\", \"may\", \"may\", \"may\", \"may\", \"may\", \"may\", \"may\", \"mcsps\", \"mcsps\", \"mcsps\", \"mcsps\", \"mcsps\", \"mcsps\", \"mcsps\", \"mcsps\", \"mcssps\", \"mcssps\", \"mcssps\", \"mcssps\", \"mcssps\", \"mcssps\", \"mcssps\", \"mcssps\", \"mcssps\", \"mean\", \"mean\", \"mean\", \"mean\", \"mean\", \"mean\", \"mean\", \"mean\", \"mean\", \"mean\", \"memory\", \"memory\", \"memory\", \"memory\", \"memory\", \"memory\", \"memory\", \"memory\", \"memory\", \"memory\", \"metaplasticity\", \"metaplasticity\", \"metaplasticity\", \"metaplasticity\", \"metaplasticity\", \"metaplasticity\", \"metaplasticity\", \"metaplasticity\", \"method\", \"method\", \"method\", \"method\", \"method\", \"method\", \"method\", \"method\", \"method\", \"method\", \"methods\", \"methods\", \"methods\", \"methods\", \"methods\", \"methods\", \"methods\", \"methods\", \"methods\", \"methods\", \"mf\", \"mf\", \"mf\", \"mf\", \"mf\", \"mf\", \"mh\", \"mh\", \"mh\", \"mh\", \"mh\", \"mh\", \"mh\", \"mh\", \"mh\", \"mimic\", \"mimic\", \"mimic\", \"mimic\", \"mimic\", \"mimic\", \"mimic\", \"mimic\", \"mimic\", \"mimic\", \"minimax\", \"minimax\", \"minimax\", \"minimax\", \"minimax\", \"minimax\", \"minimax\", \"minimax\", \"minimax\", \"minimax\", \"mistakes\", \"mistakes\", \"mistakes\", \"mistakes\", \"mistakes\", \"mistakes\", \"mistakes\", \"mistakes\", \"mistakes\", \"mistakes\", \"mixture\", \"mixture\", \"mixture\", \"mixture\", \"mixture\", \"mixture\", \"mixture\", \"mixture\", \"mixture\", \"mixture\", \"mlirl\", \"mlirl\", \"mlirl\", \"mlirl\", \"mlirl\", \"mlirl\", \"mlirl\", \"mlirl\", \"mlirl\", \"mobile\", \"mobile\", \"mobile\", \"mobile\", \"mobile\", \"mobile\", \"mobile\", \"mobile\", \"mobile\", \"model\", \"model\", \"model\", \"model\", \"model\", \"model\", \"model\", \"model\", \"model\", \"model\", \"modeling\", \"modeling\", \"modeling\", \"modeling\", \"modeling\", \"modeling\", \"modeling\", \"modeling\", \"modeling\", \"modeling\", \"models\", \"models\", \"models\", \"models\", \"models\", \"models\", \"models\", \"models\", \"models\", \"models\", \"modules\", \"modules\", \"modules\", \"modules\", \"modules\", \"modules\", \"modules\", \"monroy\", \"moritz\", \"moritz\", \"moritz\", \"moritz\", \"mossy\", \"mossy\", \"mossy\", \"mossy\", \"mossy\", \"mossy\", \"mossy\", \"motor\", \"motor\", \"motor\", \"motor\", \"motor\", \"motor\", \"motor\", \"motor\", \"motor\", \"motor\", \"nack\", \"nash\", \"nash\", \"nash\", \"nash\", \"nash\", \"nash\", \"nash\", \"nash\", \"nash\", \"nash\", \"ncr\", \"nessler\", \"nessler\", \"nessler\", \"nessler\", \"netrate\", \"netrate\", \"netrate\", \"netrate\", \"netrate\", \"netrate\", \"netrate\", \"netrate\", \"netrate\", \"netrate\", \"network\", \"network\", \"network\", \"network\", \"network\", \"network\", \"network\", \"network\", \"network\", \"network\", \"networks\", \"networks\", \"networks\", \"networks\", \"networks\", \"networks\", \"networks\", \"networks\", \"networks\", \"networks\", \"neural\", \"neural\", \"neural\", \"neural\", \"neural\", \"neural\", \"neural\", \"neural\", \"neural\", \"neural\", \"neuronl\", \"neuronl\", \"neuronl\", \"neuronl\", \"neuronl\", \"neurons\", \"neurons\", \"neurons\", \"neurons\", \"neurons\", \"neurons\", \"neurons\", \"neurons\", \"neurons\", \"neurons\", \"new\", \"new\", \"new\", \"new\", \"new\", \"new\", \"new\", \"new\", \"new\", \"new\", \"newsgroup\", \"newsgroup\", \"newsgroup\", \"newsgroup\", \"nmda\", \"nmda\", \"nmda\", \"nmda\", \"nmda\", \"nmda\", \"nmda\", \"nmda\", \"nmda\", \"node\", \"node\", \"node\", \"node\", \"node\", \"node\", \"node\", \"node\", \"node\", \"node\", \"noise\", \"noise\", \"noise\", \"noise\", \"noise\", \"noise\", \"noise\", \"noise\", \"noise\", \"noise\", \"non\", \"non\", \"non\", \"non\", \"non\", \"non\", \"non\", \"non\", \"non\", \"non\", \"noradrenergic\", \"noradrenergic\", \"noradrenergic\", \"noradrenergic\", \"noradrenergic\", \"nouns\", \"nouns\", \"number\", \"number\", \"number\", \"number\", \"number\", \"number\", \"number\", \"number\", \"number\", \"number\", \"nwii\", \"nwii\", \"nwii\", \"nwii\", \"nwii\", \"nystrom\", \"nystrom\", \"nystrom\", \"nystrom\", \"nystrom\", \"nystrom\", \"nystrom\", \"object\", \"object\", \"object\", \"object\", \"object\", \"object\", \"object\", \"object\", \"object\", \"object\", \"olfactory\", \"olfactory\", \"olfactory\", \"olfactory\", \"olfactory\", \"olfactory\", \"oli\", \"oli\", \"oli\", \"oli\", \"oli\", \"oli\", \"oli\", \"ommer\", \"ommer\", \"ommer\", \"one\", \"one\", \"one\", \"one\", \"one\", \"one\", \"one\", \"one\", \"one\", \"one\", \"optimal\", \"optimal\", \"optimal\", \"optimal\", \"optimal\", \"optimal\", \"optimal\", \"optimal\", \"optimal\", \"optimal\", \"optimization\", \"optimization\", \"optimization\", \"optimization\", \"optimization\", \"optimization\", \"optimization\", \"optimization\", \"optimization\", \"optimization\", \"option\", \"option\", \"option\", \"option\", \"option\", \"option\", \"option\", \"option\", \"option\", \"option\", \"options\", \"options\", \"options\", \"options\", \"options\", \"options\", \"options\", \"options\", \"options\", \"options\", \"order\", \"order\", \"order\", \"order\", \"order\", \"order\", \"order\", \"order\", \"order\", \"order\", \"output\", \"output\", \"output\", \"output\", \"output\", \"output\", \"output\", \"output\", \"output\", \"output\", \"packet\", \"packet\", \"packet\", \"packet\", \"packet\", \"packet\", \"packet\", \"packet\", \"packet\", \"packets\", \"packets\", \"packets\", \"packets\", \"packets\", \"packets\", \"packets\", \"packets\", \"packets\", \"paintings\", \"paintings\", \"paintings\", \"paragraphs\", \"parameters\", \"parameters\", \"parameters\", \"parameters\", \"parameters\", \"parameters\", \"parameters\", \"parameters\", \"parameters\", \"parameters\", \"partition\", \"partition\", \"partition\", \"partition\", \"partition\", \"partition\", \"partition\", \"partition\", \"partition\", \"partition\", \"pascal\", \"pascal\", \"pascal\", \"pascal\", \"pascal\", \"pascal\", \"pascal\", \"pascal\", \"pascal\", \"patterns\", \"patterns\", \"patterns\", \"patterns\", \"patterns\", \"patterns\", \"patterns\", \"patterns\", \"patterns\", \"patterns\", \"pc\", \"pc\", \"pc\", \"pc\", \"pc\", \"pc\", \"pc\", \"pc\", \"pc\", \"pc\", \"pdc\", \"pdc\", \"pdc\", \"pdc\", \"pdc\", \"pdc\", \"percent\", \"percent\", \"percent\", \"percent\", \"percent\", \"percent\", \"percent\", \"percept\", \"percept\", \"percept\", \"percept\", \"percept\", \"percept\", \"percepts\", \"percepts\", \"percepts\", \"percepts\", \"perchet\", \"perchet\", \"perchet\", \"perchet\", \"perchet\", \"performance\", \"performance\", \"performance\", \"performance\", \"performance\", \"performance\", \"performance\", \"performance\", \"performance\", \"performance\", \"phrase\", \"phrase\", \"phrase\", \"phrase\", \"phrase\", \"pil\", \"pil\", \"pil\", \"pitch\", \"pitch\", \"pitch\", \"pitch\", \"pitch\", \"pitch\", \"planar\", \"planar\", \"planar\", \"planar\", \"planar\", \"planar\", \"planar\", \"planar\", \"planar\", \"planar\", \"plasticity\", \"plasticity\", \"plasticity\", \"plasticity\", \"plasticity\", \"plasticity\", \"plasticity\", \"plasticity\", \"plasticity\", \"plasticity\", \"point\", \"point\", \"point\", \"point\", \"point\", \"point\", \"point\", \"point\", \"point\", \"point\", \"pomdp\", \"pomdp\", \"pomdp\", \"pomdp\", \"pomdp\", \"pomdp\", \"pomdp\", \"pomdp\", \"power\", \"power\", \"power\", \"power\", \"power\", \"power\", \"power\", \"power\", \"power\", \"power\", \"prediction\", \"prediction\", \"prediction\", \"prediction\", \"prediction\", \"prediction\", \"prediction\", \"prediction\", \"prediction\", \"prediction\", \"predictor\", \"predictor\", \"predictor\", \"predictor\", \"predictor\", \"prekopa\", \"prekopa\", \"prekopa\", \"prekopa\", \"prekopa\", \"prior\", \"prior\", \"prior\", \"prior\", \"prior\", \"prior\", \"prior\", \"prior\", \"prior\", \"prior\", \"privacy\", \"privacy\", \"privacy\", \"privacy\", \"privacy\", \"privacy\", \"privacy\", \"privacy\", \"privacy\", \"probability\", \"probability\", \"probability\", \"probability\", \"probability\", \"probability\", \"probability\", \"probability\", \"probability\", \"probability\", \"problem\", \"problem\", \"problem\", \"problem\", \"problem\", \"problem\", \"problem\", \"problem\", \"problem\", \"problem\", \"proce\", \"proce\", \"proce\", \"processing\", \"processing\", \"processing\", \"processing\", \"processing\", \"processing\", \"processing\", \"processing\", \"processing\", \"processing\", \"propagation\", \"propagation\", \"propagation\", \"propagation\", \"propagation\", \"propagation\", \"propagation\", \"propagation\", \"propagation\", \"propagation\", \"punctuation\", \"punctuation\", \"pv\", \"pv\", \"pv\", \"pv\", \"pv\", \"pv\", \"pv\", \"pv\", \"pv\", \"qi\", \"qi\", \"qi\", \"qi\", \"qi\", \"qi\", \"qi\", \"qi\", \"qi\", \"qi\", \"qtk\", \"qtk\", \"qtk\", \"qtk\", \"qtk\", \"qtk\", \"qtk\", \"qtk\", \"quasi\", \"quasi\", \"quasi\", \"quasi\", \"quasi\", \"quasi\", \"quasi\", \"quasi\", \"rademacher\", \"rademacher\", \"rademacher\", \"rademacher\", \"rademacher\", \"rademacher\", \"rademacher\", \"rademacher\", \"rademacher\", \"radio\", \"radio\", \"radio\", \"radio\", \"radio\", \"radio\", \"radio\", \"radio\", \"radio\", \"radios\", \"radios\", \"radios\", \"rank\", \"rank\", \"rank\", \"rank\", \"rank\", \"rank\", \"rank\", \"rank\", \"rank\", \"rank\", \"rate\", \"rate\", \"rate\", \"rate\", \"rate\", \"rate\", \"rate\", \"rate\", \"rate\", \"rate\", \"rayleigh\", \"rayleigh\", \"rayleigh\", \"rayleigh\", \"rayleigh\", \"rayleigh\", \"rayleigh\", \"rayleigh\", \"rayleigh\", \"recurrent\", \"recurrent\", \"recurrent\", \"recurrent\", \"recurrent\", \"recurrent\", \"recurrent\", \"recurrent\", \"recurrent\", \"recurrent\", \"regression\", \"regression\", \"regression\", \"regression\", \"regression\", \"regression\", \"regression\", \"regression\", \"regression\", \"regression\", \"regret\", \"regret\", \"regret\", \"regret\", \"regret\", \"regret\", \"regret\", \"regret\", \"regret\", \"regret\", \"reinforcement\", \"reinforcement\", \"reinforcement\", \"reinforcement\", \"reinforcement\", \"reinforcement\", \"reinforcement\", \"reinforcement\", \"reinforcement\", \"reinforcement\", \"relevant\", \"relevant\", \"relevant\", \"relevant\", \"relevant\", \"relevant\", \"relevant\", \"relevant\", \"relevant\", \"relevant\", \"renyi\", \"renyi\", \"renyi\", \"renyi\", \"renyi\", \"renyi\", \"renyi\", \"renyi\", \"renyi\", \"repetitive\", \"repetitive\", \"repetitive\", \"repetitive\", \"repetitive\", \"repetitive\", \"repetitive\", \"results\", \"results\", \"results\", \"results\", \"results\", \"results\", \"results\", \"results\", \"results\", \"results\", \"retina\", \"retina\", \"retina\", \"retina\", \"retina\", \"retina\", \"retina\", \"retina\", \"retina\", \"retina\", \"reward\", \"reward\", \"reward\", \"reward\", \"reward\", \"reward\", \"reward\", \"reward\", \"reward\", \"reward\", \"rivalrous\", \"rivalrous\", \"rivalrous\", \"rivalrous\", \"rivalry\", \"rivalry\", \"rivalry\", \"rivalry\", \"rivalry\", \"rivalry\", \"rivalry\", \"rivalry\", \"rivalry\", \"robbins\", \"robbins\", \"robbins\", \"robbins\", \"robbins\", \"robbins\", \"robbins\", \"roc\", \"roc\", \"roc\", \"roc\", \"roc\", \"roc\", \"roc\", \"roc\", \"roc\", \"roc\", \"rohwer\", \"rohwer\", \"routing\", \"routing\", \"routing\", \"rubrospinal\", \"rubrospinal\", \"rubrospinal\", \"rubrospinal\", \"rubrospinal\", \"samples\", \"samples\", \"samples\", \"samples\", \"samples\", \"samples\", \"samples\", \"samples\", \"samples\", \"samples\", \"sampling\", \"sampling\", \"sampling\", \"sampling\", \"sampling\", \"sampling\", \"sampling\", \"sampling\", \"sampling\", \"sampling\", \"sanger\", \"sanger\", \"sanger\", \"sanger\", \"sanger\", \"sanger\", \"sanger\", \"sanger\", \"schema\", \"schema\", \"schema\", \"schema\", \"schema\", \"schema\", \"schema\", \"schmidhuber\", \"schmidhuber\", \"schmidhuber\", \"schmidhuber\", \"schmidhuber\", \"schmidhuber\", \"schmidhuber\", \"script\", \"script\", \"script\", \"script\", \"script\", \"script\", \"segev\", \"segev\", \"segev\", \"segregation\", \"segregation\", \"segregation\", \"segregation\", \"self\", \"self\", \"self\", \"self\", \"self\", \"self\", \"self\", \"self\", \"self\", \"self\", \"semantic\", \"semantic\", \"semantic\", \"semantic\", \"semantic\", \"semantic\", \"semantic\", \"semantic\", \"semantic\", \"semantic\", \"sensorimotor\", \"sensorimotor\", \"sensorimotor\", \"sensorimotor\", \"sensorimotor\", \"sensorimotor\", \"sequence\", \"sequence\", \"sequence\", \"sequence\", \"sequence\", \"sequence\", \"sequence\", \"sequence\", \"sequence\", \"sequence\", \"servos\", \"servos\", \"servos\", \"servos\", \"servos\", \"servos\", \"servos\", \"set\", \"set\", \"set\", \"set\", \"set\", \"set\", \"set\", \"set\", \"set\", \"set\", \"shallow\", \"shallow\", \"shallow\", \"shallow\", \"shallow\", \"shallow\", \"shallow\", \"shallow\", \"shallow\", \"shallow\", \"shepard\", \"shepard\", \"shepard\", \"shepard\", \"shouval\", \"shouval\", \"shouval\", \"shouval\", \"shouval\", \"show\", \"show\", \"show\", \"show\", \"show\", \"show\", \"show\", \"show\", \"show\", \"show\", \"shrinkage\", \"shrinkage\", \"shrinkage\", \"shrinkage\", \"shrinkage\", \"shrinkage\", \"shrinkage\", \"shrinkage\", \"shrinkage\", \"siegmund\", \"siegmund\", \"siegmund\", \"similarities\", \"similarities\", \"similarities\", \"similarities\", \"similarities\", \"similarities\", \"similarities\", \"similarities\", \"similarities\", \"similarities\", \"simulation\", \"simulation\", \"simulation\", \"simulation\", \"simulation\", \"simulation\", \"simulation\", \"simulation\", \"simulation\", \"simulation\", \"simulator\", \"simulator\", \"simulator\", \"simulator\", \"simulator\", \"simulator\", \"simulator\", \"simulator\", \"simulator\", \"simulator\", \"since\", \"since\", \"since\", \"since\", \"since\", \"since\", \"since\", \"since\", \"since\", \"since\", \"size\", \"size\", \"size\", \"size\", \"size\", \"size\", \"size\", \"size\", \"size\", \"size\", \"sne\", \"sne\", \"sne\", \"sne\", \"sne\", \"sne\", \"sne\", \"sne\", \"sne\", \"sne\", \"snn\", \"snn\", \"snn\", \"snn\", \"snn\", \"snn\", \"snn\", \"snn\", \"snn\", \"sofa\", \"soukup\", \"soukup\", \"soukup\", \"soukup\", \"soukup\", \"space\", \"space\", \"space\", \"space\", \"space\", \"space\", \"space\", \"space\", \"space\", \"space\", \"sparse\", \"sparse\", \"sparse\", \"sparse\", \"sparse\", \"sparse\", \"sparse\", \"sparse\", \"sparse\", \"sparse\", \"sparsevalidate\", \"sparsevalidate\", \"sparsevalidate\", \"sparsevalidate\", \"sparsevalidate\", \"sparsevalidate\", \"sparsevalidate\", \"spec\", \"spec\", \"spec\", \"spec\", \"spec\", \"spike\", \"spike\", \"spike\", \"spike\", \"spike\", \"spike\", \"spike\", \"spike\", \"spike\", \"spike\", \"spiking\", \"spiking\", \"spiking\", \"spiking\", \"spiking\", \"spiking\", \"spiking\", \"spiking\", \"spiking\", \"spiking\", \"spinal\", \"spinal\", \"spinal\", \"spinal\", \"spinal\", \"spinal\", \"spinal\", \"spm\", \"spm\", \"spm\", \"spm\", \"spm\", \"spm\", \"sprt\", \"sprt\", \"sprt\", \"sprt\", \"sprt\", \"sprt\", \"spurious\", \"spurious\", \"spurious\", \"spurious\", \"spurious\", \"standard\", \"standard\", \"standard\", \"standard\", \"standard\", \"standard\", \"standard\", \"standard\", \"standard\", \"standard\", \"state\", \"state\", \"state\", \"state\", \"state\", \"state\", \"state\", \"state\", \"state\", \"state\", \"stdev\", \"stdev\", \"stdev\", \"stdev\", \"stdev\", \"stdev\", \"stdev\", \"stdev\", \"steve\", \"steve\", \"steve\", \"steve\", \"steve\", \"steve\", \"stochastic\", \"stochastic\", \"stochastic\", \"stochastic\", \"stochastic\", \"stochastic\", \"stochastic\", \"stochastic\", \"stochastic\", \"stochastic\", \"stopping\", \"stopping\", \"stopping\", \"stopping\", \"stopping\", \"stopping\", \"stopping\", \"stopping\", \"stopping\", \"strategies\", \"strategies\", \"strategies\", \"strategies\", \"strategies\", \"strategies\", \"strategies\", \"strategies\", \"strategies\", \"strategies\", \"strategy\", \"strategy\", \"strategy\", \"strategy\", \"strategy\", \"strategy\", \"strategy\", \"strategy\", \"strategy\", \"strategy\", \"students\", \"students\", \"suboptimal\", \"suboptimal\", \"suboptimal\", \"suboptimal\", \"suboptimal\", \"suboptimal\", \"suboptimal\", \"suboptimal\", \"supergaussian\", \"suppressed\", \"suppressed\", \"suppressed\", \"suppressed\", \"suppressed\", \"suppressed\", \"suppressed\", \"suppressed\", \"suppression\", \"suppression\", \"suppression\", \"suppression\", \"suppression\", \"suppression\", \"suppression\", \"symbolic\", \"symbolic\", \"symbolic\", \"symbolic\", \"symbolic\", \"symbolic\", \"symptom\", \"symptom\", \"symptom\", \"symptom\", \"symptom\", \"synapses\", \"synapses\", \"synapses\", \"synapses\", \"synapses\", \"synapses\", \"synapses\", \"synapses\", \"synapses\", \"synapses\", \"synaptic\", \"synaptic\", \"synaptic\", \"synaptic\", \"synaptic\", \"synaptic\", \"synaptic\", \"synaptic\", \"synaptic\", \"synaptic\", \"syntactic\", \"syntactic\", \"syntactic\", \"syntactic\", \"syntactic\", \"syntactic\", \"syntactic\", \"syntactic\", \"syntactic\", \"syntax\", \"syntax\", \"syntax\", \"syntax\", \"syntax\", \"syntax\", \"tagging\", \"tagging\", \"tagging\", \"tagging\", \"tagging\", \"tagging\", \"tagging\", \"tagging\", \"tasa\", \"tasa\", \"tasa\", \"tasa\", \"tasa\", \"tasa\", \"tasa\", \"tbl\", \"tbl\", \"tdnn\", \"tdnn\", \"tdnn\", \"tdnn\", \"temporal\", \"temporal\", \"temporal\", \"temporal\", \"temporal\", \"temporal\", \"temporal\", \"temporal\", \"temporal\", \"temporal\", \"test\", \"test\", \"test\", \"test\", \"test\", \"test\", \"test\", \"test\", \"test\", \"test\", \"thompson\", \"thompson\", \"thompson\", \"thompson\", \"thompson\", \"thompson\", \"thompson\", \"thompson\", \"thompson\", \"thompson\", \"three\", \"three\", \"three\", \"three\", \"three\", \"three\", \"three\", \"three\", \"three\", \"three\", \"thresholdout\", \"thresholdout\", \"thresholdout\", \"thresholdout\", \"thresholdout\", \"thresholdout\", \"thresholdout\", \"thresholdout\", \"time\", \"time\", \"time\", \"time\", \"time\", \"time\", \"time\", \"time\", \"time\", \"time\", \"toggle\", \"toolkits\", \"toolkits\", \"topics\", \"topics\", \"topics\", \"topics\", \"topics\", \"topics\", \"topics\", \"topics\", \"topics\", \"tourebky\", \"trace\", \"trace\", \"trace\", \"trace\", \"trace\", \"trace\", \"trace\", \"trace\", \"trace\", \"trace\", \"training\", \"training\", \"training\", \"training\", \"training\", \"training\", \"training\", \"training\", \"training\", \"training\", \"trajectories\", \"trajectories\", \"trajectories\", \"trajectories\", \"trajectories\", \"trajectories\", \"trajectories\", \"trajectories\", \"trajectories\", \"trajectories\", \"trajectory\", \"trajectory\", \"trajectory\", \"trajectory\", \"trajectory\", \"trajectory\", \"trajectory\", \"trajectory\", \"trajectory\", \"trajectory\", \"transmission\", \"transmission\", \"transmission\", \"transmission\", \"transmission\", \"transmission\", \"transmission\", \"transmission\", \"transmission\", \"transmission\", \"trigger\", \"trigger\", \"trigger\", \"trigger\", \"trigger\", \"trigger\", \"trigger\", \"trw\", \"trw\", \"trw\", \"trw\", \"trw\", \"trw\", \"trw\", \"trw\", \"trw\", \"tsne\", \"tsne\", \"tsne\", \"tsne\", \"tsne\", \"tsne\", \"tsne\", \"tsne\", \"tsne\", \"two\", \"two\", \"two\", \"two\", \"two\", \"two\", \"two\", \"two\", \"two\", \"two\", \"ucb\", \"ucb\", \"ucb\", \"ucb\", \"ucb\", \"ucb\", \"ucb\", \"ucb\", \"ucb\", \"ucb\", \"uhley\", \"uhley\", \"uhley\", \"uhley\", \"uhley\", \"uhley\", \"ullman\", \"ullman\", \"ullman\", \"ullman\", \"ullman\", \"umist\", \"umist\", \"umist\", \"umist\", \"umist\", \"units\", \"units\", \"units\", \"units\", \"units\", \"units\", \"units\", \"units\", \"units\", \"units\", \"unix\", \"unix\", \"unix\", \"unix\", \"unsegmented\", \"unsegmented\", \"unsegmented\", \"unsegmented\", \"unsegmented\", \"upper\", \"upper\", \"upper\", \"upper\", \"upper\", \"upper\", \"upper\", \"upper\", \"upper\", \"upper\", \"used\", \"used\", \"used\", \"used\", \"used\", \"used\", \"used\", \"used\", \"used\", \"used\", \"using\", \"using\", \"using\", \"using\", \"using\", \"using\", \"using\", \"using\", \"using\", \"using\", \"utterances\", \"utterances\", \"utterances\", \"utterances\", \"utterances\", \"utterances\", \"values\", \"values\", \"values\", \"values\", \"values\", \"values\", \"values\", \"values\", \"values\", \"values\", \"variables\", \"variables\", \"variables\", \"variables\", \"variables\", \"variables\", \"variables\", \"variables\", \"variables\", \"variables\", \"vector\", \"vector\", \"vector\", \"vector\", \"vector\", \"vector\", \"vector\", \"vector\", \"vector\", \"vector\", \"vertical\", \"vertical\", \"vertical\", \"vertical\", \"vertical\", \"vertical\", \"vertical\", \"vertical\", \"vertical\", \"vex\", \"via\", \"via\", \"via\", \"via\", \"via\", \"via\", \"via\", \"via\", \"via\", \"via\", \"vianney\", \"vianney\", \"vianney\", \"view\", \"view\", \"view\", \"view\", \"view\", \"view\", \"view\", \"view\", \"view\", \"view\", \"viterbi\", \"vki\", \"vki\", \"vki\", \"vki\", \"vki\", \"vki\", \"vki\", \"vki\", \"vm\", \"vm\", \"vm\", \"vm\", \"voltage\", \"voltage\", \"voltage\", \"voltage\", \"voltage\", \"voltage\", \"voltage\", \"voltage\", \"voltage\", \"vrest\", \"vrest\", \"waibel\", \"wait\", \"wait\", \"wait\", \"wait\", \"wald\", \"wald\", \"wald\", \"wald\", \"well\", \"well\", \"well\", \"well\", \"well\", \"well\", \"well\", \"well\", \"well\", \"well\", \"widgets\", \"widgets\", \"widgets\", \"widgets\", \"wireless\", \"wireless\", \"wireless\", \"wireless\", \"wireless\", \"wireless\", \"wireless\", \"wireless\", \"without\", \"without\", \"without\", \"without\", \"without\", \"without\", \"without\", \"without\", \"without\", \"without\", \"word\", \"word\", \"word\", \"word\", \"word\", \"word\", \"word\", \"word\", \"word\", \"words\", \"words\", \"words\", \"words\", \"words\", \"words\", \"words\", \"words\", \"words\", \"words\", \"work\", \"work\", \"work\", \"work\", \"work\", \"work\", \"work\", \"work\", \"work\", \"work\", \"wta\", \"wta\", \"wta\", \"wta\", \"wta\", \"wta\", \"wta\", \"wta\", \"wta\", \"xi\", \"xi\", \"xi\", \"xi\", \"xi\", \"xi\", \"xi\", \"xi\", \"xi\", \"xi\", \"xj\", \"xj\", \"xj\", \"xj\", \"xj\", \"xj\", \"xj\", \"xj\", \"xj\", \"xj\", \"xm\", \"xm\", \"xm\", \"xm\", \"xm\", \"xm\", \"xm\", \"xm\", \"xm\", \"xm\", \"xnew\", \"xnew\", \"xnew\", \"xnew\", \"xnew\", \"xnew\", \"xnew\", \"xnew\", \"xnew\", \"xodus\", \"xodus\", \"xp\", \"xp\", \"xp\", \"xp\", \"xp\", \"xp\", \"xt\", \"xt\", \"xt\", \"xt\", \"xt\", \"xt\", \"xt\", \"xt\", \"xt\", \"xt\", \"zee\", \"zee\", \"zee\", \"zee\", \"zhaoping\", \"zk\", \"zk\", \"zk\", \"zk\", \"zk\", \"zk\", \"zk\", \"zk\", \"zk\", \"zk\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [2, 10, 5, 1, 3, 4, 7, 6, 9, 8]};\n",
              "\n",
              "function LDAvis_load_lib(url, callback){\n",
              "  var s = document.createElement('script');\n",
              "  s.src = url;\n",
              "  s.async = true;\n",
              "  s.onreadystatechange = s.onload = callback;\n",
              "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
              "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
              "}\n",
              "\n",
              "if(typeof(LDAvis) !== \"undefined\"){\n",
              "   // already loaded: just create the visualization\n",
              "   !function(LDAvis){\n",
              "       new LDAvis(\"#\" + \"ldavis_el2491350606372124966694343950\", ldavis_el2491350606372124966694343950_data);\n",
              "   }(LDAvis);\n",
              "}else if(typeof define === \"function\" && define.amd){\n",
              "   // require.js is available: use it to load d3/LDAvis\n",
              "   require.config({paths: {d3: \"https://d3js.org/d3.v5\"}});\n",
              "   require([\"d3\"], function(d3){\n",
              "      window.d3 = d3;\n",
              "      LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.4.0/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
              "        new LDAvis(\"#\" + \"ldavis_el2491350606372124966694343950\", ldavis_el2491350606372124966694343950_data);\n",
              "      });\n",
              "    });\n",
              "}else{\n",
              "    // require.js not available: dynamically load d3 & LDAvis\n",
              "    LDAvis_load_lib(\"https://d3js.org/d3.v5.js\", function(){\n",
              "         LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.4.0/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
              "                 new LDAvis(\"#\" + \"ldavis_el2491350606372124966694343950\", ldavis_el2491350606372124966694343950_data);\n",
              "            })\n",
              "         });\n",
              "}\n",
              "</script>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "import pyLDAvis.gensim_models\n",
        "import pickle\n",
        "import pyLDAvis\n",
        "\n",
        "# Visualize the topics\n",
        "pyLDAvis.enable_notebook()\n",
        "\n",
        "LDAvis_data_filepath = os.path.join('/content_'+str(num_topics))\n",
        "\n",
        "# # this is a bit time consuming - make the if statement True\n",
        "# # if you want to execute visualization prep yourself\n",
        "if 1 == 1:\n",
        "    LDAvis_prepared = pyLDAvis.gensim_models.prepare(lda_model, corpus, id2word)\n",
        "    with open(LDAvis_data_filepath, 'wb') as f:\n",
        "        pickle.dump(LDAvis_prepared, f)\n",
        "\n",
        "# load the pre-prepared pyLDAvis data from disk\n",
        "with open(LDAvis_data_filepath, 'rb') as f:\n",
        "    LDAvis_prepared = pickle.load(f)\n",
        "\n",
        "pyLDAvis.save_html(LDAvis_prepared, 'content_'+ str(num_topics) +'.html')\n",
        "\n",
        "LDAvis_prepared"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5VSXbmiaz7Fo"
      },
      "source": [
        "** **\n",
        "#### Closing Notes\n",
        "Machine learning has become increasingly popular over the past decade, and recent advances in computational availability have led to exponential growth to people looking for ways how new methods can be incorporated to advance the field of Natural Language Processing.\n",
        "\n",
        "Often, we treat topic models as black-box algorithms, but hopefully, this notebook addressed to shed light on the underlying math, and intuitions behind it, and high-level code to get you started with any textual data.\n",
        "\n",
        "In the next article, we’ll go one step deeper into understanding how you can evaluate the performance of topic models, tune its hyper-parameters to get more intuitive and reliable results.\n",
        "\n",
        "** **\n",
        "#### References:\n",
        "1. Topic model — Wikipedia. https://en.wikipedia.org/wiki/Topic_model\n",
        "2. Distributed Strategies for Topic Modeling. https://www.ideals.illinois.edu/bitstream/handle/2142/46405/ParallelTopicModels.pdf?sequence=2&isAllowed=y\n",
        "3. Topic Mapping — Software — Resources — Amaral Lab. https://amaral.northwestern.edu/resources/software/topic-mapping\n",
        "4. A Survey of Topic Modeling in Text Mining. https://thesai.org/Downloads/Volume6No1/Paper_21-A_Survey_of_Topic_Modeling_in_Text_Mining.pdf\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "oL9KopJirB2g"
      ],
      "toc_visible": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}